{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>CID</th>\n",
       "      <th>f_avg_IC50</th>\n",
       "      <th>r_avg_IC50</th>\n",
       "      <th>ROMol</th>\n",
       "      <th>molecular_weight</th>\n",
       "      <th>n_hba</th>\n",
       "      <th>n_hbd</th>\n",
       "      <th>logp</th>\n",
       "      <th>Ro5_fulfilled</th>\n",
       "      <th>f_avg_pIC50</th>\n",
       "      <th>r_avg_pIC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>N#Cc1cccc(NC(=O)Cc2cncc3ccccc23)c1</td>\n",
       "      <td>DAR-DIA-23aa0b97-19</td>\n",
       "      <td>26.719515</td>\n",
       "      <td>14.641091</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7fc319ac34c0&gt;</td>\n",
       "      <td>287.105862</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.28768</td>\n",
       "      <td>True</td>\n",
       "      <td>4.573171</td>\n",
       "      <td>4.834427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>O=C(Cc1cncc2ccccc12)Nc1ccccc1</td>\n",
       "      <td>DAR-DIA-23aa0b97-20</td>\n",
       "      <td>57.590417</td>\n",
       "      <td>45.077469</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x7fc319ac3530&gt;</td>\n",
       "      <td>262.110613</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.41600</td>\n",
       "      <td>True</td>\n",
       "      <td>4.239650</td>\n",
       "      <td>4.346040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              SMILES                  CID  \\\n",
       "0          35  N#Cc1cccc(NC(=O)Cc2cncc3ccccc23)c1  DAR-DIA-23aa0b97-19   \n",
       "1          36       O=C(Cc1cncc2ccccc12)Nc1ccccc1  DAR-DIA-23aa0b97-20   \n",
       "\n",
       "   f_avg_IC50  r_avg_IC50                                             ROMol  \\\n",
       "0   26.719515   14.641091  <rdkit.Chem.rdchem.Mol object at 0x7fc319ac34c0>   \n",
       "1   57.590417   45.077469  <rdkit.Chem.rdchem.Mol object at 0x7fc319ac3530>   \n",
       "\n",
       "   molecular_weight  n_hba  n_hbd     logp  Ro5_fulfilled  f_avg_pIC50  \\\n",
       "0        287.105862      3      1  3.28768           True     4.573171   \n",
       "1        262.110613      2      1  3.41600           True     4.239650   \n",
       "\n",
       "   r_avg_pIC50  \n",
       "0     4.834427  \n",
       "1     4.346040  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from helper_fun import *\n",
    "import helper_fun\n",
    "\n",
    "# Silence some expected warnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "from Split_functions_regression.split_furthest_cluster import *\n",
    "from Split_functions_regression.split_hierarchical_cluster import *\n",
    "from Split_functions_regression.split_random import *\n",
    "from Split_functions_regression.split_strat_pIC50 import *\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Neural network specific libraries\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "\n",
    "# Set path to this notebook\n",
    "HERE = Path(_dh[-1])\n",
    "DATA = HERE / \"data\"\n",
    "\n",
    "compounds = pd.read_csv('../COVID_MOONSHOT/compounds_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assign cluster ID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/595 [00:00<?, ?it/s][11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      " 29%|██▊       | 170/595 [00:00<00:00, 1695.39it/s][11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      " 57%|█████▋    | 340/595 [00:00<00:00, 1555.91it/s][11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      " 84%|████████▎ | 497/595 [00:00<00:00, 1470.93it/s][11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "100%|██████████| 595/595 [00:00<00:00, 1463.83it/s]\n",
      "  0%|          | 0/595 [00:00<?, ?it/s][11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      " 29%|██▊       | 171/595 [00:00<00:00, 1704.34it/s][11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      " 57%|█████▋    | 342/595 [00:00<00:00, 1657.00it/s][11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:33] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      " 85%|████████▌ | 508/595 [00:00<00:00, 1081.79it/s][11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:34] DEPRECATION WARNING: please use MorganGenerator\n",
      "100%|██████████| 595/595 [00:00<00:00, 1195.70it/s]\n",
      "  0%|          | 0/595 [00:00<?, ?it/s][11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      " 28%|██▊       | 164/595 [00:00<00:00, 1636.12it/s][11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      " 55%|█████▌    | 328/595 [00:00<00:00, 1420.52it/s][11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      " 79%|███████▉  | 472/595 [00:00<00:00, 1391.15it/s][11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "100%|██████████| 595/595 [00:00<00:00, 1434.42it/s]\n",
      "  0%|          | 0/595 [00:00<?, ?it/s][11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      " 20%|█▉        | 118/595 [00:00<00:00, 1121.61it/s][11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      " 39%|███▉      | 231/595 [00:00<00:00, 1093.63it/s][11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      " 64%|██████▍   | 381/595 [00:00<00:00, 1273.35it/s][11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      " 91%|█████████ | 542/595 [00:00<00:00, 1400.90it/s][11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "[11:45:45] DEPRECATION WARNING: please use MorganGenerator\n",
      "100%|██████████| 595/595 [00:00<00:00, 1334.14it/s]\n"
     ]
    }
   ],
   "source": [
    "compounds[\"Fingerprints\"] = compounds[\"SMILES\"].apply(smiles_to_fp)\n",
    "x_train_rand, x_test_rand, y_train_rand, y_test_rand = random_split(compounds[\"Fingerprints\"], compounds[\"f_avg_pIC50\"])\n",
    "x_train_strat, x_test_strat, y_train_strat, y_test_strat = strat_pIC50_split(compounds)\n",
    "x_train_hi, x_test_hi, y_train_hi, y_test_hi = split_hierarchical_clusters(compounds, test_size=0.2, random_state=42)\n",
    "x_train_noise, x_test_noise, y_train_noise, y_test_noise = UMAP_noise_split(compounds)\n",
    "x_train_fur, x_test_fur, y_train_fur, y_test_fur = furthest_cluster_split(compounds)\n",
    "# print(f\"Shape of train_x: {train_x.shape}\") (476,)\n",
    "# print(f\"Shape of test_x: {test_y.shape}\") (119,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_rand = RandomForestRegressor(random_state=SEED)\n",
    "rfr_strat = RandomForestRegressor(random_state=SEED)\n",
    "rfr_hi = RandomForestRegressor(random_state=SEED)\n",
    "rfr_noise = RandomForestRegressor(random_state=SEED)\n",
    "rfr_fur = RandomForestRegressor(random_state=SEED)\n",
    "rfr_rand.fit(np.array(list((x_train_rand))).astype(float), y_train_rand)\n",
    "rfr_strat.fit(np.array(list((x_train_strat))).astype(float), y_train_strat)\n",
    "rfr_hi.fit(np.array(list((x_train_hi))).astype(float), y_train_hi)\n",
    "rfr_noise.fit(np.array(list((x_train_noise))).astype(float), y_train_noise)\n",
    "rfr_fur.fit(np.array(list((x_train_fur))).astype(float), y_train_fur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rfr_rand = rfr_rand.predict(np.array(list((x_test_rand))).astype(float))\n",
    "y_pred_rfr_strat = rfr_strat.predict(np.array(list((x_test_strat))).astype(float))\n",
    "y_pred_rfr_hi = rfr_hi.predict(np.array(list((x_test_hi))).astype(float))\n",
    "y_pred_rfr_noise = rfr_noise.predict(np.array(list((x_test_noise))).astype(float))\n",
    "y_pred_rfr_fur = rfr_fur.predict(np.array(list((x_test_fur))).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_rfr_rand = mean_absolute_error(y_test_rand, y_pred_rfr_rand)\n",
    "mse_rfr_rand = mean_squared_error(y_test_rand, y_pred_rfr_rand)\n",
    "r2_rfr_rand = r2_score(y_test_rand, y_pred_rfr_rand)\n",
    "\n",
    "mae_rfr_strat = mean_absolute_error(y_test_strat, y_pred_rfr_strat)\n",
    "mse_rfr_strat = mean_squared_error(y_test_strat, y_pred_rfr_strat)\n",
    "r2_rfr_strat = r2_score(y_test_strat, y_pred_rfr_strat)\n",
    "\n",
    "mae_rfr_hi = mean_absolute_error(y_test_hi, y_pred_rfr_hi)\n",
    "mse_rfr_hi = mean_squared_error(y_test_hi, y_pred_rfr_hi)\n",
    "r2_rfr_hi = r2_score(y_test_hi, y_pred_rfr_hi)\n",
    "\n",
    "mae_rfr_noise = mean_absolute_error(y_test_noise, y_pred_rfr_noise)\n",
    "mse_rfr_noise = mean_squared_error(y_test_noise, y_pred_rfr_noise)\n",
    "r2_rfr_noise = r2_score(y_test_noise, y_pred_rfr_noise)\n",
    "\n",
    "mae_rfr_fur = mean_absolute_error(y_test_fur, y_pred_rfr_fur)\n",
    "mse_rfr_fur = mean_squared_error(y_test_fur, y_pred_rfr_fur)\n",
    "r2_rfr_fur = r2_score(y_test_fur, y_pred_rfr_fur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              MAE       MSE        R2\n",
      "Split                                                \n",
      "Random                   0.382970  0.309122  0.579999\n",
      "Stratified pIC50         0.461976  0.423172  0.516725\n",
      "Hierarchical Clustering  0.674829  0.705286  0.323519\n",
      "UMAP Noise               0.787113  0.913533 -0.179115\n",
      "UMAP Furthest Cluster    0.839491  0.938845 -0.237629\n"
     ]
    }
   ],
   "source": [
    "#Creat a table that shows the performance of the random forest regressor on the different splits displaying mae, mse and r2 values\n",
    "split_scores_rfr_initial = {'Split': ['Random', 'Stratified pIC50', 'Hierarchical Clustering', 'UMAP Noise', 'UMAP Furthest Cluster'],\n",
    "        'MAE': [mae_rfr_rand, mae_rfr_strat, mae_rfr_hi, mae_rfr_noise, mae_rfr_fur],\n",
    "        'MSE': [mse_rfr_rand, mse_rfr_strat, mse_rfr_hi, mse_rfr_noise, mse_rfr_fur],\n",
    "        'R2': [r2_rfr_rand, r2_rfr_strat, r2_rfr_hi, r2_rfr_noise, r2_rfr_fur]}\n",
    "\n",
    "split_scores_rfr_initial_df = pd.DataFrame(split_scores_rfr_initial)\n",
    "split_scores_rfr_initial_df.set_index(\"Split\", inplace=True)\n",
    "#save df to csv in data file\n",
    "split_scores_rfr_initial_df.to_csv(DATA / \"split_scores_rfr_initial.csv\")\n",
    "\n",
    "print(split_scores_rfr_initial_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X_train, y_train):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 2, 500)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 50)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 50)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 50)\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs=-1).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 13:00:28,100] A new study created in memory with name: no-name-d9d00627-1541-46d0-96ca-5f8bc2a00891\n",
      "[I 2024-07-29 13:00:28,103] A new study created in memory with name: no-name-bf7e876b-7118-4952-b140-f797665b6a62\n",
      "[I 2024-07-29 13:00:28,106] A new study created in memory with name: no-name-6cba7155-7f3e-48b4-a320-bddf5edc9f4e\n",
      "[I 2024-07-29 13:00:28,109] A new study created in memory with name: no-name-6143c822-6e46-4f3c-9f50-66999845e895\n",
      "[I 2024-07-29 13:00:28,111] A new study created in memory with name: no-name-c0c8d958-71d5-41c7-b910-4b432f912eb2\n"
     ]
    }
   ],
   "source": [
    "study_rand = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.RandomSampler(seed=SEED))\n",
    "study_strat = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.RandomSampler(seed=SEED))\n",
    "study_hi = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.RandomSampler(seed=SEED))\n",
    "study_noise = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.RandomSampler(seed=SEED))\n",
    "study_fur = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.RandomSampler(seed=SEED))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aadcf5ee6b142e68a4dda60dd5e916d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 13:02:00,247] Trial 0 finished with value: -0.6684983150560477 and parameters: {'n_estimators': 188, 'max_depth': 48, 'min_samples_split': 37, 'min_samples_leaf': 30}. Best is trial 0 with value: -0.6684983150560477.\n",
      "[I 2024-07-29 13:02:00,761] Trial 1 finished with value: -0.7239100458278541 and parameters: {'n_estimators': 79, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 44}. Best is trial 0 with value: -0.6684983150560477.\n",
      "[I 2024-07-29 13:02:01,971] Trial 2 finished with value: -0.7366020211370621 and parameters: {'n_estimators': 301, 'max_depth': 36, 'min_samples_split': 3, 'min_samples_leaf': 49}. Best is trial 0 with value: -0.6684983150560477.\n",
      "[I 2024-07-29 13:02:04,286] Trial 3 finished with value: -0.529789797686855 and parameters: {'n_estimators': 417, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:05,056] Trial 4 finished with value: -0.5772483072029229 and parameters: {'n_estimators': 153, 'max_depth': 27, 'min_samples_split': 23, 'min_samples_leaf': 15}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:06,605] Trial 5 finished with value: -0.6088852888887266 and parameters: {'n_estimators': 307, 'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 19}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:07,715] Trial 6 finished with value: -0.6493895745165462 and parameters: {'n_estimators': 229, 'max_depth': 40, 'min_samples_split': 11, 'min_samples_leaf': 26}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:09,328] Trial 7 finished with value: -0.5865616064298859 and parameters: {'n_estimators': 297, 'max_depth': 4, 'min_samples_split': 31, 'min_samples_leaf': 9}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:09,517] Trial 8 finished with value: -0.7107116163584777 and parameters: {'n_estimators': 34, 'max_depth': 48, 'min_samples_split': 49, 'min_samples_leaf': 41}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:10,518] Trial 9 finished with value: -0.6337803390421113 and parameters: {'n_estimators': 154, 'max_depth': 6, 'min_samples_split': 35, 'min_samples_leaf': 23}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:10,914] Trial 10 finished with value: -0.734262367172645 and parameters: {'n_estimators': 62, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 46}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:11,849] Trial 11 finished with value: -0.6488222511455719 and parameters: {'n_estimators': 131, 'max_depth': 34, 'min_samples_split': 17, 'min_samples_leaf': 27}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:13,370] Trial 12 finished with value: -0.7013014857133459 and parameters: {'n_estimators': 274, 'max_depth': 11, 'min_samples_split': 49, 'min_samples_leaf': 39}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:15,160] Trial 13 finished with value: -0.7327306243658963 and parameters: {'n_estimators': 470, 'max_depth': 45, 'min_samples_split': 31, 'min_samples_leaf': 47}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:15,417] Trial 14 finished with value: -0.5973517758073555 and parameters: {'n_estimators': 46, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 17}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:16,438] Trial 15 finished with value: -0.6151690099273347 and parameters: {'n_estimators': 195, 'max_depth': 15, 'min_samples_split': 42, 'min_samples_leaf': 18}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:17,003] Trial 16 finished with value: -0.710114581082378 and parameters: {'n_estimators': 142, 'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 41}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:17,248] Trial 17 finished with value: -0.5763815662523346 and parameters: {'n_estimators': 39, 'max_depth': 50, 'min_samples_split': 39, 'min_samples_leaf': 10}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:17,326] Trial 18 finished with value: -0.7126205393538967 and parameters: {'n_estimators': 4, 'max_depth': 41, 'min_samples_split': 36, 'min_samples_leaf': 37}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:19,333] Trial 19 finished with value: -0.53529861039854 and parameters: {'n_estimators': 386, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 6}. Best is trial 3 with value: -0.529789797686855.\n",
      "[I 2024-07-29 13:02:21,927] Trial 20 finished with value: -0.48139478737866853 and parameters: {'n_estimators': 432, 'max_depth': 32, 'min_samples_split': 18, 'min_samples_leaf': 4}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:22,662] Trial 21 finished with value: -0.6690874494507902 and parameters: {'n_estimators': 157, 'max_depth': 17, 'min_samples_split': 37, 'min_samples_leaf': 32}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:24,494] Trial 22 finished with value: -0.6874229370988006 and parameters: {'n_estimators': 444, 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 36}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:26,477] Trial 23 finished with value: -0.6458022994654788 and parameters: {'n_estimators': 381, 'max_depth': 29, 'min_samples_split': 39, 'min_samples_leaf': 25}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:28,093] Trial 24 finished with value: -0.48807640708177147 and parameters: {'n_estimators': 262, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:28,209] Trial 25 finished with value: -0.6412523444023307 and parameters: {'n_estimators': 17, 'max_depth': 33, 'min_samples_split': 17, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:30,409] Trial 26 finished with value: -0.6942278203471206 and parameters: {'n_estimators': 454, 'max_depth': 14, 'min_samples_split': 22, 'min_samples_leaf': 38}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:31,073] Trial 27 finished with value: -0.5460506021034266 and parameters: {'n_estimators': 116, 'max_depth': 5, 'min_samples_split': 16, 'min_samples_leaf': 9}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:33,011] Trial 28 finished with value: -0.7225600211012873 and parameters: {'n_estimators': 465, 'max_depth': 41, 'min_samples_split': 33, 'min_samples_leaf': 44}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:35,144] Trial 29 finished with value: -0.6520311011145214 and parameters: {'n_estimators': 403, 'max_depth': 11, 'min_samples_split': 45, 'min_samples_leaf': 27}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:37,774] Trial 30 finished with value: -0.49496641188716584 and parameters: {'n_estimators': 404, 'max_depth': 45, 'min_samples_split': 17, 'min_samples_leaf': 6}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:38,294] Trial 31 finished with value: -0.7167964334826705 and parameters: {'n_estimators': 115, 'max_depth': 22, 'min_samples_split': 42, 'min_samples_leaf': 44}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:38,376] Trial 32 finished with value: -0.5969858635442613 and parameters: {'n_estimators': 5, 'max_depth': 27, 'min_samples_split': 22, 'min_samples_leaf': 12}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:38,719] Trial 33 finished with value: -0.6212627339376003 and parameters: {'n_estimators': 61, 'max_depth': 18, 'min_samples_split': 48, 'min_samples_leaf': 17}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:39,820] Trial 34 finished with value: -0.7365501342815801 and parameters: {'n_estimators': 260, 'max_depth': 36, 'min_samples_split': 19, 'min_samples_leaf': 49}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:42,273] Trial 35 finished with value: -0.5830663474692801 and parameters: {'n_estimators': 482, 'max_depth': 14, 'min_samples_split': 26, 'min_samples_leaf': 16}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:42,813] Trial 36 finished with value: -0.6764164877487813 and parameters: {'n_estimators': 144, 'max_depth': 3, 'min_samples_split': 31, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:43,003] Trial 37 finished with value: -0.5912821123829846 and parameters: {'n_estimators': 27, 'max_depth': 15, 'min_samples_split': 46, 'min_samples_leaf': 12}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:43,418] Trial 38 finished with value: -0.6044429453371934 and parameters: {'n_estimators': 74, 'max_depth': 25, 'min_samples_split': 50, 'min_samples_leaf': 13}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:45,239] Trial 39 finished with value: -0.6925147834606931 and parameters: {'n_estimators': 337, 'max_depth': 39, 'min_samples_split': 13, 'min_samples_leaf': 37}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:46,357] Trial 40 finished with value: -0.6538034094695424 and parameters: {'n_estimators': 185, 'max_depth': 32, 'min_samples_split': 33, 'min_samples_leaf': 27}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:46,623] Trial 41 finished with value: -0.5412777779873966 and parameters: {'n_estimators': 47, 'max_depth': 42, 'min_samples_split': 17, 'min_samples_leaf': 10}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:46,777] Trial 42 finished with value: -0.5232540757670046 and parameters: {'n_estimators': 22, 'max_depth': 30, 'min_samples_split': 35, 'min_samples_leaf': 1}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:48,273] Trial 43 finished with value: -0.5530476337814488 and parameters: {'n_estimators': 257, 'max_depth': 13, 'min_samples_split': 33, 'min_samples_leaf': 9}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:49,940] Trial 44 finished with value: -0.5789419443441431 and parameters: {'n_estimators': 346, 'max_depth': 20, 'min_samples_split': 47, 'min_samples_leaf': 7}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:50,834] Trial 45 finished with value: -0.7226692385328699 and parameters: {'n_estimators': 172, 'max_depth': 7, 'min_samples_split': 47, 'min_samples_leaf': 44}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:51,430] Trial 46 finished with value: -0.6618627673805062 and parameters: {'n_estimators': 130, 'max_depth': 34, 'min_samples_split': 42, 'min_samples_leaf': 28}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:52,425] Trial 47 finished with value: -0.7261914346093422 and parameters: {'n_estimators': 266, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 45}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:54,427] Trial 48 finished with value: -0.6054698798910986 and parameters: {'n_estimators': 451, 'max_depth': 33, 'min_samples_split': 18, 'min_samples_leaf': 18}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:55,901] Trial 49 finished with value: -0.6996762270817016 and parameters: {'n_estimators': 364, 'max_depth': 45, 'min_samples_split': 45, 'min_samples_leaf': 39}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:57,356] Trial 50 finished with value: -0.727961344489737 and parameters: {'n_estimators': 322, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 45}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:58,648] Trial 51 finished with value: -0.7371012233643315 and parameters: {'n_estimators': 304, 'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 34}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:02:58,726] Trial 52 finished with value: -0.7280765918238685 and parameters: {'n_estimators': 4, 'max_depth': 9, 'min_samples_split': 28, 'min_samples_leaf': 35}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:00,122] Trial 53 finished with value: -0.569322471399617 and parameters: {'n_estimators': 327, 'max_depth': 12, 'min_samples_split': 36, 'min_samples_leaf': 12}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:00,740] Trial 54 finished with value: -0.717017329371944 and parameters: {'n_estimators': 164, 'max_depth': 38, 'min_samples_split': 33, 'min_samples_leaf': 43}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:02,758] Trial 55 finished with value: -0.6123259190496753 and parameters: {'n_estimators': 330, 'max_depth': 29, 'min_samples_split': 6, 'min_samples_leaf': 19}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:03,449] Trial 56 finished with value: -0.6295970603540043 and parameters: {'n_estimators': 134, 'max_depth': 13, 'min_samples_split': 49, 'min_samples_leaf': 20}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:05,236] Trial 57 finished with value: -0.6500922745939006 and parameters: {'n_estimators': 447, 'max_depth': 32, 'min_samples_split': 40, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:06,394] Trial 58 finished with value: -0.6920368951387723 and parameters: {'n_estimators': 289, 'max_depth': 26, 'min_samples_split': 11, 'min_samples_leaf': 37}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:07,158] Trial 59 finished with value: -0.6373753271114236 and parameters: {'n_estimators': 142, 'max_depth': 3, 'min_samples_split': 33, 'min_samples_leaf': 9}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:09,277] Trial 60 finished with value: -0.6206027429855 and parameters: {'n_estimators': 471, 'max_depth': 48, 'min_samples_split': 46, 'min_samples_leaf': 19}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:09,345] Trial 61 finished with value: -0.7454937266407082 and parameters: {'n_estimators': 9, 'max_depth': 47, 'min_samples_split': 22, 'min_samples_leaf': 49}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:11,687] Trial 62 finished with value: -0.6173686589057175 and parameters: {'n_estimators': 482, 'max_depth': 43, 'min_samples_split': 16, 'min_samples_leaf': 20}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:13,664] Trial 63 finished with value: -0.6582935527452327 and parameters: {'n_estimators': 426, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 28}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:16,087] Trial 64 finished with value: -0.5195495415458181 and parameters: {'n_estimators': 469, 'max_depth': 36, 'min_samples_split': 29, 'min_samples_leaf': 5}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:17,212] Trial 65 finished with value: -0.6489641780761122 and parameters: {'n_estimators': 308, 'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:19,118] Trial 66 finished with value: -0.6863143431048792 and parameters: {'n_estimators': 439, 'max_depth': 38, 'min_samples_split': 36, 'min_samples_leaf': 36}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:19,741] Trial 67 finished with value: -0.7053128570166036 and parameters: {'n_estimators': 181, 'max_depth': 16, 'min_samples_split': 41, 'min_samples_leaf': 41}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:21,511] Trial 68 finished with value: -0.6487379037046888 and parameters: {'n_estimators': 434, 'max_depth': 46, 'min_samples_split': 27, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:23,263] Trial 69 finished with value: -0.7059074434115665 and parameters: {'n_estimators': 400, 'max_depth': 33, 'min_samples_split': 36, 'min_samples_leaf': 40}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:25,886] Trial 70 finished with value: -0.49522896386841797 and parameters: {'n_estimators': 446, 'max_depth': 18, 'min_samples_split': 20, 'min_samples_leaf': 5}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:27,235] Trial 71 finished with value: -0.6774014794122833 and parameters: {'n_estimators': 290, 'max_depth': 3, 'min_samples_split': 24, 'min_samples_leaf': 28}. Best is trial 20 with value: -0.48139478737866853.\n",
      "[I 2024-07-29 13:03:28,170] Trial 72 finished with value: -0.4226941268599618 and parameters: {'n_estimators': 144, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:30,073] Trial 73 finished with value: -0.6516376006964928 and parameters: {'n_estimators': 412, 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 27}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:32,313] Trial 74 finished with value: -0.527089002623187 and parameters: {'n_estimators': 386, 'max_depth': 12, 'min_samples_split': 32, 'min_samples_leaf': 5}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:32,463] Trial 75 finished with value: -0.6766312420713034 and parameters: {'n_estimators': 27, 'max_depth': 28, 'min_samples_split': 28, 'min_samples_leaf': 32}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:34,113] Trial 76 finished with value: -0.5940066298439721 and parameters: {'n_estimators': 364, 'max_depth': 49, 'min_samples_split': 27, 'min_samples_leaf': 17}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:36,488] Trial 77 finished with value: -0.4960766977037457 and parameters: {'n_estimators': 398, 'max_depth': 15, 'min_samples_split': 23, 'min_samples_leaf': 4}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:36,574] Trial 78 finished with value: -0.6965026153590683 and parameters: {'n_estimators': 14, 'max_depth': 49, 'min_samples_split': 42, 'min_samples_leaf': 35}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:37,482] Trial 79 finished with value: -0.5536131630161563 and parameters: {'n_estimators': 206, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 13}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:39,195] Trial 80 finished with value: -0.5786569754120503 and parameters: {'n_estimators': 276, 'max_depth': 37, 'min_samples_split': 34, 'min_samples_leaf': 14}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:42,106] Trial 81 finished with value: -0.6692990303825924 and parameters: {'n_estimators': 478, 'max_depth': 38, 'min_samples_split': 29, 'min_samples_leaf': 31}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:43,023] Trial 82 finished with value: -0.6974127822681128 and parameters: {'n_estimators': 211, 'max_depth': 14, 'min_samples_split': 19, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:43,108] Trial 83 finished with value: -0.48710399811801997 and parameters: {'n_estimators': 9, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:45,515] Trial 84 finished with value: -0.5104197490247129 and parameters: {'n_estimators': 428, 'max_depth': 36, 'min_samples_split': 25, 'min_samples_leaf': 5}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:47,143] Trial 85 finished with value: -0.6298386871904919 and parameters: {'n_estimators': 247, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 22}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:48,486] Trial 86 finished with value: -0.5194898577704786 and parameters: {'n_estimators': 200, 'max_depth': 32, 'min_samples_split': 33, 'min_samples_leaf': 3}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:49,370] Trial 87 finished with value: -0.718937697897823 and parameters: {'n_estimators': 188, 'max_depth': 32, 'min_samples_split': 26, 'min_samples_leaf': 43}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:50,954] Trial 88 finished with value: -0.6776918586166137 and parameters: {'n_estimators': 330, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 33}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:51,059] Trial 89 finished with value: -0.6644061795038537 and parameters: {'n_estimators': 15, 'max_depth': 30, 'min_samples_split': 48, 'min_samples_leaf': 29}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:51,939] Trial 90 finished with value: -0.6559874384133387 and parameters: {'n_estimators': 195, 'max_depth': 33, 'min_samples_split': 24, 'min_samples_leaf': 28}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:53,557] Trial 91 finished with value: -0.7287044939164352 and parameters: {'n_estimators': 471, 'max_depth': 20, 'min_samples_split': 49, 'min_samples_leaf': 46}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:54,132] Trial 92 finished with value: -0.5041443955978132 and parameters: {'n_estimators': 99, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:54,417] Trial 93 finished with value: -0.5879112192050917 and parameters: {'n_estimators': 49, 'max_depth': 35, 'min_samples_split': 5, 'min_samples_leaf': 16}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:56,542] Trial 94 finished with value: -0.6536967185030367 and parameters: {'n_estimators': 423, 'max_depth': 3, 'min_samples_split': 41, 'min_samples_leaf': 15}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:56,780] Trial 95 finished with value: -0.7224887798578778 and parameters: {'n_estimators': 60, 'max_depth': 36, 'min_samples_split': 32, 'min_samples_leaf': 44}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:03:58,968] Trial 96 finished with value: -0.521060930851953 and parameters: {'n_estimators': 368, 'max_depth': 41, 'min_samples_split': 15, 'min_samples_leaf': 9}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:00,769] Trial 97 finished with value: -0.6321381505585271 and parameters: {'n_estimators': 376, 'max_depth': 41, 'min_samples_split': 50, 'min_samples_leaf': 21}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:01,548] Trial 98 finished with value: -0.736389289849248 and parameters: {'n_estimators': 187, 'max_depth': 40, 'min_samples_split': 18, 'min_samples_leaf': 47}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:03,414] Trial 99 finished with value: -0.6958830736898671 and parameters: {'n_estimators': 430, 'max_depth': 23, 'min_samples_split': 38, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:03,823] Trial 100 finished with value: -0.7165567776594419 and parameters: {'n_estimators': 53, 'max_depth': 46, 'min_samples_split': 26, 'min_samples_leaf': 42}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:04,825] Trial 101 finished with value: -0.47507832553462837 and parameters: {'n_estimators': 161, 'max_depth': 45, 'min_samples_split': 21, 'min_samples_leaf': 1}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:06,483] Trial 102 finished with value: -0.7346355588603635 and parameters: {'n_estimators': 453, 'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 48}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:08,807] Trial 103 finished with value: -0.6325874902383803 and parameters: {'n_estimators': 476, 'max_depth': 30, 'min_samples_split': 32, 'min_samples_leaf': 23}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:09,361] Trial 104 finished with value: -0.6927370369306989 and parameters: {'n_estimators': 148, 'max_depth': 18, 'min_samples_split': 34, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:10,789] Trial 105 finished with value: -0.6450998192469684 and parameters: {'n_estimators': 396, 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 25}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:10,922] Trial 106 finished with value: -0.7291968319553691 and parameters: {'n_estimators': 30, 'max_depth': 28, 'min_samples_split': 23, 'min_samples_leaf': 45}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:11,760] Trial 107 finished with value: -0.6959857959625018 and parameters: {'n_estimators': 177, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 39}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:13,236] Trial 108 finished with value: -0.6880652247105574 and parameters: {'n_estimators': 310, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 36}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:13,483] Trial 109 finished with value: -0.5500428535415833 and parameters: {'n_estimators': 38, 'max_depth': 42, 'min_samples_split': 36, 'min_samples_leaf': 5}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:13,760] Trial 110 finished with value: -0.6279499979773432 and parameters: {'n_estimators': 44, 'max_depth': 50, 'min_samples_split': 20, 'min_samples_leaf': 19}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:15,501] Trial 111 finished with value: -0.6960984778957887 and parameters: {'n_estimators': 407, 'max_depth': 48, 'min_samples_split': 50, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:16,302] Trial 112 finished with value: -0.6549776500776312 and parameters: {'n_estimators': 189, 'max_depth': 6, 'min_samples_split': 40, 'min_samples_leaf': 28}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:17,322] Trial 113 finished with value: -0.6473614183928891 and parameters: {'n_estimators': 213, 'max_depth': 46, 'min_samples_split': 7, 'min_samples_leaf': 25}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:17,399] Trial 114 finished with value: -0.4990749198150244 and parameters: {'n_estimators': 7, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:17,660] Trial 115 finished with value: -0.669655297276528 and parameters: {'n_estimators': 60, 'max_depth': 33, 'min_samples_split': 38, 'min_samples_leaf': 30}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:19,379] Trial 116 finished with value: -0.7205408955348054 and parameters: {'n_estimators': 482, 'max_depth': 20, 'min_samples_split': 15, 'min_samples_leaf': 44}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:19,777] Trial 117 finished with value: -0.7399290907738003 and parameters: {'n_estimators': 113, 'max_depth': 49, 'min_samples_split': 2, 'min_samples_leaf': 49}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:19,863] Trial 118 finished with value: -0.7404083941687232 and parameters: {'n_estimators': 23, 'max_depth': 45, 'min_samples_split': 27, 'min_samples_leaf': 50}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:20,003] Trial 119 finished with value: -0.660013354433459 and parameters: {'n_estimators': 38, 'max_depth': 29, 'min_samples_split': 49, 'min_samples_leaf': 27}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:21,193] Trial 120 finished with value: -0.673678962298807 and parameters: {'n_estimators': 316, 'max_depth': 36, 'min_samples_split': 24, 'min_samples_leaf': 32}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:22,468] Trial 121 finished with value: -0.5772736949333328 and parameters: {'n_estimators': 293, 'max_depth': 46, 'min_samples_split': 4, 'min_samples_leaf': 15}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:24,534] Trial 122 finished with value: -0.6717880635765833 and parameters: {'n_estimators': 476, 'max_depth': 45, 'min_samples_split': 24, 'min_samples_leaf': 32}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:25,287] Trial 123 finished with value: -0.6039135185547562 and parameters: {'n_estimators': 140, 'max_depth': 11, 'min_samples_split': 24, 'min_samples_leaf': 18}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:26,488] Trial 124 finished with value: -0.7405615528423397 and parameters: {'n_estimators': 293, 'max_depth': 5, 'min_samples_split': 49, 'min_samples_leaf': 50}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:27,963] Trial 125 finished with value: -0.7069944815619215 and parameters: {'n_estimators': 350, 'max_depth': 28, 'min_samples_split': 17, 'min_samples_leaf': 41}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:29,368] Trial 126 finished with value: -0.7108941436775391 and parameters: {'n_estimators': 343, 'max_depth': 9, 'min_samples_split': 46, 'min_samples_leaf': 42}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:31,878] Trial 127 finished with value: -0.6216054270448861 and parameters: {'n_estimators': 475, 'max_depth': 37, 'min_samples_split': 32, 'min_samples_leaf': 21}. Best is trial 72 with value: -0.4226941268599618.\n",
      "[I 2024-07-29 13:04:35,228] Trial 128 finished with value: -0.4207627526327403 and parameters: {'n_estimators': 467, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:36,172] Trial 129 finished with value: -0.5880348207753135 and parameters: {'n_estimators': 189, 'max_depth': 41, 'min_samples_split': 50, 'min_samples_leaf': 8}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:37,340] Trial 130 finished with value: -0.7181632124325281 and parameters: {'n_estimators': 298, 'max_depth': 20, 'min_samples_split': 49, 'min_samples_leaf': 43}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:39,557] Trial 131 finished with value: -0.5703223096963241 and parameters: {'n_estimators': 420, 'max_depth': 24, 'min_samples_split': 22, 'min_samples_leaf': 14}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:39,709] Trial 132 finished with value: -0.7382843752231362 and parameters: {'n_estimators': 30, 'max_depth': 44, 'min_samples_split': 41, 'min_samples_leaf': 50}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:41,592] Trial 133 finished with value: -0.7352286628452791 and parameters: {'n_estimators': 499, 'max_depth': 29, 'min_samples_split': 39, 'min_samples_leaf': 48}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:43,784] Trial 134 finished with value: -0.5221517804550255 and parameters: {'n_estimators': 425, 'max_depth': 14, 'min_samples_split': 24, 'min_samples_leaf': 7}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:45,758] Trial 135 finished with value: -0.6794608206923807 and parameters: {'n_estimators': 478, 'max_depth': 31, 'min_samples_split': 13, 'min_samples_leaf': 34}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:46,836] Trial 136 finished with value: -0.679721518882818 and parameters: {'n_estimators': 310, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 34}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:47,787] Trial 137 finished with value: -0.7171459805561511 and parameters: {'n_estimators': 261, 'max_depth': 39, 'min_samples_split': 27, 'min_samples_leaf': 43}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:48,950] Trial 138 finished with value: -0.6254124348146769 and parameters: {'n_estimators': 277, 'max_depth': 29, 'min_samples_split': 44, 'min_samples_leaf': 21}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:49,391] Trial 139 finished with value: -0.6796798224525464 and parameters: {'n_estimators': 68, 'max_depth': 3, 'min_samples_split': 39, 'min_samples_leaf': 32}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:52,196] Trial 140 finished with value: -0.42688932414137815 and parameters: {'n_estimators': 353, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:52,896] Trial 141 finished with value: -0.6313164025150457 and parameters: {'n_estimators': 176, 'max_depth': 30, 'min_samples_split': 21, 'min_samples_leaf': 22}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:54,518] Trial 142 finished with value: -0.7016984784762373 and parameters: {'n_estimators': 453, 'max_depth': 19, 'min_samples_split': 27, 'min_samples_leaf': 40}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:55,246] Trial 143 finished with value: -0.737763842975614 and parameters: {'n_estimators': 199, 'max_depth': 32, 'min_samples_split': 44, 'min_samples_leaf': 48}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:55,679] Trial 144 finished with value: -0.5473522316853339 and parameters: {'n_estimators': 75, 'max_depth': 47, 'min_samples_split': 26, 'min_samples_leaf': 13}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:56,779] Trial 145 finished with value: -0.5978473590292973 and parameters: {'n_estimators': 231, 'max_depth': 50, 'min_samples_split': 26, 'min_samples_leaf': 17}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:58,747] Trial 146 finished with value: -0.4980544263350165 and parameters: {'n_estimators': 318, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:59,022] Trial 147 finished with value: -0.681546240364644 and parameters: {'n_estimators': 65, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 33}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:04:59,359] Trial 148 finished with value: -0.640431233706018 and parameters: {'n_estimators': 92, 'max_depth': 18, 'min_samples_split': 45, 'min_samples_leaf': 24}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:01,145] Trial 149 finished with value: -0.4535753409661563 and parameters: {'n_estimators': 335, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:01,588] Trial 150 finished with value: -0.46931899590148074 and parameters: {'n_estimators': 86, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:01,845] Trial 151 finished with value: -0.6064293257222897 and parameters: {'n_estimators': 62, 'max_depth': 24, 'min_samples_split': 12, 'min_samples_leaf': 19}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:02,798] Trial 152 finished with value: -0.7061892289392613 and parameters: {'n_estimators': 253, 'max_depth': 35, 'min_samples_split': 3, 'min_samples_leaf': 40}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:04,234] Trial 153 finished with value: -0.7322177454328298 and parameters: {'n_estimators': 315, 'max_depth': 6, 'min_samples_split': 44, 'min_samples_leaf': 47}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:04,392] Trial 154 finished with value: -0.6989019758898947 and parameters: {'n_estimators': 32, 'max_depth': 15, 'min_samples_split': 41, 'min_samples_leaf': 38}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:04,865] Trial 155 finished with value: -0.6446935187723448 and parameters: {'n_estimators': 94, 'max_depth': 12, 'min_samples_split': 20, 'min_samples_leaf': 25}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:06,115] Trial 156 finished with value: -0.694728174128679 and parameters: {'n_estimators': 310, 'max_depth': 20, 'min_samples_split': 24, 'min_samples_leaf': 38}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:06,276] Trial 157 finished with value: -0.7290861674877261 and parameters: {'n_estimators': 20, 'max_depth': 14, 'min_samples_split': 36, 'min_samples_leaf': 45}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:07,502] Trial 158 finished with value: -0.6344330728317261 and parameters: {'n_estimators': 257, 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 23}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:08,690] Trial 159 finished with value: -0.6094804485518106 and parameters: {'n_estimators': 267, 'max_depth': 13, 'min_samples_split': 15, 'min_samples_leaf': 19}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:08,777] Trial 160 finished with value: -0.5951699435012949 and parameters: {'n_estimators': 12, 'max_depth': 17, 'min_samples_split': 12, 'min_samples_leaf': 17}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:09,032] Trial 161 finished with value: -0.6796129877364777 and parameters: {'n_estimators': 61, 'max_depth': 45, 'min_samples_split': 31, 'min_samples_leaf': 34}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:10,845] Trial 162 finished with value: -0.6547674191233351 and parameters: {'n_estimators': 395, 'max_depth': 26, 'min_samples_split': 6, 'min_samples_leaf': 27}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:12,320] Trial 163 finished with value: -0.5200173492346732 and parameters: {'n_estimators': 294, 'max_depth': 38, 'min_samples_split': 23, 'min_samples_leaf': 7}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:13,077] Trial 164 finished with value: -0.6610575482454132 and parameters: {'n_estimators': 143, 'max_depth': 19, 'min_samples_split': 33, 'min_samples_leaf': 29}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:13,911] Trial 165 finished with value: -0.5625921334825748 and parameters: {'n_estimators': 179, 'max_depth': 50, 'min_samples_split': 31, 'min_samples_leaf': 12}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:14,162] Trial 166 finished with value: -0.5266373831593558 and parameters: {'n_estimators': 52, 'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 9}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:14,477] Trial 167 finished with value: -0.7295022070181354 and parameters: {'n_estimators': 95, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 45}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:14,728] Trial 168 finished with value: -0.7337754444114071 and parameters: {'n_estimators': 42, 'max_depth': 27, 'min_samples_split': 22, 'min_samples_leaf': 50}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:15,021] Trial 169 finished with value: -0.7241488821651157 and parameters: {'n_estimators': 57, 'max_depth': 21, 'min_samples_split': 49, 'min_samples_leaf': 44}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:16,493] Trial 170 finished with value: -0.6788934326262515 and parameters: {'n_estimators': 409, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 34}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:18,525] Trial 171 finished with value: -0.571241455673344 and parameters: {'n_estimators': 465, 'max_depth': 29, 'min_samples_split': 30, 'min_samples_leaf': 14}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:20,462] Trial 172 finished with value: -0.6286111150456521 and parameters: {'n_estimators': 385, 'max_depth': 11, 'min_samples_split': 17, 'min_samples_leaf': 22}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:21,534] Trial 173 finished with value: -0.6698894650450355 and parameters: {'n_estimators': 255, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 31}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:22,097] Trial 174 finished with value: -0.6450495846917553 and parameters: {'n_estimators': 146, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 25}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:23,248] Trial 175 finished with value: -0.5698735659322015 and parameters: {'n_estimators': 267, 'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 7}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:23,439] Trial 176 finished with value: -0.7096512573919344 and parameters: {'n_estimators': 33, 'max_depth': 50, 'min_samples_split': 17, 'min_samples_leaf': 41}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:23,919] Trial 177 finished with value: -0.6649864528535339 and parameters: {'n_estimators': 129, 'max_depth': 35, 'min_samples_split': 39, 'min_samples_leaf': 30}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:24,749] Trial 178 finished with value: -0.7328333494144692 and parameters: {'n_estimators': 237, 'max_depth': 22, 'min_samples_split': 19, 'min_samples_leaf': 47}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:26,082] Trial 179 finished with value: -0.6905429887470884 and parameters: {'n_estimators': 416, 'max_depth': 49, 'min_samples_split': 8, 'min_samples_leaf': 37}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:27,648] Trial 180 finished with value: -0.6923141580818981 and parameters: {'n_estimators': 470, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 38}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:28,919] Trial 181 finished with value: -0.7036909989920299 and parameters: {'n_estimators': 288, 'max_depth': 43, 'min_samples_split': 8, 'min_samples_leaf': 40}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:29,297] Trial 182 finished with value: -0.712328052267385 and parameters: {'n_estimators': 102, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 41}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:30,466] Trial 183 finished with value: -0.7250945630493574 and parameters: {'n_estimators': 333, 'max_depth': 27, 'min_samples_split': 19, 'min_samples_leaf': 44}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:31,311] Trial 184 finished with value: -0.6127961993914504 and parameters: {'n_estimators': 197, 'max_depth': 42, 'min_samples_split': 23, 'min_samples_leaf': 19}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:32,225] Trial 185 finished with value: -0.6469825250402438 and parameters: {'n_estimators': 232, 'max_depth': 16, 'min_samples_split': 38, 'min_samples_leaf': 26}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:32,667] Trial 186 finished with value: -0.6573959267755122 and parameters: {'n_estimators': 117, 'max_depth': 46, 'min_samples_split': 20, 'min_samples_leaf': 28}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:34,184] Trial 187 finished with value: -0.7317168915442833 and parameters: {'n_estimators': 454, 'max_depth': 32, 'min_samples_split': 7, 'min_samples_leaf': 47}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:35,284] Trial 188 finished with value: -0.7067485414272892 and parameters: {'n_estimators': 315, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 40}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:36,514] Trial 189 finished with value: -0.7041621923186419 and parameters: {'n_estimators': 311, 'max_depth': 28, 'min_samples_split': 45, 'min_samples_leaf': 40}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:36,942] Trial 190 finished with value: -0.6976901347240909 and parameters: {'n_estimators': 77, 'max_depth': 17, 'min_samples_split': 14, 'min_samples_leaf': 38}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:37,060] Trial 191 finished with value: -0.7291658091330728 and parameters: {'n_estimators': 18, 'max_depth': 29, 'min_samples_split': 39, 'min_samples_leaf': 44}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:37,736] Trial 192 finished with value: -0.7178552011112342 and parameters: {'n_estimators': 172, 'max_depth': 42, 'min_samples_split': 7, 'min_samples_leaf': 43}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:38,052] Trial 193 finished with value: -0.5762804599815876 and parameters: {'n_estimators': 65, 'max_depth': 21, 'min_samples_split': 41, 'min_samples_leaf': 8}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:38,502] Trial 194 finished with value: -0.6800994710519184 and parameters: {'n_estimators': 116, 'max_depth': 37, 'min_samples_split': 37, 'min_samples_leaf': 33}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:40,162] Trial 195 finished with value: -0.5979225043054 and parameters: {'n_estimators': 348, 'max_depth': 28, 'min_samples_split': 14, 'min_samples_leaf': 18}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:40,502] Trial 196 finished with value: -0.6217304200224671 and parameters: {'n_estimators': 92, 'max_depth': 46, 'min_samples_split': 30, 'min_samples_leaf': 21}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:41,434] Trial 197 finished with value: -0.6680529613012578 and parameters: {'n_estimators': 232, 'max_depth': 48, 'min_samples_split': 9, 'min_samples_leaf': 30}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:42,280] Trial 198 finished with value: -0.7222435670471846 and parameters: {'n_estimators': 254, 'max_depth': 31, 'min_samples_split': 2, 'min_samples_leaf': 44}. Best is trial 128 with value: -0.4207627526327403.\n",
      "[I 2024-07-29 13:05:43,976] Trial 199 finished with value: -0.7331428393924543 and parameters: {'n_estimators': 467, 'max_depth': 29, 'min_samples_split': 36, 'min_samples_leaf': 47}. Best is trial 128 with value: -0.4207627526327403.\n"
     ]
    }
   ],
   "source": [
    "#add trials using study.optimize\n",
    "study_rand.optimize(lambda trial: objective(trial, np.array(list((x_train_rand))).astype(float), y_train_rand), n_trials=200, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f03a64302b74ba893950069ffe72aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 13:05:45,407] Trial 0 finished with value: -0.6441660272739511 and parameters: {'n_estimators': 188, 'max_depth': 48, 'min_samples_split': 37, 'min_samples_leaf': 30}. Best is trial 0 with value: -0.6441660272739511.\n",
      "[I 2024-07-29 13:05:45,734] Trial 1 finished with value: -0.6999763900413865 and parameters: {'n_estimators': 79, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 44}. Best is trial 0 with value: -0.6441660272739511.\n",
      "[I 2024-07-29 13:05:46,981] Trial 2 finished with value: -0.7119319769361262 and parameters: {'n_estimators': 301, 'max_depth': 36, 'min_samples_split': 3, 'min_samples_leaf': 49}. Best is trial 0 with value: -0.6441660272739511.\n",
      "[I 2024-07-29 13:05:49,193] Trial 3 finished with value: -0.5010318009388504 and parameters: {'n_estimators': 417, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:05:49,889] Trial 4 finished with value: -0.5491613096621354 and parameters: {'n_estimators': 153, 'max_depth': 27, 'min_samples_split': 23, 'min_samples_leaf': 15}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:05:51,117] Trial 5 finished with value: -0.5851421770488705 and parameters: {'n_estimators': 307, 'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 19}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:05:52,163] Trial 6 finished with value: -0.6237160739203308 and parameters: {'n_estimators': 229, 'max_depth': 40, 'min_samples_split': 11, 'min_samples_leaf': 26}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:05:53,428] Trial 7 finished with value: -0.5570938268734259 and parameters: {'n_estimators': 297, 'max_depth': 4, 'min_samples_split': 31, 'min_samples_leaf': 9}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:05:53,585] Trial 8 finished with value: -0.6929038463139084 and parameters: {'n_estimators': 34, 'max_depth': 48, 'min_samples_split': 49, 'min_samples_leaf': 41}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:05:54,391] Trial 9 finished with value: -0.6085647134437722 and parameters: {'n_estimators': 154, 'max_depth': 6, 'min_samples_split': 35, 'min_samples_leaf': 23}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:05:54,634] Trial 10 finished with value: -0.707836115285591 and parameters: {'n_estimators': 62, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 46}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:05:55,153] Trial 11 finished with value: -0.6267059863104519 and parameters: {'n_estimators': 131, 'max_depth': 34, 'min_samples_split': 17, 'min_samples_leaf': 27}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:05:56,135] Trial 12 finished with value: -0.6783189901003966 and parameters: {'n_estimators': 274, 'max_depth': 11, 'min_samples_split': 49, 'min_samples_leaf': 39}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:05:57,716] Trial 13 finished with value: -0.705220194429328 and parameters: {'n_estimators': 470, 'max_depth': 45, 'min_samples_split': 31, 'min_samples_leaf': 47}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:05:58,088] Trial 14 finished with value: -0.570973646137171 and parameters: {'n_estimators': 46, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 17}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:05:58,811] Trial 15 finished with value: -0.5866928895959154 and parameters: {'n_estimators': 195, 'max_depth': 15, 'min_samples_split': 42, 'min_samples_leaf': 18}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:05:59,369] Trial 16 finished with value: -0.690888339727399 and parameters: {'n_estimators': 142, 'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 41}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:05:59,546] Trial 17 finished with value: -0.5416475376558136 and parameters: {'n_estimators': 39, 'max_depth': 50, 'min_samples_split': 39, 'min_samples_leaf': 10}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:05:59,588] Trial 18 finished with value: -0.7202894009186471 and parameters: {'n_estimators': 4, 'max_depth': 41, 'min_samples_split': 36, 'min_samples_leaf': 37}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:06:01,414] Trial 19 finished with value: -0.5028295408221818 and parameters: {'n_estimators': 386, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 6}. Best is trial 3 with value: -0.5010318009388504.\n",
      "[I 2024-07-29 13:06:04,031] Trial 20 finished with value: -0.4560467347121698 and parameters: {'n_estimators': 432, 'max_depth': 32, 'min_samples_split': 18, 'min_samples_leaf': 4}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:04,716] Trial 21 finished with value: -0.6554757436974417 and parameters: {'n_estimators': 157, 'max_depth': 17, 'min_samples_split': 37, 'min_samples_leaf': 32}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:06,371] Trial 22 finished with value: -0.6715003887728838 and parameters: {'n_estimators': 444, 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 36}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:07,735] Trial 23 finished with value: -0.6188002362165185 and parameters: {'n_estimators': 381, 'max_depth': 29, 'min_samples_split': 39, 'min_samples_leaf': 25}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:09,840] Trial 24 finished with value: -0.4574726958788863 and parameters: {'n_estimators': 262, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:09,946] Trial 25 finished with value: -0.6304983679970209 and parameters: {'n_estimators': 17, 'max_depth': 33, 'min_samples_split': 17, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:11,810] Trial 26 finished with value: -0.6772458165428096 and parameters: {'n_estimators': 454, 'max_depth': 14, 'min_samples_split': 22, 'min_samples_leaf': 38}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:12,388] Trial 27 finished with value: -0.5207486875768519 and parameters: {'n_estimators': 116, 'max_depth': 5, 'min_samples_split': 16, 'min_samples_leaf': 9}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:14,105] Trial 28 finished with value: -0.6982097012271449 and parameters: {'n_estimators': 465, 'max_depth': 41, 'min_samples_split': 33, 'min_samples_leaf': 44}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:15,624] Trial 29 finished with value: -0.6304033901069277 and parameters: {'n_estimators': 403, 'max_depth': 11, 'min_samples_split': 45, 'min_samples_leaf': 27}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:17,774] Trial 30 finished with value: -0.46400885637195666 and parameters: {'n_estimators': 404, 'max_depth': 45, 'min_samples_split': 17, 'min_samples_leaf': 6}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:18,192] Trial 31 finished with value: -0.6943744044294591 and parameters: {'n_estimators': 115, 'max_depth': 22, 'min_samples_split': 42, 'min_samples_leaf': 44}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:18,244] Trial 32 finished with value: -0.5644706873403911 and parameters: {'n_estimators': 5, 'max_depth': 27, 'min_samples_split': 22, 'min_samples_leaf': 12}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:18,525] Trial 33 finished with value: -0.5843735150477685 and parameters: {'n_estimators': 61, 'max_depth': 18, 'min_samples_split': 48, 'min_samples_leaf': 17}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:19,403] Trial 34 finished with value: -0.7101215157322311 and parameters: {'n_estimators': 260, 'max_depth': 36, 'min_samples_split': 19, 'min_samples_leaf': 49}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:21,564] Trial 35 finished with value: -0.5559466883089146 and parameters: {'n_estimators': 482, 'max_depth': 14, 'min_samples_split': 26, 'min_samples_leaf': 16}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:22,352] Trial 36 finished with value: -0.6459821881514884 and parameters: {'n_estimators': 144, 'max_depth': 3, 'min_samples_split': 31, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:22,516] Trial 37 finished with value: -0.5620382551344012 and parameters: {'n_estimators': 27, 'max_depth': 15, 'min_samples_split': 46, 'min_samples_leaf': 12}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:22,816] Trial 38 finished with value: -0.5854325275565307 and parameters: {'n_estimators': 74, 'max_depth': 25, 'min_samples_split': 50, 'min_samples_leaf': 13}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:24,307] Trial 39 finished with value: -0.675743072908274 and parameters: {'n_estimators': 337, 'max_depth': 39, 'min_samples_split': 13, 'min_samples_leaf': 37}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:25,059] Trial 40 finished with value: -0.6274173749415893 and parameters: {'n_estimators': 185, 'max_depth': 32, 'min_samples_split': 33, 'min_samples_leaf': 27}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:25,327] Trial 41 finished with value: -0.5089537203193564 and parameters: {'n_estimators': 47, 'max_depth': 42, 'min_samples_split': 17, 'min_samples_leaf': 10}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:25,461] Trial 42 finished with value: -0.505265731793969 and parameters: {'n_estimators': 22, 'max_depth': 30, 'min_samples_split': 35, 'min_samples_leaf': 1}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:26,659] Trial 43 finished with value: -0.5230496464493528 and parameters: {'n_estimators': 257, 'max_depth': 13, 'min_samples_split': 33, 'min_samples_leaf': 9}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:28,295] Trial 44 finished with value: -0.5512371002149175 and parameters: {'n_estimators': 346, 'max_depth': 20, 'min_samples_split': 47, 'min_samples_leaf': 7}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:28,911] Trial 45 finished with value: -0.6979374656588984 and parameters: {'n_estimators': 172, 'max_depth': 7, 'min_samples_split': 47, 'min_samples_leaf': 44}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:29,489] Trial 46 finished with value: -0.6316037408672945 and parameters: {'n_estimators': 130, 'max_depth': 34, 'min_samples_split': 42, 'min_samples_leaf': 28}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:30,564] Trial 47 finished with value: -0.7000129659778003 and parameters: {'n_estimators': 266, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 45}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:32,876] Trial 48 finished with value: -0.5746854754090844 and parameters: {'n_estimators': 451, 'max_depth': 33, 'min_samples_split': 18, 'min_samples_leaf': 18}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:34,276] Trial 49 finished with value: -0.6805555661143982 and parameters: {'n_estimators': 364, 'max_depth': 45, 'min_samples_split': 45, 'min_samples_leaf': 39}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:35,366] Trial 50 finished with value: -0.7032715190533974 and parameters: {'n_estimators': 322, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 45}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:36,662] Trial 51 finished with value: -0.7019263376258299 and parameters: {'n_estimators': 304, 'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 34}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:36,708] Trial 52 finished with value: -0.6851214453565178 and parameters: {'n_estimators': 4, 'max_depth': 9, 'min_samples_split': 28, 'min_samples_leaf': 35}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:38,330] Trial 53 finished with value: -0.5393450897712004 and parameters: {'n_estimators': 327, 'max_depth': 12, 'min_samples_split': 36, 'min_samples_leaf': 12}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:39,086] Trial 54 finished with value: -0.6939079923892917 and parameters: {'n_estimators': 164, 'max_depth': 38, 'min_samples_split': 33, 'min_samples_leaf': 43}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:40,560] Trial 55 finished with value: -0.5837091355447097 and parameters: {'n_estimators': 330, 'max_depth': 29, 'min_samples_split': 6, 'min_samples_leaf': 19}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:41,359] Trial 56 finished with value: -0.6041124891566124 and parameters: {'n_estimators': 134, 'max_depth': 13, 'min_samples_split': 49, 'min_samples_leaf': 20}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:43,921] Trial 57 finished with value: -0.6213622134685053 and parameters: {'n_estimators': 447, 'max_depth': 32, 'min_samples_split': 40, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:45,156] Trial 58 finished with value: -0.6722271413394534 and parameters: {'n_estimators': 289, 'max_depth': 26, 'min_samples_split': 11, 'min_samples_leaf': 37}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:45,814] Trial 59 finished with value: -0.6090653166270188 and parameters: {'n_estimators': 142, 'max_depth': 3, 'min_samples_split': 33, 'min_samples_leaf': 9}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:49,090] Trial 60 finished with value: -0.5938094282539537 and parameters: {'n_estimators': 471, 'max_depth': 48, 'min_samples_split': 46, 'min_samples_leaf': 19}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:49,171] Trial 61 finished with value: -0.7171437033094687 and parameters: {'n_estimators': 9, 'max_depth': 47, 'min_samples_split': 22, 'min_samples_leaf': 49}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:51,282] Trial 62 finished with value: -0.5909331491966613 and parameters: {'n_estimators': 482, 'max_depth': 43, 'min_samples_split': 16, 'min_samples_leaf': 20}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:53,496] Trial 63 finished with value: -0.637394352887825 and parameters: {'n_estimators': 426, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 28}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:56,176] Trial 64 finished with value: -0.4946560537580755 and parameters: {'n_estimators': 469, 'max_depth': 36, 'min_samples_split': 29, 'min_samples_leaf': 5}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:57,680] Trial 65 finished with value: -0.6242656957024592 and parameters: {'n_estimators': 308, 'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:06:59,756] Trial 66 finished with value: -0.667929615928837 and parameters: {'n_estimators': 439, 'max_depth': 38, 'min_samples_split': 36, 'min_samples_leaf': 36}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:07:00,536] Trial 67 finished with value: -0.6885668197826933 and parameters: {'n_estimators': 181, 'max_depth': 16, 'min_samples_split': 41, 'min_samples_leaf': 41}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:07:02,816] Trial 68 finished with value: -0.6284197330295603 and parameters: {'n_estimators': 434, 'max_depth': 46, 'min_samples_split': 27, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:07:04,672] Trial 69 finished with value: -0.6841902077433362 and parameters: {'n_estimators': 400, 'max_depth': 33, 'min_samples_split': 36, 'min_samples_leaf': 40}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:07:07,212] Trial 70 finished with value: -0.46918373199870017 and parameters: {'n_estimators': 446, 'max_depth': 18, 'min_samples_split': 20, 'min_samples_leaf': 5}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:07:08,760] Trial 71 finished with value: -0.6540531661678266 and parameters: {'n_estimators': 290, 'max_depth': 3, 'min_samples_split': 24, 'min_samples_leaf': 28}. Best is trial 20 with value: -0.4560467347121698.\n",
      "[I 2024-07-29 13:07:09,905] Trial 72 finished with value: -0.39624870446964333 and parameters: {'n_estimators': 144, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:11,807] Trial 73 finished with value: -0.6271197342108839 and parameters: {'n_estimators': 412, 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 27}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:13,831] Trial 74 finished with value: -0.5007204608638236 and parameters: {'n_estimators': 386, 'max_depth': 12, 'min_samples_split': 32, 'min_samples_leaf': 5}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:13,971] Trial 75 finished with value: -0.6492731015711066 and parameters: {'n_estimators': 27, 'max_depth': 28, 'min_samples_split': 28, 'min_samples_leaf': 32}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:15,404] Trial 76 finished with value: -0.5686236973698061 and parameters: {'n_estimators': 364, 'max_depth': 49, 'min_samples_split': 27, 'min_samples_leaf': 17}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:17,216] Trial 77 finished with value: -0.4731930064552367 and parameters: {'n_estimators': 398, 'max_depth': 15, 'min_samples_split': 23, 'min_samples_leaf': 4}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:17,292] Trial 78 finished with value: -0.6550007621590048 and parameters: {'n_estimators': 14, 'max_depth': 49, 'min_samples_split': 42, 'min_samples_leaf': 35}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:18,119] Trial 79 finished with value: -0.5315811952936109 and parameters: {'n_estimators': 206, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 13}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:19,175] Trial 80 finished with value: -0.5461949760232636 and parameters: {'n_estimators': 276, 'max_depth': 37, 'min_samples_split': 34, 'min_samples_leaf': 14}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:20,937] Trial 81 finished with value: -0.6484653700087178 and parameters: {'n_estimators': 478, 'max_depth': 38, 'min_samples_split': 29, 'min_samples_leaf': 31}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:21,908] Trial 82 finished with value: -0.6804567329625827 and parameters: {'n_estimators': 211, 'max_depth': 14, 'min_samples_split': 19, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:22,055] Trial 83 finished with value: -0.4415209651080764 and parameters: {'n_estimators': 9, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:24,181] Trial 84 finished with value: -0.48377151122798445 and parameters: {'n_estimators': 428, 'max_depth': 36, 'min_samples_split': 25, 'min_samples_leaf': 5}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:25,079] Trial 85 finished with value: -0.6007707585464537 and parameters: {'n_estimators': 247, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 22}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:25,818] Trial 86 finished with value: -0.4948108098995756 and parameters: {'n_estimators': 200, 'max_depth': 32, 'min_samples_split': 33, 'min_samples_leaf': 3}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:26,464] Trial 87 finished with value: -0.6949205814664879 and parameters: {'n_estimators': 188, 'max_depth': 32, 'min_samples_split': 26, 'min_samples_leaf': 43}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:27,515] Trial 88 finished with value: -0.6589591713038939 and parameters: {'n_estimators': 330, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 33}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:27,593] Trial 89 finished with value: -0.6486557750033535 and parameters: {'n_estimators': 15, 'max_depth': 30, 'min_samples_split': 48, 'min_samples_leaf': 29}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:28,307] Trial 90 finished with value: -0.6348719619843746 and parameters: {'n_estimators': 195, 'max_depth': 33, 'min_samples_split': 24, 'min_samples_leaf': 28}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:30,494] Trial 91 finished with value: -0.7044706134365588 and parameters: {'n_estimators': 471, 'max_depth': 20, 'min_samples_split': 49, 'min_samples_leaf': 46}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:31,089] Trial 92 finished with value: -0.46461217745090966 and parameters: {'n_estimators': 99, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:31,324] Trial 93 finished with value: -0.5646020068244179 and parameters: {'n_estimators': 49, 'max_depth': 35, 'min_samples_split': 5, 'min_samples_leaf': 16}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:33,138] Trial 94 finished with value: -0.6251659784776955 and parameters: {'n_estimators': 423, 'max_depth': 3, 'min_samples_split': 41, 'min_samples_leaf': 15}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:33,374] Trial 95 finished with value: -0.6991662561404492 and parameters: {'n_estimators': 60, 'max_depth': 36, 'min_samples_split': 32, 'min_samples_leaf': 44}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:35,723] Trial 96 finished with value: -0.49228927635128866 and parameters: {'n_estimators': 368, 'max_depth': 41, 'min_samples_split': 15, 'min_samples_leaf': 9}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:37,102] Trial 97 finished with value: -0.6050052752295081 and parameters: {'n_estimators': 376, 'max_depth': 41, 'min_samples_split': 50, 'min_samples_leaf': 21}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:37,740] Trial 98 finished with value: -0.7050264393288211 and parameters: {'n_estimators': 187, 'max_depth': 40, 'min_samples_split': 18, 'min_samples_leaf': 47}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:39,202] Trial 99 finished with value: -0.6754353806401182 and parameters: {'n_estimators': 430, 'max_depth': 23, 'min_samples_split': 38, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:39,410] Trial 100 finished with value: -0.6874643743260379 and parameters: {'n_estimators': 53, 'max_depth': 46, 'min_samples_split': 26, 'min_samples_leaf': 42}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:40,197] Trial 101 finished with value: -0.4464821685765922 and parameters: {'n_estimators': 161, 'max_depth': 45, 'min_samples_split': 21, 'min_samples_leaf': 1}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:41,576] Trial 102 finished with value: -0.7070247460034913 and parameters: {'n_estimators': 453, 'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 48}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:43,421] Trial 103 finished with value: -0.6121106145481889 and parameters: {'n_estimators': 476, 'max_depth': 30, 'min_samples_split': 32, 'min_samples_leaf': 23}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:43,944] Trial 104 finished with value: -0.6783760418524705 and parameters: {'n_estimators': 148, 'max_depth': 18, 'min_samples_split': 34, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:45,627] Trial 105 finished with value: -0.6201658333692308 and parameters: {'n_estimators': 396, 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 25}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:45,744] Trial 106 finished with value: -0.7052736804426676 and parameters: {'n_estimators': 30, 'max_depth': 28, 'min_samples_split': 23, 'min_samples_leaf': 45}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:46,384] Trial 107 finished with value: -0.6796276723733977 and parameters: {'n_estimators': 177, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 39}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:47,408] Trial 108 finished with value: -0.6688993752776037 and parameters: {'n_estimators': 310, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 36}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:47,592] Trial 109 finished with value: -0.5088552775981954 and parameters: {'n_estimators': 38, 'max_depth': 42, 'min_samples_split': 36, 'min_samples_leaf': 5}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:47,766] Trial 110 finished with value: -0.5961552920802042 and parameters: {'n_estimators': 44, 'max_depth': 50, 'min_samples_split': 20, 'min_samples_leaf': 19}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:49,566] Trial 111 finished with value: -0.674548024705488 and parameters: {'n_estimators': 407, 'max_depth': 48, 'min_samples_split': 50, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:50,711] Trial 112 finished with value: -0.6351159861278226 and parameters: {'n_estimators': 189, 'max_depth': 6, 'min_samples_split': 40, 'min_samples_leaf': 28}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:51,566] Trial 113 finished with value: -0.6231315524028306 and parameters: {'n_estimators': 213, 'max_depth': 46, 'min_samples_split': 7, 'min_samples_leaf': 25}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:51,730] Trial 114 finished with value: -0.5000955733071453 and parameters: {'n_estimators': 7, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:52,171] Trial 115 finished with value: -0.6518434267499027 and parameters: {'n_estimators': 60, 'max_depth': 33, 'min_samples_split': 38, 'min_samples_leaf': 30}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:54,272] Trial 116 finished with value: -0.6968229413821893 and parameters: {'n_estimators': 482, 'max_depth': 20, 'min_samples_split': 15, 'min_samples_leaf': 44}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:54,660] Trial 117 finished with value: -0.7124019336818839 and parameters: {'n_estimators': 113, 'max_depth': 49, 'min_samples_split': 2, 'min_samples_leaf': 49}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:54,759] Trial 118 finished with value: -0.7238919363972987 and parameters: {'n_estimators': 23, 'max_depth': 45, 'min_samples_split': 27, 'min_samples_leaf': 50}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:54,915] Trial 119 finished with value: -0.6311289551322142 and parameters: {'n_estimators': 38, 'max_depth': 29, 'min_samples_split': 49, 'min_samples_leaf': 27}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:56,233] Trial 120 finished with value: -0.6550425794662026 and parameters: {'n_estimators': 316, 'max_depth': 36, 'min_samples_split': 24, 'min_samples_leaf': 32}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:57,585] Trial 121 finished with value: -0.5434179787079298 and parameters: {'n_estimators': 293, 'max_depth': 46, 'min_samples_split': 4, 'min_samples_leaf': 15}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:07:59,443] Trial 122 finished with value: -0.6540088030751958 and parameters: {'n_estimators': 476, 'max_depth': 45, 'min_samples_split': 24, 'min_samples_leaf': 32}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:08:00,024] Trial 123 finished with value: -0.5732274408290651 and parameters: {'n_estimators': 140, 'max_depth': 11, 'min_samples_split': 24, 'min_samples_leaf': 18}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:08:00,966] Trial 124 finished with value: -0.7103758867662742 and parameters: {'n_estimators': 293, 'max_depth': 5, 'min_samples_split': 49, 'min_samples_leaf': 50}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:08:02,209] Trial 125 finished with value: -0.6880265676040549 and parameters: {'n_estimators': 350, 'max_depth': 28, 'min_samples_split': 17, 'min_samples_leaf': 41}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:08:03,860] Trial 126 finished with value: -0.6952404305167507 and parameters: {'n_estimators': 343, 'max_depth': 9, 'min_samples_split': 46, 'min_samples_leaf': 42}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:08:05,947] Trial 127 finished with value: -0.599811437086317 and parameters: {'n_estimators': 475, 'max_depth': 37, 'min_samples_split': 32, 'min_samples_leaf': 21}. Best is trial 72 with value: -0.39624870446964333.\n",
      "[I 2024-07-29 13:08:09,041] Trial 128 finished with value: -0.3958956314053652 and parameters: {'n_estimators': 467, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 128 with value: -0.3958956314053652.\n",
      "[I 2024-07-29 13:08:09,804] Trial 129 finished with value: -0.5599000295049013 and parameters: {'n_estimators': 189, 'max_depth': 41, 'min_samples_split': 50, 'min_samples_leaf': 8}. Best is trial 128 with value: -0.3958956314053652.\n",
      "[I 2024-07-29 13:08:10,797] Trial 130 finished with value: -0.6931529028820816 and parameters: {'n_estimators': 298, 'max_depth': 20, 'min_samples_split': 49, 'min_samples_leaf': 43}. Best is trial 128 with value: -0.3958956314053652.\n",
      "[I 2024-07-29 13:08:12,906] Trial 131 finished with value: -0.5391398528497987 and parameters: {'n_estimators': 420, 'max_depth': 24, 'min_samples_split': 22, 'min_samples_leaf': 14}. Best is trial 128 with value: -0.3958956314053652.\n",
      "[I 2024-07-29 13:08:13,045] Trial 132 finished with value: -0.7134446893460888 and parameters: {'n_estimators': 30, 'max_depth': 44, 'min_samples_split': 41, 'min_samples_leaf': 50}. Best is trial 128 with value: -0.3958956314053652.\n",
      "[I 2024-07-29 13:08:15,084] Trial 133 finished with value: -0.7073874510612406 and parameters: {'n_estimators': 499, 'max_depth': 29, 'min_samples_split': 39, 'min_samples_leaf': 48}. Best is trial 128 with value: -0.3958956314053652.\n",
      "[I 2024-07-29 13:08:17,202] Trial 134 finished with value: -0.49126859060866723 and parameters: {'n_estimators': 425, 'max_depth': 14, 'min_samples_split': 24, 'min_samples_leaf': 7}. Best is trial 128 with value: -0.3958956314053652.\n",
      "[I 2024-07-29 13:08:19,675] Trial 135 finished with value: -0.6634611201352824 and parameters: {'n_estimators': 478, 'max_depth': 31, 'min_samples_split': 13, 'min_samples_leaf': 34}. Best is trial 128 with value: -0.3958956314053652.\n",
      "[I 2024-07-29 13:08:21,110] Trial 136 finished with value: -0.6633331920823142 and parameters: {'n_estimators': 310, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 34}. Best is trial 128 with value: -0.3958956314053652.\n",
      "[I 2024-07-29 13:08:22,205] Trial 137 finished with value: -0.695026235110605 and parameters: {'n_estimators': 261, 'max_depth': 39, 'min_samples_split': 27, 'min_samples_leaf': 43}. Best is trial 128 with value: -0.3958956314053652.\n",
      "[I 2024-07-29 13:08:23,340] Trial 138 finished with value: -0.6004810298289032 and parameters: {'n_estimators': 277, 'max_depth': 29, 'min_samples_split': 44, 'min_samples_leaf': 21}. Best is trial 128 with value: -0.3958956314053652.\n",
      "[I 2024-07-29 13:08:23,619] Trial 139 finished with value: -0.6664762139195092 and parameters: {'n_estimators': 68, 'max_depth': 3, 'min_samples_split': 39, 'min_samples_leaf': 32}. Best is trial 128 with value: -0.3958956314053652.\n",
      "[I 2024-07-29 13:08:26,160] Trial 140 finished with value: -0.39487989823559305 and parameters: {'n_estimators': 353, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:27,078] Trial 141 finished with value: -0.6038111979594185 and parameters: {'n_estimators': 176, 'max_depth': 30, 'min_samples_split': 21, 'min_samples_leaf': 22}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:29,024] Trial 142 finished with value: -0.6855204555584754 and parameters: {'n_estimators': 453, 'max_depth': 19, 'min_samples_split': 27, 'min_samples_leaf': 40}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:29,725] Trial 143 finished with value: -0.7092712928237049 and parameters: {'n_estimators': 199, 'max_depth': 32, 'min_samples_split': 44, 'min_samples_leaf': 48}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:30,248] Trial 144 finished with value: -0.533069862917488 and parameters: {'n_estimators': 75, 'max_depth': 47, 'min_samples_split': 26, 'min_samples_leaf': 13}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:31,395] Trial 145 finished with value: -0.5668425987310992 and parameters: {'n_estimators': 231, 'max_depth': 50, 'min_samples_split': 26, 'min_samples_leaf': 17}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:33,130] Trial 146 finished with value: -0.47150953316295163 and parameters: {'n_estimators': 318, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:33,409] Trial 147 finished with value: -0.6585205558987375 and parameters: {'n_estimators': 65, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 33}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:33,921] Trial 148 finished with value: -0.6158755870696553 and parameters: {'n_estimators': 92, 'max_depth': 18, 'min_samples_split': 45, 'min_samples_leaf': 24}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:36,132] Trial 149 finished with value: -0.42830840887265714 and parameters: {'n_estimators': 335, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:36,622] Trial 150 finished with value: -0.44811063218227815 and parameters: {'n_estimators': 86, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:36,892] Trial 151 finished with value: -0.5783574101565907 and parameters: {'n_estimators': 62, 'max_depth': 24, 'min_samples_split': 12, 'min_samples_leaf': 19}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:37,754] Trial 152 finished with value: -0.6833924793993896 and parameters: {'n_estimators': 253, 'max_depth': 35, 'min_samples_split': 3, 'min_samples_leaf': 40}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:38,801] Trial 153 finished with value: -0.705267730467517 and parameters: {'n_estimators': 315, 'max_depth': 6, 'min_samples_split': 44, 'min_samples_leaf': 47}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:38,944] Trial 154 finished with value: -0.6756236436014235 and parameters: {'n_estimators': 32, 'max_depth': 15, 'min_samples_split': 41, 'min_samples_leaf': 38}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:39,399] Trial 155 finished with value: -0.6212484482916806 and parameters: {'n_estimators': 94, 'max_depth': 12, 'min_samples_split': 20, 'min_samples_leaf': 25}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:40,497] Trial 156 finished with value: -0.6702593937001395 and parameters: {'n_estimators': 310, 'max_depth': 20, 'min_samples_split': 24, 'min_samples_leaf': 38}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:40,592] Trial 157 finished with value: -0.7091084780754484 and parameters: {'n_estimators': 20, 'max_depth': 14, 'min_samples_split': 36, 'min_samples_leaf': 45}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:41,792] Trial 158 finished with value: -0.6090024959702438 and parameters: {'n_estimators': 257, 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 23}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:43,077] Trial 159 finished with value: -0.580758353606784 and parameters: {'n_estimators': 267, 'max_depth': 13, 'min_samples_split': 15, 'min_samples_leaf': 19}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:43,146] Trial 160 finished with value: -0.5720400320267871 and parameters: {'n_estimators': 12, 'max_depth': 17, 'min_samples_split': 12, 'min_samples_leaf': 17}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:43,339] Trial 161 finished with value: -0.6676935149134151 and parameters: {'n_estimators': 61, 'max_depth': 45, 'min_samples_split': 31, 'min_samples_leaf': 34}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:45,030] Trial 162 finished with value: -0.6316513392797234 and parameters: {'n_estimators': 395, 'max_depth': 26, 'min_samples_split': 6, 'min_samples_leaf': 27}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:46,614] Trial 163 finished with value: -0.4892756106600181 and parameters: {'n_estimators': 294, 'max_depth': 38, 'min_samples_split': 23, 'min_samples_leaf': 7}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:47,238] Trial 164 finished with value: -0.6378985376414158 and parameters: {'n_estimators': 143, 'max_depth': 19, 'min_samples_split': 33, 'min_samples_leaf': 29}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:48,227] Trial 165 finished with value: -0.5305427686699924 and parameters: {'n_estimators': 179, 'max_depth': 50, 'min_samples_split': 31, 'min_samples_leaf': 12}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:48,709] Trial 166 finished with value: -0.48708601169703647 and parameters: {'n_estimators': 52, 'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 9}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:49,210] Trial 167 finished with value: -0.7004644674993885 and parameters: {'n_estimators': 95, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 45}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:49,480] Trial 168 finished with value: -0.7118452901033169 and parameters: {'n_estimators': 42, 'max_depth': 27, 'min_samples_split': 22, 'min_samples_leaf': 50}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:49,789] Trial 169 finished with value: -0.7030374290972232 and parameters: {'n_estimators': 57, 'max_depth': 21, 'min_samples_split': 49, 'min_samples_leaf': 44}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:52,068] Trial 170 finished with value: -0.6599151793667947 and parameters: {'n_estimators': 409, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 34}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:54,423] Trial 171 finished with value: -0.5389908870515202 and parameters: {'n_estimators': 465, 'max_depth': 29, 'min_samples_split': 30, 'min_samples_leaf': 14}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:56,410] Trial 172 finished with value: -0.6036637178121166 and parameters: {'n_estimators': 385, 'max_depth': 11, 'min_samples_split': 17, 'min_samples_leaf': 22}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:57,654] Trial 173 finished with value: -0.6491877044936233 and parameters: {'n_estimators': 255, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 31}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:58,273] Trial 174 finished with value: -0.6204309879493206 and parameters: {'n_estimators': 146, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 25}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:08:59,888] Trial 175 finished with value: -0.5452469513226705 and parameters: {'n_estimators': 267, 'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 7}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:00,056] Trial 176 finished with value: -0.6891214612399252 and parameters: {'n_estimators': 33, 'max_depth': 50, 'min_samples_split': 17, 'min_samples_leaf': 41}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:00,662] Trial 177 finished with value: -0.6414029366627776 and parameters: {'n_estimators': 129, 'max_depth': 35, 'min_samples_split': 39, 'min_samples_leaf': 30}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:01,780] Trial 178 finished with value: -0.7063185363399116 and parameters: {'n_estimators': 237, 'max_depth': 22, 'min_samples_split': 19, 'min_samples_leaf': 47}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:03,699] Trial 179 finished with value: -0.6711337762405556 and parameters: {'n_estimators': 416, 'max_depth': 49, 'min_samples_split': 8, 'min_samples_leaf': 37}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:05,635] Trial 180 finished with value: -0.6766211693246036 and parameters: {'n_estimators': 470, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 38}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:06,757] Trial 181 finished with value: -0.6863405000445675 and parameters: {'n_estimators': 288, 'max_depth': 43, 'min_samples_split': 8, 'min_samples_leaf': 40}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:07,146] Trial 182 finished with value: -0.6889092378062618 and parameters: {'n_estimators': 102, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 41}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:08,260] Trial 183 finished with value: -0.6994043271152923 and parameters: {'n_estimators': 333, 'max_depth': 27, 'min_samples_split': 19, 'min_samples_leaf': 44}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:09,485] Trial 184 finished with value: -0.5814854036736387 and parameters: {'n_estimators': 197, 'max_depth': 42, 'min_samples_split': 23, 'min_samples_leaf': 19}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:10,397] Trial 185 finished with value: -0.6269877153579764 and parameters: {'n_estimators': 232, 'max_depth': 16, 'min_samples_split': 38, 'min_samples_leaf': 26}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:10,845] Trial 186 finished with value: -0.6394242563423056 and parameters: {'n_estimators': 117, 'max_depth': 46, 'min_samples_split': 20, 'min_samples_leaf': 28}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:12,419] Trial 187 finished with value: -0.7044561322972781 and parameters: {'n_estimators': 454, 'max_depth': 32, 'min_samples_split': 7, 'min_samples_leaf': 47}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:13,872] Trial 188 finished with value: -0.6832329726173901 and parameters: {'n_estimators': 315, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 40}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:15,281] Trial 189 finished with value: -0.6823346673197695 and parameters: {'n_estimators': 311, 'max_depth': 28, 'min_samples_split': 45, 'min_samples_leaf': 40}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:15,691] Trial 190 finished with value: -0.677471946619815 and parameters: {'n_estimators': 77, 'max_depth': 17, 'min_samples_split': 14, 'min_samples_leaf': 38}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:15,810] Trial 191 finished with value: -0.701775036549652 and parameters: {'n_estimators': 18, 'max_depth': 29, 'min_samples_split': 39, 'min_samples_leaf': 44}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:16,443] Trial 192 finished with value: -0.6951530661553671 and parameters: {'n_estimators': 172, 'max_depth': 42, 'min_samples_split': 7, 'min_samples_leaf': 43}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:16,743] Trial 193 finished with value: -0.5399393018852505 and parameters: {'n_estimators': 65, 'max_depth': 21, 'min_samples_split': 41, 'min_samples_leaf': 8}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:17,338] Trial 194 finished with value: -0.6613687658977028 and parameters: {'n_estimators': 116, 'max_depth': 37, 'min_samples_split': 37, 'min_samples_leaf': 33}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:19,146] Trial 195 finished with value: -0.5710411475503484 and parameters: {'n_estimators': 348, 'max_depth': 28, 'min_samples_split': 14, 'min_samples_leaf': 18}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:19,698] Trial 196 finished with value: -0.5993314186154638 and parameters: {'n_estimators': 92, 'max_depth': 46, 'min_samples_split': 30, 'min_samples_leaf': 21}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:20,842] Trial 197 finished with value: -0.6462532701847865 and parameters: {'n_estimators': 232, 'max_depth': 48, 'min_samples_split': 9, 'min_samples_leaf': 30}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:22,137] Trial 198 finished with value: -0.7001869884590209 and parameters: {'n_estimators': 254, 'max_depth': 31, 'min_samples_split': 2, 'min_samples_leaf': 44}. Best is trial 140 with value: -0.39487989823559305.\n",
      "[I 2024-07-29 13:09:24,442] Trial 199 finished with value: -0.7080070521248799 and parameters: {'n_estimators': 467, 'max_depth': 29, 'min_samples_split': 36, 'min_samples_leaf': 47}. Best is trial 140 with value: -0.39487989823559305.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "study_strat.optimize(lambda trial: objective(trial, np.array(list((x_train_strat))).astype(float), y_train_strat), n_trials=200, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db06430f5fe4b1ebb7212ea87979322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 13:09:25,545] Trial 0 finished with value: -0.7167219274670849 and parameters: {'n_estimators': 188, 'max_depth': 48, 'min_samples_split': 37, 'min_samples_leaf': 30}. Best is trial 0 with value: -0.7167219274670849.\n",
      "[I 2024-07-29 13:09:25,876] Trial 1 finished with value: -0.7477847211586006 and parameters: {'n_estimators': 79, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 44}. Best is trial 0 with value: -0.7167219274670849.\n",
      "[I 2024-07-29 13:09:27,017] Trial 2 finished with value: -0.7617869269563752 and parameters: {'n_estimators': 301, 'max_depth': 36, 'min_samples_split': 3, 'min_samples_leaf': 49}. Best is trial 0 with value: -0.7167219274670849.\n",
      "[I 2024-07-29 13:09:28,868] Trial 3 finished with value: -0.6053018149299224 and parameters: {'n_estimators': 417, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:29,592] Trial 4 finished with value: -0.6424199499177167 and parameters: {'n_estimators': 153, 'max_depth': 27, 'min_samples_split': 23, 'min_samples_leaf': 15}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:31,345] Trial 5 finished with value: -0.6674056524103291 and parameters: {'n_estimators': 307, 'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 19}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:32,593] Trial 6 finished with value: -0.6997804766504445 and parameters: {'n_estimators': 229, 'max_depth': 40, 'min_samples_split': 11, 'min_samples_leaf': 26}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:34,224] Trial 7 finished with value: -0.6657603639214342 and parameters: {'n_estimators': 297, 'max_depth': 4, 'min_samples_split': 31, 'min_samples_leaf': 9}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:34,434] Trial 8 finished with value: -0.738955048523169 and parameters: {'n_estimators': 34, 'max_depth': 48, 'min_samples_split': 49, 'min_samples_leaf': 41}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:35,293] Trial 9 finished with value: -0.6816475039267871 and parameters: {'n_estimators': 154, 'max_depth': 6, 'min_samples_split': 35, 'min_samples_leaf': 23}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:35,622] Trial 10 finished with value: -0.7512985127389558 and parameters: {'n_estimators': 62, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 46}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:36,385] Trial 11 finished with value: -0.6952237093357674 and parameters: {'n_estimators': 131, 'max_depth': 34, 'min_samples_split': 17, 'min_samples_leaf': 27}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:37,610] Trial 12 finished with value: -0.7448102099694489 and parameters: {'n_estimators': 274, 'max_depth': 11, 'min_samples_split': 49, 'min_samples_leaf': 39}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:40,124] Trial 13 finished with value: -0.74864281205397 and parameters: {'n_estimators': 470, 'max_depth': 45, 'min_samples_split': 31, 'min_samples_leaf': 47}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:40,483] Trial 14 finished with value: -0.6488683714521957 and parameters: {'n_estimators': 46, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 17}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:41,482] Trial 15 finished with value: -0.6669292290714042 and parameters: {'n_estimators': 195, 'max_depth': 15, 'min_samples_split': 42, 'min_samples_leaf': 18}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:42,052] Trial 16 finished with value: -0.7456820874638427 and parameters: {'n_estimators': 142, 'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 41}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:42,251] Trial 17 finished with value: -0.6305247244018364 and parameters: {'n_estimators': 39, 'max_depth': 50, 'min_samples_split': 39, 'min_samples_leaf': 10}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:42,314] Trial 18 finished with value: -0.762492805163675 and parameters: {'n_estimators': 4, 'max_depth': 41, 'min_samples_split': 36, 'min_samples_leaf': 37}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:44,818] Trial 19 finished with value: -0.6242777045086138 and parameters: {'n_estimators': 386, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 6}. Best is trial 3 with value: -0.6053018149299224.\n",
      "[I 2024-07-29 13:09:47,660] Trial 20 finished with value: -0.5747656317115487 and parameters: {'n_estimators': 432, 'max_depth': 32, 'min_samples_split': 18, 'min_samples_leaf': 4}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:09:48,807] Trial 21 finished with value: -0.7262574107675791 and parameters: {'n_estimators': 157, 'max_depth': 17, 'min_samples_split': 37, 'min_samples_leaf': 32}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:09:50,686] Trial 22 finished with value: -0.7410786381861099 and parameters: {'n_estimators': 444, 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 36}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:09:52,350] Trial 23 finished with value: -0.686297322190636 and parameters: {'n_estimators': 381, 'max_depth': 29, 'min_samples_split': 39, 'min_samples_leaf': 25}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:09:53,942] Trial 24 finished with value: -0.5774379631696436 and parameters: {'n_estimators': 262, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:09:54,043] Trial 25 finished with value: -0.7020728114830588 and parameters: {'n_estimators': 17, 'max_depth': 33, 'min_samples_split': 17, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:09:55,938] Trial 26 finished with value: -0.7441347901263881 and parameters: {'n_estimators': 454, 'max_depth': 14, 'min_samples_split': 22, 'min_samples_leaf': 38}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:09:56,471] Trial 27 finished with value: -0.6306002969709523 and parameters: {'n_estimators': 116, 'max_depth': 5, 'min_samples_split': 16, 'min_samples_leaf': 9}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:09:58,496] Trial 28 finished with value: -0.7470452449259881 and parameters: {'n_estimators': 465, 'max_depth': 41, 'min_samples_split': 33, 'min_samples_leaf': 44}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:00,092] Trial 29 finished with value: -0.7025316769685029 and parameters: {'n_estimators': 403, 'max_depth': 11, 'min_samples_split': 45, 'min_samples_leaf': 27}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:02,314] Trial 30 finished with value: -0.5896693928558593 and parameters: {'n_estimators': 404, 'max_depth': 45, 'min_samples_split': 17, 'min_samples_leaf': 6}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:02,749] Trial 31 finished with value: -0.756389567770708 and parameters: {'n_estimators': 115, 'max_depth': 22, 'min_samples_split': 42, 'min_samples_leaf': 44}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:02,822] Trial 32 finished with value: -0.6073365463973388 and parameters: {'n_estimators': 5, 'max_depth': 27, 'min_samples_split': 22, 'min_samples_leaf': 12}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:03,126] Trial 33 finished with value: -0.6697596627935194 and parameters: {'n_estimators': 61, 'max_depth': 18, 'min_samples_split': 48, 'min_samples_leaf': 17}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:04,176] Trial 34 finished with value: -0.752714840903552 and parameters: {'n_estimators': 260, 'max_depth': 36, 'min_samples_split': 19, 'min_samples_leaf': 49}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:06,591] Trial 35 finished with value: -0.6458495080374409 and parameters: {'n_estimators': 482, 'max_depth': 14, 'min_samples_split': 26, 'min_samples_leaf': 16}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:07,252] Trial 36 finished with value: -0.7268493930908195 and parameters: {'n_estimators': 144, 'max_depth': 3, 'min_samples_split': 31, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:07,387] Trial 37 finished with value: -0.6550656880905128 and parameters: {'n_estimators': 27, 'max_depth': 15, 'min_samples_split': 46, 'min_samples_leaf': 12}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:07,720] Trial 38 finished with value: -0.6597122485693057 and parameters: {'n_estimators': 74, 'max_depth': 25, 'min_samples_split': 50, 'min_samples_leaf': 13}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:09,164] Trial 39 finished with value: -0.7456574473160262 and parameters: {'n_estimators': 337, 'max_depth': 39, 'min_samples_split': 13, 'min_samples_leaf': 37}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:10,039] Trial 40 finished with value: -0.6944637998558694 and parameters: {'n_estimators': 185, 'max_depth': 32, 'min_samples_split': 33, 'min_samples_leaf': 27}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:10,306] Trial 41 finished with value: -0.6255450433254579 and parameters: {'n_estimators': 47, 'max_depth': 42, 'min_samples_split': 17, 'min_samples_leaf': 10}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:10,442] Trial 42 finished with value: -0.6027390988307086 and parameters: {'n_estimators': 22, 'max_depth': 30, 'min_samples_split': 35, 'min_samples_leaf': 1}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:11,953] Trial 43 finished with value: -0.6297588144076962 and parameters: {'n_estimators': 257, 'max_depth': 13, 'min_samples_split': 33, 'min_samples_leaf': 9}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:14,111] Trial 44 finished with value: -0.6372840642971684 and parameters: {'n_estimators': 346, 'max_depth': 20, 'min_samples_split': 47, 'min_samples_leaf': 7}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:14,875] Trial 45 finished with value: -0.7514257857331512 and parameters: {'n_estimators': 172, 'max_depth': 7, 'min_samples_split': 47, 'min_samples_leaf': 44}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:15,507] Trial 46 finished with value: -0.7099692958390118 and parameters: {'n_estimators': 130, 'max_depth': 34, 'min_samples_split': 42, 'min_samples_leaf': 28}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:16,796] Trial 47 finished with value: -0.7454815936175356 and parameters: {'n_estimators': 266, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 45}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:19,033] Trial 48 finished with value: -0.6596618147027539 and parameters: {'n_estimators': 451, 'max_depth': 33, 'min_samples_split': 18, 'min_samples_leaf': 18}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:20,549] Trial 49 finished with value: -0.7408507898220629 and parameters: {'n_estimators': 364, 'max_depth': 45, 'min_samples_split': 45, 'min_samples_leaf': 39}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:22,280] Trial 50 finished with value: -0.7495780634214348 and parameters: {'n_estimators': 322, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 45}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:23,498] Trial 51 finished with value: -0.7783619948498186 and parameters: {'n_estimators': 304, 'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 34}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:23,548] Trial 52 finished with value: -0.699914269303567 and parameters: {'n_estimators': 4, 'max_depth': 9, 'min_samples_split': 28, 'min_samples_leaf': 35}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:24,945] Trial 53 finished with value: -0.6315125916854426 and parameters: {'n_estimators': 327, 'max_depth': 12, 'min_samples_split': 36, 'min_samples_leaf': 12}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:25,720] Trial 54 finished with value: -0.7580662190633052 and parameters: {'n_estimators': 164, 'max_depth': 38, 'min_samples_split': 33, 'min_samples_leaf': 43}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:27,337] Trial 55 finished with value: -0.6651161746180471 and parameters: {'n_estimators': 330, 'max_depth': 29, 'min_samples_split': 6, 'min_samples_leaf': 19}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:28,141] Trial 56 finished with value: -0.6738597038981273 and parameters: {'n_estimators': 134, 'max_depth': 13, 'min_samples_split': 49, 'min_samples_leaf': 20}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:29,915] Trial 57 finished with value: -0.6920017526639907 and parameters: {'n_estimators': 447, 'max_depth': 32, 'min_samples_split': 40, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:30,931] Trial 58 finished with value: -0.7451196550078099 and parameters: {'n_estimators': 289, 'max_depth': 26, 'min_samples_split': 11, 'min_samples_leaf': 37}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:31,474] Trial 59 finished with value: -0.7160035653579802 and parameters: {'n_estimators': 142, 'max_depth': 3, 'min_samples_split': 33, 'min_samples_leaf': 9}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:33,684] Trial 60 finished with value: -0.6675958183303861 and parameters: {'n_estimators': 471, 'max_depth': 48, 'min_samples_split': 46, 'min_samples_leaf': 19}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:33,752] Trial 61 finished with value: -0.7839019225671751 and parameters: {'n_estimators': 9, 'max_depth': 47, 'min_samples_split': 22, 'min_samples_leaf': 49}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:36,036] Trial 62 finished with value: -0.674642919831563 and parameters: {'n_estimators': 482, 'max_depth': 43, 'min_samples_split': 16, 'min_samples_leaf': 20}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:37,626] Trial 63 finished with value: -0.7042998901163886 and parameters: {'n_estimators': 426, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 28}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:40,178] Trial 64 finished with value: -0.6108899894979256 and parameters: {'n_estimators': 469, 'max_depth': 36, 'min_samples_split': 29, 'min_samples_leaf': 5}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:41,518] Trial 65 finished with value: -0.6972831662997659 and parameters: {'n_estimators': 308, 'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:43,368] Trial 66 finished with value: -0.7386243645627864 and parameters: {'n_estimators': 439, 'max_depth': 38, 'min_samples_split': 36, 'min_samples_leaf': 36}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:44,108] Trial 67 finished with value: -0.7444772301950315 and parameters: {'n_estimators': 181, 'max_depth': 16, 'min_samples_split': 41, 'min_samples_leaf': 41}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:46,126] Trial 68 finished with value: -0.6929685170302473 and parameters: {'n_estimators': 434, 'max_depth': 46, 'min_samples_split': 27, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:47,982] Trial 69 finished with value: -0.7411394423712359 and parameters: {'n_estimators': 400, 'max_depth': 33, 'min_samples_split': 36, 'min_samples_leaf': 40}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:50,757] Trial 70 finished with value: -0.5904006578806936 and parameters: {'n_estimators': 446, 'max_depth': 18, 'min_samples_split': 20, 'min_samples_leaf': 5}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:51,915] Trial 71 finished with value: -0.7336623859648819 and parameters: {'n_estimators': 290, 'max_depth': 3, 'min_samples_split': 24, 'min_samples_leaf': 28}. Best is trial 20 with value: -0.5747656317115487.\n",
      "[I 2024-07-29 13:10:52,920] Trial 72 finished with value: -0.5094615568305532 and parameters: {'n_estimators': 144, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:10:54,317] Trial 73 finished with value: -0.7002120342356889 and parameters: {'n_estimators': 412, 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 27}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:10:55,753] Trial 74 finished with value: -0.6148008470413453 and parameters: {'n_estimators': 386, 'max_depth': 12, 'min_samples_split': 32, 'min_samples_leaf': 5}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:10:55,858] Trial 75 finished with value: -0.7428681562406785 and parameters: {'n_estimators': 27, 'max_depth': 28, 'min_samples_split': 28, 'min_samples_leaf': 32}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:10:57,030] Trial 76 finished with value: -0.6516314792089333 and parameters: {'n_estimators': 364, 'max_depth': 49, 'min_samples_split': 27, 'min_samples_leaf': 17}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:10:58,618] Trial 77 finished with value: -0.5921193777043874 and parameters: {'n_estimators': 398, 'max_depth': 15, 'min_samples_split': 23, 'min_samples_leaf': 4}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:10:58,687] Trial 78 finished with value: -0.7358572084940974 and parameters: {'n_estimators': 14, 'max_depth': 49, 'min_samples_split': 42, 'min_samples_leaf': 35}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:10:59,374] Trial 79 finished with value: -0.6310552883737105 and parameters: {'n_estimators': 206, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 13}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:00,261] Trial 80 finished with value: -0.6383330614133278 and parameters: {'n_estimators': 276, 'max_depth': 37, 'min_samples_split': 34, 'min_samples_leaf': 14}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:01,566] Trial 81 finished with value: -0.7236559702648757 and parameters: {'n_estimators': 478, 'max_depth': 38, 'min_samples_split': 29, 'min_samples_leaf': 31}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:02,152] Trial 82 finished with value: -0.7343063595442814 and parameters: {'n_estimators': 211, 'max_depth': 14, 'min_samples_split': 19, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:02,220] Trial 83 finished with value: -0.6262022412913484 and parameters: {'n_estimators': 9, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:03,788] Trial 84 finished with value: -0.6026062655994552 and parameters: {'n_estimators': 428, 'max_depth': 36, 'min_samples_split': 25, 'min_samples_leaf': 5}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:04,727] Trial 85 finished with value: -0.6778007639043879 and parameters: {'n_estimators': 247, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 22}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:05,418] Trial 86 finished with value: -0.6138696804638911 and parameters: {'n_estimators': 200, 'max_depth': 32, 'min_samples_split': 33, 'min_samples_leaf': 3}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:05,934] Trial 87 finished with value: -0.7499893455720302 and parameters: {'n_estimators': 188, 'max_depth': 32, 'min_samples_split': 26, 'min_samples_leaf': 43}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:06,857] Trial 88 finished with value: -0.7354688116334384 and parameters: {'n_estimators': 330, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 33}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:06,932] Trial 89 finished with value: -0.728560946763807 and parameters: {'n_estimators': 15, 'max_depth': 30, 'min_samples_split': 48, 'min_samples_leaf': 29}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:07,501] Trial 90 finished with value: -0.7160879821437475 and parameters: {'n_estimators': 195, 'max_depth': 33, 'min_samples_split': 24, 'min_samples_leaf': 28}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:08,689] Trial 91 finished with value: -0.7495468440710485 and parameters: {'n_estimators': 471, 'max_depth': 20, 'min_samples_split': 49, 'min_samples_leaf': 46}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:09,066] Trial 92 finished with value: -0.5764725376730158 and parameters: {'n_estimators': 99, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:09,245] Trial 93 finished with value: -0.668032180843173 and parameters: {'n_estimators': 49, 'max_depth': 35, 'min_samples_split': 5, 'min_samples_leaf': 16}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:10,562] Trial 94 finished with value: -0.7125532791637136 and parameters: {'n_estimators': 423, 'max_depth': 3, 'min_samples_split': 41, 'min_samples_leaf': 15}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:10,743] Trial 95 finished with value: -0.7498290566759194 and parameters: {'n_estimators': 60, 'max_depth': 36, 'min_samples_split': 32, 'min_samples_leaf': 44}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:12,026] Trial 96 finished with value: -0.5992933757609193 and parameters: {'n_estimators': 368, 'max_depth': 41, 'min_samples_split': 15, 'min_samples_leaf': 9}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:13,098] Trial 97 finished with value: -0.677385702635928 and parameters: {'n_estimators': 376, 'max_depth': 41, 'min_samples_split': 50, 'min_samples_leaf': 21}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:13,593] Trial 98 finished with value: -0.7519059450409581 and parameters: {'n_estimators': 187, 'max_depth': 40, 'min_samples_split': 18, 'min_samples_leaf': 47}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:14,897] Trial 99 finished with value: -0.7471843068549655 and parameters: {'n_estimators': 430, 'max_depth': 23, 'min_samples_split': 38, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:15,059] Trial 100 finished with value: -0.7454473845708014 and parameters: {'n_estimators': 53, 'max_depth': 46, 'min_samples_split': 26, 'min_samples_leaf': 42}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:15,714] Trial 101 finished with value: -0.55971906112778 and parameters: {'n_estimators': 161, 'max_depth': 45, 'min_samples_split': 21, 'min_samples_leaf': 1}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:16,859] Trial 102 finished with value: -0.7565817871478052 and parameters: {'n_estimators': 453, 'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 48}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:18,462] Trial 103 finished with value: -0.680471654356272 and parameters: {'n_estimators': 476, 'max_depth': 30, 'min_samples_split': 32, 'min_samples_leaf': 23}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:18,889] Trial 104 finished with value: -0.7516005975020412 and parameters: {'n_estimators': 148, 'max_depth': 18, 'min_samples_split': 34, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:20,315] Trial 105 finished with value: -0.6859224488506979 and parameters: {'n_estimators': 396, 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 25}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:20,454] Trial 106 finished with value: -0.7472292368530467 and parameters: {'n_estimators': 30, 'max_depth': 28, 'min_samples_split': 23, 'min_samples_leaf': 45}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:21,003] Trial 107 finished with value: -0.7484385066558087 and parameters: {'n_estimators': 177, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 39}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:22,124] Trial 108 finished with value: -0.7407636720348373 and parameters: {'n_estimators': 310, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 36}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:22,295] Trial 109 finished with value: -0.6395199327543823 and parameters: {'n_estimators': 38, 'max_depth': 42, 'min_samples_split': 36, 'min_samples_leaf': 5}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:22,566] Trial 110 finished with value: -0.6772804073804976 and parameters: {'n_estimators': 44, 'max_depth': 50, 'min_samples_split': 20, 'min_samples_leaf': 19}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:23,843] Trial 111 finished with value: -0.7424391615378135 and parameters: {'n_estimators': 407, 'max_depth': 48, 'min_samples_split': 50, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:24,549] Trial 112 finished with value: -0.7077613987326269 and parameters: {'n_estimators': 189, 'max_depth': 6, 'min_samples_split': 40, 'min_samples_leaf': 28}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:25,170] Trial 113 finished with value: -0.6867447985189639 and parameters: {'n_estimators': 213, 'max_depth': 46, 'min_samples_split': 7, 'min_samples_leaf': 25}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:25,229] Trial 114 finished with value: -0.5820552391158049 and parameters: {'n_estimators': 7, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:25,412] Trial 115 finished with value: -0.7193134755622801 and parameters: {'n_estimators': 60, 'max_depth': 33, 'min_samples_split': 38, 'min_samples_leaf': 30}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:26,666] Trial 116 finished with value: -0.7513574384977477 and parameters: {'n_estimators': 482, 'max_depth': 20, 'min_samples_split': 15, 'min_samples_leaf': 44}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:26,979] Trial 117 finished with value: -0.7538694288845003 and parameters: {'n_estimators': 113, 'max_depth': 49, 'min_samples_split': 2, 'min_samples_leaf': 49}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:27,071] Trial 118 finished with value: -0.762056289241206 and parameters: {'n_estimators': 23, 'max_depth': 45, 'min_samples_split': 27, 'min_samples_leaf': 50}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:27,224] Trial 119 finished with value: -0.6757826845521901 and parameters: {'n_estimators': 38, 'max_depth': 29, 'min_samples_split': 49, 'min_samples_leaf': 27}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:28,093] Trial 120 finished with value: -0.7289817778495957 and parameters: {'n_estimators': 316, 'max_depth': 36, 'min_samples_split': 24, 'min_samples_leaf': 32}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:29,019] Trial 121 finished with value: -0.6346320792356313 and parameters: {'n_estimators': 293, 'max_depth': 46, 'min_samples_split': 4, 'min_samples_leaf': 15}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:30,445] Trial 122 finished with value: -0.7282537550852772 and parameters: {'n_estimators': 476, 'max_depth': 45, 'min_samples_split': 24, 'min_samples_leaf': 32}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:30,907] Trial 123 finished with value: -0.6527135458202594 and parameters: {'n_estimators': 140, 'max_depth': 11, 'min_samples_split': 24, 'min_samples_leaf': 18}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:31,651] Trial 124 finished with value: -0.7657286699968184 and parameters: {'n_estimators': 293, 'max_depth': 5, 'min_samples_split': 49, 'min_samples_leaf': 50}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:32,557] Trial 125 finished with value: -0.7426093035522607 and parameters: {'n_estimators': 350, 'max_depth': 28, 'min_samples_split': 17, 'min_samples_leaf': 41}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:33,468] Trial 126 finished with value: -0.7425017035427366 and parameters: {'n_estimators': 343, 'max_depth': 9, 'min_samples_split': 46, 'min_samples_leaf': 42}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:34,870] Trial 127 finished with value: -0.675018221326762 and parameters: {'n_estimators': 475, 'max_depth': 37, 'min_samples_split': 32, 'min_samples_leaf': 21}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:37,235] Trial 128 finished with value: -0.5136596991270723 and parameters: {'n_estimators': 467, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:37,843] Trial 129 finished with value: -0.6528126174056036 and parameters: {'n_estimators': 189, 'max_depth': 41, 'min_samples_split': 50, 'min_samples_leaf': 8}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:38,608] Trial 130 finished with value: -0.7488546045909793 and parameters: {'n_estimators': 298, 'max_depth': 20, 'min_samples_split': 49, 'min_samples_leaf': 43}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:39,941] Trial 131 finished with value: -0.6303606774949683 and parameters: {'n_estimators': 420, 'max_depth': 24, 'min_samples_split': 22, 'min_samples_leaf': 14}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:40,196] Trial 132 finished with value: -0.7634006658587456 and parameters: {'n_estimators': 30, 'max_depth': 44, 'min_samples_split': 41, 'min_samples_leaf': 50}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:41,452] Trial 133 finished with value: -0.752496888133018 and parameters: {'n_estimators': 499, 'max_depth': 29, 'min_samples_split': 39, 'min_samples_leaf': 48}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:42,912] Trial 134 finished with value: -0.6088621652130847 and parameters: {'n_estimators': 425, 'max_depth': 14, 'min_samples_split': 24, 'min_samples_leaf': 7}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:44,204] Trial 135 finished with value: -0.7338128776417522 and parameters: {'n_estimators': 478, 'max_depth': 31, 'min_samples_split': 13, 'min_samples_leaf': 34}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:45,080] Trial 136 finished with value: -0.735126335886961 and parameters: {'n_estimators': 310, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 34}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:45,765] Trial 137 finished with value: -0.7470144201331038 and parameters: {'n_estimators': 261, 'max_depth': 39, 'min_samples_split': 27, 'min_samples_leaf': 43}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:46,747] Trial 138 finished with value: -0.6712544395829174 and parameters: {'n_estimators': 277, 'max_depth': 29, 'min_samples_split': 44, 'min_samples_leaf': 21}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:46,955] Trial 139 finished with value: -0.7510041514618434 and parameters: {'n_estimators': 68, 'max_depth': 3, 'min_samples_split': 39, 'min_samples_leaf': 32}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:48,603] Trial 140 finished with value: -0.5220770195222987 and parameters: {'n_estimators': 353, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:49,125] Trial 141 finished with value: -0.6832021360927882 and parameters: {'n_estimators': 176, 'max_depth': 30, 'min_samples_split': 21, 'min_samples_leaf': 22}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:50,290] Trial 142 finished with value: -0.7481720098793263 and parameters: {'n_estimators': 453, 'max_depth': 19, 'min_samples_split': 27, 'min_samples_leaf': 40}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:50,814] Trial 143 finished with value: -0.759932412912741 and parameters: {'n_estimators': 199, 'max_depth': 32, 'min_samples_split': 44, 'min_samples_leaf': 48}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:51,224] Trial 144 finished with value: -0.6404737867581016 and parameters: {'n_estimators': 75, 'max_depth': 47, 'min_samples_split': 26, 'min_samples_leaf': 13}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:51,971] Trial 145 finished with value: -0.653221102289727 and parameters: {'n_estimators': 231, 'max_depth': 50, 'min_samples_split': 26, 'min_samples_leaf': 17}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:53,120] Trial 146 finished with value: -0.5888927157193601 and parameters: {'n_estimators': 318, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:53,333] Trial 147 finished with value: -0.7261583776385475 and parameters: {'n_estimators': 65, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 33}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:53,617] Trial 148 finished with value: -0.6930695046651336 and parameters: {'n_estimators': 92, 'max_depth': 18, 'min_samples_split': 45, 'min_samples_leaf': 24}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:55,119] Trial 149 finished with value: -0.5522399535511734 and parameters: {'n_estimators': 335, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:55,479] Trial 150 finished with value: -0.5762188433557714 and parameters: {'n_estimators': 86, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:55,690] Trial 151 finished with value: -0.6658874871093745 and parameters: {'n_estimators': 62, 'max_depth': 24, 'min_samples_split': 12, 'min_samples_leaf': 19}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:56,365] Trial 152 finished with value: -0.7459343604832197 and parameters: {'n_estimators': 253, 'max_depth': 35, 'min_samples_split': 3, 'min_samples_leaf': 40}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:57,174] Trial 153 finished with value: -0.7574983388702498 and parameters: {'n_estimators': 315, 'max_depth': 6, 'min_samples_split': 44, 'min_samples_leaf': 47}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:57,286] Trial 154 finished with value: -0.74760880024459 and parameters: {'n_estimators': 32, 'max_depth': 15, 'min_samples_split': 41, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:57,611] Trial 155 finished with value: -0.685984725952496 and parameters: {'n_estimators': 94, 'max_depth': 12, 'min_samples_split': 20, 'min_samples_leaf': 25}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:58,440] Trial 156 finished with value: -0.744871292316782 and parameters: {'n_estimators': 310, 'max_depth': 20, 'min_samples_split': 24, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:58,523] Trial 157 finished with value: -0.7369321882903483 and parameters: {'n_estimators': 20, 'max_depth': 14, 'min_samples_split': 36, 'min_samples_leaf': 45}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:11:59,269] Trial 158 finished with value: -0.6782324839404665 and parameters: {'n_estimators': 257, 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 23}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:00,091] Trial 159 finished with value: -0.6681617203159538 and parameters: {'n_estimators': 267, 'max_depth': 13, 'min_samples_split': 15, 'min_samples_leaf': 19}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:00,154] Trial 160 finished with value: -0.6687662085874683 and parameters: {'n_estimators': 12, 'max_depth': 17, 'min_samples_split': 12, 'min_samples_leaf': 17}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:00,337] Trial 161 finished with value: -0.738915290771766 and parameters: {'n_estimators': 61, 'max_depth': 45, 'min_samples_split': 31, 'min_samples_leaf': 34}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:01,459] Trial 162 finished with value: -0.6998902512432609 and parameters: {'n_estimators': 395, 'max_depth': 26, 'min_samples_split': 6, 'min_samples_leaf': 27}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:02,488] Trial 163 finished with value: -0.6006339701575721 and parameters: {'n_estimators': 294, 'max_depth': 38, 'min_samples_split': 23, 'min_samples_leaf': 7}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:02,942] Trial 164 finished with value: -0.7137197887840212 and parameters: {'n_estimators': 143, 'max_depth': 19, 'min_samples_split': 33, 'min_samples_leaf': 29}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:03,543] Trial 165 finished with value: -0.6276810602337188 and parameters: {'n_estimators': 179, 'max_depth': 50, 'min_samples_split': 31, 'min_samples_leaf': 12}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:03,749] Trial 166 finished with value: -0.5976464046920065 and parameters: {'n_estimators': 52, 'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 9}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:04,166] Trial 167 finished with value: -0.7528541784812111 and parameters: {'n_estimators': 95, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 45}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:04,297] Trial 168 finished with value: -0.762451400873214 and parameters: {'n_estimators': 42, 'max_depth': 27, 'min_samples_split': 22, 'min_samples_leaf': 50}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:04,470] Trial 169 finished with value: -0.7680646733941745 and parameters: {'n_estimators': 57, 'max_depth': 21, 'min_samples_split': 49, 'min_samples_leaf': 44}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:05,566] Trial 170 finished with value: -0.7415508429525721 and parameters: {'n_estimators': 409, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 34}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:07,099] Trial 171 finished with value: -0.6370840653821782 and parameters: {'n_estimators': 465, 'max_depth': 29, 'min_samples_split': 30, 'min_samples_leaf': 14}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:08,425] Trial 172 finished with value: -0.6843973223356723 and parameters: {'n_estimators': 385, 'max_depth': 11, 'min_samples_split': 17, 'min_samples_leaf': 22}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:09,126] Trial 173 finished with value: -0.7159645807898766 and parameters: {'n_estimators': 255, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 31}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:09,564] Trial 174 finished with value: -0.6790237850153524 and parameters: {'n_estimators': 146, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 25}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:10,390] Trial 175 finished with value: -0.6514462462765547 and parameters: {'n_estimators': 267, 'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 7}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:10,507] Trial 176 finished with value: -0.755707447295473 and parameters: {'n_estimators': 33, 'max_depth': 50, 'min_samples_split': 17, 'min_samples_leaf': 41}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:10,885] Trial 177 finished with value: -0.725668094975741 and parameters: {'n_estimators': 129, 'max_depth': 35, 'min_samples_split': 39, 'min_samples_leaf': 30}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:11,498] Trial 178 finished with value: -0.7552364764005232 and parameters: {'n_estimators': 237, 'max_depth': 22, 'min_samples_split': 19, 'min_samples_leaf': 47}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:12,603] Trial 179 finished with value: -0.7419678483464052 and parameters: {'n_estimators': 416, 'max_depth': 49, 'min_samples_split': 8, 'min_samples_leaf': 37}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:14,011] Trial 180 finished with value: -0.7393804479148515 and parameters: {'n_estimators': 470, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:14,770] Trial 181 finished with value: -0.7479030933963466 and parameters: {'n_estimators': 288, 'max_depth': 43, 'min_samples_split': 8, 'min_samples_leaf': 40}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:15,058] Trial 182 finished with value: -0.7465281198598912 and parameters: {'n_estimators': 102, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 41}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:15,933] Trial 183 finished with value: -0.7452136832914562 and parameters: {'n_estimators': 333, 'max_depth': 27, 'min_samples_split': 19, 'min_samples_leaf': 44}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:16,541] Trial 184 finished with value: -0.6619431089085325 and parameters: {'n_estimators': 197, 'max_depth': 42, 'min_samples_split': 23, 'min_samples_leaf': 19}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:17,208] Trial 185 finished with value: -0.6934630572325127 and parameters: {'n_estimators': 232, 'max_depth': 16, 'min_samples_split': 38, 'min_samples_leaf': 26}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:17,554] Trial 186 finished with value: -0.7075234988466251 and parameters: {'n_estimators': 117, 'max_depth': 46, 'min_samples_split': 20, 'min_samples_leaf': 28}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:18,751] Trial 187 finished with value: -0.7511822248497784 and parameters: {'n_estimators': 454, 'max_depth': 32, 'min_samples_split': 7, 'min_samples_leaf': 47}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:19,623] Trial 188 finished with value: -0.7400701397833664 and parameters: {'n_estimators': 315, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 40}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:20,604] Trial 189 finished with value: -0.7454442158217797 and parameters: {'n_estimators': 311, 'max_depth': 28, 'min_samples_split': 45, 'min_samples_leaf': 40}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:20,837] Trial 190 finished with value: -0.7411111240267398 and parameters: {'n_estimators': 77, 'max_depth': 17, 'min_samples_split': 14, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:20,911] Trial 191 finished with value: -0.7529281155776616 and parameters: {'n_estimators': 18, 'max_depth': 29, 'min_samples_split': 39, 'min_samples_leaf': 44}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:21,363] Trial 192 finished with value: -0.7465154133031314 and parameters: {'n_estimators': 172, 'max_depth': 42, 'min_samples_split': 7, 'min_samples_leaf': 43}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:21,597] Trial 193 finished with value: -0.6384598351560731 and parameters: {'n_estimators': 65, 'max_depth': 21, 'min_samples_split': 41, 'min_samples_leaf': 8}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:21,935] Trial 194 finished with value: -0.7345232538646014 and parameters: {'n_estimators': 116, 'max_depth': 37, 'min_samples_split': 37, 'min_samples_leaf': 33}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:23,005] Trial 195 finished with value: -0.6557356316171978 and parameters: {'n_estimators': 348, 'max_depth': 28, 'min_samples_split': 14, 'min_samples_leaf': 18}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:23,310] Trial 196 finished with value: -0.6786952742897855 and parameters: {'n_estimators': 92, 'max_depth': 46, 'min_samples_split': 30, 'min_samples_leaf': 21}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:24,010] Trial 197 finished with value: -0.7170917657434888 and parameters: {'n_estimators': 232, 'max_depth': 48, 'min_samples_split': 9, 'min_samples_leaf': 30}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:24,763] Trial 198 finished with value: -0.751854808377229 and parameters: {'n_estimators': 254, 'max_depth': 31, 'min_samples_split': 2, 'min_samples_leaf': 44}. Best is trial 72 with value: -0.5094615568305532.\n",
      "[I 2024-07-29 13:12:25,962] Trial 199 finished with value: -0.7530152272560022 and parameters: {'n_estimators': 467, 'max_depth': 29, 'min_samples_split': 36, 'min_samples_leaf': 47}. Best is trial 72 with value: -0.5094615568305532.\n"
     ]
    }
   ],
   "source": [
    "study_hi.optimize(lambda trial: objective(trial, np.array(list((x_train_hi))).astype(float), y_train_hi), n_trials=200, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2dc22d26690431481a9c8aec21d55db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 13:12:26,446] Trial 0 finished with value: -1.5071943232138791 and parameters: {'n_estimators': 188, 'max_depth': 48, 'min_samples_split': 37, 'min_samples_leaf': 30}. Best is trial 0 with value: -1.5071943232138791.\n",
      "[I 2024-07-29 13:12:26,604] Trial 1 finished with value: -1.5053346379045176 and parameters: {'n_estimators': 79, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 44}. Best is trial 1 with value: -1.5053346379045176.\n",
      "[I 2024-07-29 13:12:27,167] Trial 2 finished with value: -1.5043201719368686 and parameters: {'n_estimators': 301, 'max_depth': 36, 'min_samples_split': 3, 'min_samples_leaf': 49}. Best is trial 2 with value: -1.5043201719368686.\n",
      "[I 2024-07-29 13:12:28,187] Trial 3 finished with value: -0.9171519059553427 and parameters: {'n_estimators': 417, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:28,490] Trial 4 finished with value: -1.490152867383379 and parameters: {'n_estimators': 153, 'max_depth': 27, 'min_samples_split': 23, 'min_samples_leaf': 15}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:29,049] Trial 5 finished with value: -1.5005586380442055 and parameters: {'n_estimators': 307, 'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 19}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:29,480] Trial 6 finished with value: -1.4926469608129227 and parameters: {'n_estimators': 229, 'max_depth': 40, 'min_samples_split': 11, 'min_samples_leaf': 26}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:30,033] Trial 7 finished with value: -1.4887822375582052 and parameters: {'n_estimators': 297, 'max_depth': 4, 'min_samples_split': 31, 'min_samples_leaf': 9}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:30,112] Trial 8 finished with value: -1.483247772941239 and parameters: {'n_estimators': 34, 'max_depth': 48, 'min_samples_split': 49, 'min_samples_leaf': 41}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:30,404] Trial 9 finished with value: -1.515284485456288 and parameters: {'n_estimators': 154, 'max_depth': 6, 'min_samples_split': 35, 'min_samples_leaf': 23}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:30,537] Trial 10 finished with value: -1.5041375785651774 and parameters: {'n_estimators': 62, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 46}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:30,799] Trial 11 finished with value: -1.5157763848129542 and parameters: {'n_estimators': 131, 'max_depth': 34, 'min_samples_split': 17, 'min_samples_leaf': 27}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:31,309] Trial 12 finished with value: -1.5121837012342745 and parameters: {'n_estimators': 274, 'max_depth': 11, 'min_samples_split': 49, 'min_samples_leaf': 39}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:32,181] Trial 13 finished with value: -1.5009751245486216 and parameters: {'n_estimators': 470, 'max_depth': 45, 'min_samples_split': 31, 'min_samples_leaf': 47}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:32,282] Trial 14 finished with value: -1.4758102140544518 and parameters: {'n_estimators': 46, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 17}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:32,651] Trial 15 finished with value: -1.5042370212429048 and parameters: {'n_estimators': 195, 'max_depth': 15, 'min_samples_split': 42, 'min_samples_leaf': 18}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:32,920] Trial 16 finished with value: -1.507844201843128 and parameters: {'n_estimators': 142, 'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 41}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:33,007] Trial 17 finished with value: -1.488613620936653 and parameters: {'n_estimators': 39, 'max_depth': 50, 'min_samples_split': 39, 'min_samples_leaf': 10}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:33,028] Trial 18 finished with value: -1.4564747696245333 and parameters: {'n_estimators': 4, 'max_depth': 41, 'min_samples_split': 36, 'min_samples_leaf': 37}. Best is trial 3 with value: -0.9171519059553427.\n",
      "[I 2024-07-29 13:12:33,781] Trial 19 finished with value: -0.7604444629255265 and parameters: {'n_estimators': 386, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 6}. Best is trial 19 with value: -0.7604444629255265.\n",
      "[I 2024-07-29 13:12:34,623] Trial 20 finished with value: -0.7138538762948786 and parameters: {'n_estimators': 432, 'max_depth': 32, 'min_samples_split': 18, 'min_samples_leaf': 4}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:34,940] Trial 21 finished with value: -1.4948234464615422 and parameters: {'n_estimators': 157, 'max_depth': 17, 'min_samples_split': 37, 'min_samples_leaf': 32}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:36,127] Trial 22 finished with value: -1.510072854060349 and parameters: {'n_estimators': 444, 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 36}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:36,853] Trial 23 finished with value: -1.5029524958626537 and parameters: {'n_estimators': 381, 'max_depth': 29, 'min_samples_split': 39, 'min_samples_leaf': 25}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:37,364] Trial 24 finished with value: -0.7532978933158214 and parameters: {'n_estimators': 262, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:37,416] Trial 25 finished with value: -1.4760845901827957 and parameters: {'n_estimators': 17, 'max_depth': 33, 'min_samples_split': 17, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:38,279] Trial 26 finished with value: -1.500087680795151 and parameters: {'n_estimators': 454, 'max_depth': 14, 'min_samples_split': 22, 'min_samples_leaf': 38}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:38,520] Trial 27 finished with value: -0.8735095457109207 and parameters: {'n_estimators': 116, 'max_depth': 5, 'min_samples_split': 16, 'min_samples_leaf': 9}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:39,522] Trial 28 finished with value: -1.501990910053003 and parameters: {'n_estimators': 465, 'max_depth': 41, 'min_samples_split': 33, 'min_samples_leaf': 44}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:40,291] Trial 29 finished with value: -1.5130435917572216 and parameters: {'n_estimators': 403, 'max_depth': 11, 'min_samples_split': 45, 'min_samples_leaf': 27}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:41,213] Trial 30 finished with value: -0.7591693889947891 and parameters: {'n_estimators': 404, 'max_depth': 45, 'min_samples_split': 17, 'min_samples_leaf': 6}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:41,454] Trial 31 finished with value: -1.499504544008365 and parameters: {'n_estimators': 115, 'max_depth': 22, 'min_samples_split': 42, 'min_samples_leaf': 44}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:41,480] Trial 32 finished with value: -1.1533917555221 and parameters: {'n_estimators': 5, 'max_depth': 27, 'min_samples_split': 22, 'min_samples_leaf': 12}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:41,611] Trial 33 finished with value: -1.4822609087100043 and parameters: {'n_estimators': 61, 'max_depth': 18, 'min_samples_split': 48, 'min_samples_leaf': 17}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:42,153] Trial 34 finished with value: -1.5054485282305694 and parameters: {'n_estimators': 260, 'max_depth': 36, 'min_samples_split': 19, 'min_samples_leaf': 49}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:43,838] Trial 35 finished with value: -1.5059595573224358 and parameters: {'n_estimators': 482, 'max_depth': 14, 'min_samples_split': 26, 'min_samples_leaf': 16}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:44,252] Trial 36 finished with value: -1.5214444471644322 and parameters: {'n_estimators': 144, 'max_depth': 3, 'min_samples_split': 31, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:44,339] Trial 37 finished with value: -1.4607315268235417 and parameters: {'n_estimators': 27, 'max_depth': 15, 'min_samples_split': 46, 'min_samples_leaf': 12}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:44,529] Trial 38 finished with value: -1.4856158557820902 and parameters: {'n_estimators': 74, 'max_depth': 25, 'min_samples_split': 50, 'min_samples_leaf': 13}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:45,340] Trial 39 finished with value: -1.5155233713941612 and parameters: {'n_estimators': 337, 'max_depth': 39, 'min_samples_split': 13, 'min_samples_leaf': 37}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:45,807] Trial 40 finished with value: -1.495091849820721 and parameters: {'n_estimators': 185, 'max_depth': 32, 'min_samples_split': 33, 'min_samples_leaf': 27}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:45,940] Trial 41 finished with value: -0.9205374610011914 and parameters: {'n_estimators': 47, 'max_depth': 42, 'min_samples_split': 17, 'min_samples_leaf': 10}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:46,013] Trial 42 finished with value: -1.532291905274732 and parameters: {'n_estimators': 22, 'max_depth': 30, 'min_samples_split': 35, 'min_samples_leaf': 1}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:46,712] Trial 43 finished with value: -1.4939209115804306 and parameters: {'n_estimators': 257, 'max_depth': 13, 'min_samples_split': 33, 'min_samples_leaf': 9}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:47,677] Trial 44 finished with value: -1.505572973581097 and parameters: {'n_estimators': 346, 'max_depth': 20, 'min_samples_split': 47, 'min_samples_leaf': 7}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:48,116] Trial 45 finished with value: -1.5108164085249756 and parameters: {'n_estimators': 172, 'max_depth': 7, 'min_samples_split': 47, 'min_samples_leaf': 44}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:48,510] Trial 46 finished with value: -1.4963699008513516 and parameters: {'n_estimators': 130, 'max_depth': 34, 'min_samples_split': 42, 'min_samples_leaf': 28}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:49,310] Trial 47 finished with value: -1.508519970200171 and parameters: {'n_estimators': 266, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 45}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:50,801] Trial 48 finished with value: -1.4954232329898651 and parameters: {'n_estimators': 451, 'max_depth': 33, 'min_samples_split': 18, 'min_samples_leaf': 18}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:51,684] Trial 49 finished with value: -1.5132796606508596 and parameters: {'n_estimators': 364, 'max_depth': 45, 'min_samples_split': 45, 'min_samples_leaf': 39}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:52,443] Trial 50 finished with value: -1.486936915479969 and parameters: {'n_estimators': 322, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 45}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:53,166] Trial 51 finished with value: -1.504019071623036 and parameters: {'n_estimators': 304, 'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 34}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:53,193] Trial 52 finished with value: -1.4053928390308215 and parameters: {'n_estimators': 4, 'max_depth': 9, 'min_samples_split': 28, 'min_samples_leaf': 35}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:54,082] Trial 53 finished with value: -1.4920745130293684 and parameters: {'n_estimators': 327, 'max_depth': 12, 'min_samples_split': 36, 'min_samples_leaf': 12}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:54,491] Trial 54 finished with value: -1.4984578266675483 and parameters: {'n_estimators': 164, 'max_depth': 38, 'min_samples_split': 33, 'min_samples_leaf': 43}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:55,309] Trial 55 finished with value: -1.5005113818835176 and parameters: {'n_estimators': 330, 'max_depth': 29, 'min_samples_split': 6, 'min_samples_leaf': 19}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:55,655] Trial 56 finished with value: -1.495444361242433 and parameters: {'n_estimators': 134, 'max_depth': 13, 'min_samples_split': 49, 'min_samples_leaf': 20}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:57,127] Trial 57 finished with value: -1.4982845723906322 and parameters: {'n_estimators': 447, 'max_depth': 32, 'min_samples_split': 40, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:57,844] Trial 58 finished with value: -1.5008688758014366 and parameters: {'n_estimators': 289, 'max_depth': 26, 'min_samples_split': 11, 'min_samples_leaf': 37}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:58,205] Trial 59 finished with value: -1.5087653815625377 and parameters: {'n_estimators': 142, 'max_depth': 3, 'min_samples_split': 33, 'min_samples_leaf': 9}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:59,386] Trial 60 finished with value: -1.4943020600770986 and parameters: {'n_estimators': 471, 'max_depth': 48, 'min_samples_split': 46, 'min_samples_leaf': 19}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:12:59,428] Trial 61 finished with value: -1.5413660168831973 and parameters: {'n_estimators': 9, 'max_depth': 47, 'min_samples_split': 22, 'min_samples_leaf': 49}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:13:00,775] Trial 62 finished with value: -1.5009048897379074 and parameters: {'n_estimators': 482, 'max_depth': 43, 'min_samples_split': 16, 'min_samples_leaf': 20}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:13:01,793] Trial 63 finished with value: -1.5008282046885941 and parameters: {'n_estimators': 426, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 28}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:13:03,027] Trial 64 finished with value: -1.4357736329143862 and parameters: {'n_estimators': 469, 'max_depth': 36, 'min_samples_split': 29, 'min_samples_leaf': 5}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:13:03,969] Trial 65 finished with value: -1.5140704688107927 and parameters: {'n_estimators': 308, 'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:13:05,025] Trial 66 finished with value: -1.501586475823192 and parameters: {'n_estimators': 439, 'max_depth': 38, 'min_samples_split': 36, 'min_samples_leaf': 36}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:13:05,445] Trial 67 finished with value: -1.4872522987689432 and parameters: {'n_estimators': 181, 'max_depth': 16, 'min_samples_split': 41, 'min_samples_leaf': 41}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:13:06,250] Trial 68 finished with value: -1.5015543752909069 and parameters: {'n_estimators': 434, 'max_depth': 46, 'min_samples_split': 27, 'min_samples_leaf': 26}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:13:08,017] Trial 69 finished with value: -1.5046493004483916 and parameters: {'n_estimators': 400, 'max_depth': 33, 'min_samples_split': 36, 'min_samples_leaf': 40}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:13:08,994] Trial 70 finished with value: -0.7425922891483596 and parameters: {'n_estimators': 446, 'max_depth': 18, 'min_samples_split': 20, 'min_samples_leaf': 5}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:13:09,550] Trial 71 finished with value: -1.5018488833812926 and parameters: {'n_estimators': 290, 'max_depth': 3, 'min_samples_split': 24, 'min_samples_leaf': 28}. Best is trial 20 with value: -0.7138538762948786.\n",
      "[I 2024-07-29 13:13:09,841] Trial 72 finished with value: -0.5413094284300675 and parameters: {'n_estimators': 144, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:10,571] Trial 73 finished with value: -1.503140791527689 and parameters: {'n_estimators': 412, 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 27}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:11,259] Trial 74 finished with value: -1.501861229001906 and parameters: {'n_estimators': 386, 'max_depth': 12, 'min_samples_split': 32, 'min_samples_leaf': 5}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:11,326] Trial 75 finished with value: -1.4722876264528135 and parameters: {'n_estimators': 27, 'max_depth': 28, 'min_samples_split': 28, 'min_samples_leaf': 32}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:11,969] Trial 76 finished with value: -1.504388953838904 and parameters: {'n_estimators': 364, 'max_depth': 49, 'min_samples_split': 27, 'min_samples_leaf': 17}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:12,708] Trial 77 finished with value: -0.7715037674982334 and parameters: {'n_estimators': 398, 'max_depth': 15, 'min_samples_split': 23, 'min_samples_leaf': 4}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:12,752] Trial 78 finished with value: -1.454983293654352 and parameters: {'n_estimators': 14, 'max_depth': 49, 'min_samples_split': 42, 'min_samples_leaf': 35}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:13,131] Trial 79 finished with value: -1.3026998475032903 and parameters: {'n_estimators': 206, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 13}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:13,639] Trial 80 finished with value: -1.501043664937546 and parameters: {'n_estimators': 276, 'max_depth': 37, 'min_samples_split': 34, 'min_samples_leaf': 14}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:14,500] Trial 81 finished with value: -1.5081550338356142 and parameters: {'n_estimators': 478, 'max_depth': 38, 'min_samples_split': 29, 'min_samples_leaf': 31}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:14,897] Trial 82 finished with value: -1.4847478141319055 and parameters: {'n_estimators': 211, 'max_depth': 14, 'min_samples_split': 19, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:15,119] Trial 83 finished with value: -0.6611290466998987 and parameters: {'n_estimators': 9, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:16,985] Trial 84 finished with value: -0.8820199193662264 and parameters: {'n_estimators': 428, 'max_depth': 36, 'min_samples_split': 25, 'min_samples_leaf': 5}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:17,835] Trial 85 finished with value: -1.4935033441996481 and parameters: {'n_estimators': 247, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 22}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:18,618] Trial 86 finished with value: -1.5061203343280631 and parameters: {'n_estimators': 200, 'max_depth': 32, 'min_samples_split': 33, 'min_samples_leaf': 3}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:19,698] Trial 87 finished with value: -1.5061423887042515 and parameters: {'n_estimators': 188, 'max_depth': 32, 'min_samples_split': 26, 'min_samples_leaf': 43}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:20,587] Trial 88 finished with value: -1.5030647721939172 and parameters: {'n_estimators': 330, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 33}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:20,674] Trial 89 finished with value: -1.427871097730721 and parameters: {'n_estimators': 15, 'max_depth': 30, 'min_samples_split': 48, 'min_samples_leaf': 29}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:21,140] Trial 90 finished with value: -1.5122326056906894 and parameters: {'n_estimators': 195, 'max_depth': 33, 'min_samples_split': 24, 'min_samples_leaf': 28}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:22,284] Trial 91 finished with value: -1.5061266874120338 and parameters: {'n_estimators': 471, 'max_depth': 20, 'min_samples_split': 49, 'min_samples_leaf': 46}. Best is trial 72 with value: -0.5413094284300675.\n",
      "[I 2024-07-29 13:13:22,709] Trial 92 finished with value: -0.5092009309640215 and parameters: {'n_estimators': 99, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:22,860] Trial 93 finished with value: -1.5000721734070648 and parameters: {'n_estimators': 49, 'max_depth': 35, 'min_samples_split': 5, 'min_samples_leaf': 16}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:24,140] Trial 94 finished with value: -1.5026510563238116 and parameters: {'n_estimators': 423, 'max_depth': 3, 'min_samples_split': 41, 'min_samples_leaf': 15}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:24,332] Trial 95 finished with value: -1.4909330135360623 and parameters: {'n_estimators': 60, 'max_depth': 36, 'min_samples_split': 32, 'min_samples_leaf': 44}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:25,397] Trial 96 finished with value: -0.868360845088767 and parameters: {'n_estimators': 368, 'max_depth': 41, 'min_samples_split': 15, 'min_samples_leaf': 9}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:26,730] Trial 97 finished with value: -1.4982439085111814 and parameters: {'n_estimators': 376, 'max_depth': 41, 'min_samples_split': 50, 'min_samples_leaf': 21}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:27,236] Trial 98 finished with value: -1.5042297691417983 and parameters: {'n_estimators': 187, 'max_depth': 40, 'min_samples_split': 18, 'min_samples_leaf': 47}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:28,395] Trial 99 finished with value: -1.4991789291309363 and parameters: {'n_estimators': 430, 'max_depth': 23, 'min_samples_split': 38, 'min_samples_leaf': 38}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:28,567] Trial 100 finished with value: -1.4540007150059542 and parameters: {'n_estimators': 53, 'max_depth': 46, 'min_samples_split': 26, 'min_samples_leaf': 42}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:29,058] Trial 101 finished with value: -0.6757075376197484 and parameters: {'n_estimators': 161, 'max_depth': 45, 'min_samples_split': 21, 'min_samples_leaf': 1}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:30,244] Trial 102 finished with value: -1.5051735329982128 and parameters: {'n_estimators': 453, 'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 48}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:31,639] Trial 103 finished with value: -1.5119134173309452 and parameters: {'n_estimators': 476, 'max_depth': 30, 'min_samples_split': 32, 'min_samples_leaf': 23}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:32,056] Trial 104 finished with value: -1.5208360403241377 and parameters: {'n_estimators': 148, 'max_depth': 18, 'min_samples_split': 34, 'min_samples_leaf': 38}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:33,079] Trial 105 finished with value: -1.501789073670077 and parameters: {'n_estimators': 396, 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 25}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:33,180] Trial 106 finished with value: -1.4944316653428185 and parameters: {'n_estimators': 30, 'max_depth': 28, 'min_samples_split': 23, 'min_samples_leaf': 45}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:33,828] Trial 107 finished with value: -1.491951965447713 and parameters: {'n_estimators': 177, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 39}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:34,677] Trial 108 finished with value: -1.499801247250872 and parameters: {'n_estimators': 310, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 36}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:34,824] Trial 109 finished with value: -1.4491359131315733 and parameters: {'n_estimators': 38, 'max_depth': 42, 'min_samples_split': 36, 'min_samples_leaf': 5}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:34,972] Trial 110 finished with value: -1.5057785732261437 and parameters: {'n_estimators': 44, 'max_depth': 50, 'min_samples_split': 20, 'min_samples_leaf': 19}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:35,906] Trial 111 finished with value: -1.51214797774088 and parameters: {'n_estimators': 407, 'max_depth': 48, 'min_samples_split': 50, 'min_samples_leaf': 38}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:36,360] Trial 112 finished with value: -1.4998534472832248 and parameters: {'n_estimators': 189, 'max_depth': 6, 'min_samples_split': 40, 'min_samples_leaf': 28}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:36,889] Trial 113 finished with value: -1.4973510250997664 and parameters: {'n_estimators': 213, 'max_depth': 46, 'min_samples_split': 7, 'min_samples_leaf': 25}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:36,924] Trial 114 finished with value: -0.7268262740284388 and parameters: {'n_estimators': 7, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:37,050] Trial 115 finished with value: -1.5150574027627275 and parameters: {'n_estimators': 60, 'max_depth': 33, 'min_samples_split': 38, 'min_samples_leaf': 30}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:37,954] Trial 116 finished with value: -1.493362805573507 and parameters: {'n_estimators': 482, 'max_depth': 20, 'min_samples_split': 15, 'min_samples_leaf': 44}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:38,196] Trial 117 finished with value: -1.4815653906036892 and parameters: {'n_estimators': 113, 'max_depth': 49, 'min_samples_split': 2, 'min_samples_leaf': 49}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:38,262] Trial 118 finished with value: -1.522630396986982 and parameters: {'n_estimators': 23, 'max_depth': 45, 'min_samples_split': 27, 'min_samples_leaf': 50}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:38,348] Trial 119 finished with value: -1.515766835072011 and parameters: {'n_estimators': 38, 'max_depth': 29, 'min_samples_split': 49, 'min_samples_leaf': 27}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:38,964] Trial 120 finished with value: -1.4882836442107101 and parameters: {'n_estimators': 316, 'max_depth': 36, 'min_samples_split': 24, 'min_samples_leaf': 32}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:39,744] Trial 121 finished with value: -1.5122604744797399 and parameters: {'n_estimators': 293, 'max_depth': 46, 'min_samples_split': 4, 'min_samples_leaf': 15}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:40,627] Trial 122 finished with value: -1.4994719288386515 and parameters: {'n_estimators': 476, 'max_depth': 45, 'min_samples_split': 24, 'min_samples_leaf': 32}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:40,906] Trial 123 finished with value: -1.5026871976633458 and parameters: {'n_estimators': 140, 'max_depth': 11, 'min_samples_split': 24, 'min_samples_leaf': 18}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:41,467] Trial 124 finished with value: -1.5026045492582163 and parameters: {'n_estimators': 293, 'max_depth': 5, 'min_samples_split': 49, 'min_samples_leaf': 50}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:42,121] Trial 125 finished with value: -1.5068413174676283 and parameters: {'n_estimators': 350, 'max_depth': 28, 'min_samples_split': 17, 'min_samples_leaf': 41}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:42,770] Trial 126 finished with value: -1.4934481087028944 and parameters: {'n_estimators': 343, 'max_depth': 9, 'min_samples_split': 46, 'min_samples_leaf': 42}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:43,666] Trial 127 finished with value: -1.5017859071696953 and parameters: {'n_estimators': 475, 'max_depth': 37, 'min_samples_split': 32, 'min_samples_leaf': 21}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:44,608] Trial 128 finished with value: -0.5260559209398487 and parameters: {'n_estimators': 467, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:44,981] Trial 129 finished with value: -1.4986427032105385 and parameters: {'n_estimators': 189, 'max_depth': 41, 'min_samples_split': 50, 'min_samples_leaf': 8}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:45,548] Trial 130 finished with value: -1.496483149174124 and parameters: {'n_estimators': 298, 'max_depth': 20, 'min_samples_split': 49, 'min_samples_leaf': 43}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:46,347] Trial 131 finished with value: -1.4178803604047876 and parameters: {'n_estimators': 420, 'max_depth': 24, 'min_samples_split': 22, 'min_samples_leaf': 14}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:46,434] Trial 132 finished with value: -1.4848120917550203 and parameters: {'n_estimators': 30, 'max_depth': 44, 'min_samples_split': 41, 'min_samples_leaf': 50}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:47,360] Trial 133 finished with value: -1.4959911424276646 and parameters: {'n_estimators': 499, 'max_depth': 29, 'min_samples_split': 39, 'min_samples_leaf': 48}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:48,188] Trial 134 finished with value: -0.8212051089647826 and parameters: {'n_estimators': 425, 'max_depth': 14, 'min_samples_split': 24, 'min_samples_leaf': 7}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:49,081] Trial 135 finished with value: -1.5187485511792858 and parameters: {'n_estimators': 478, 'max_depth': 31, 'min_samples_split': 13, 'min_samples_leaf': 34}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:49,701] Trial 136 finished with value: -1.5023501310281886 and parameters: {'n_estimators': 310, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 34}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:50,189] Trial 137 finished with value: -1.4833075127091144 and parameters: {'n_estimators': 261, 'max_depth': 39, 'min_samples_split': 27, 'min_samples_leaf': 43}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:50,713] Trial 138 finished with value: -1.5186120747453293 and parameters: {'n_estimators': 277, 'max_depth': 29, 'min_samples_split': 44, 'min_samples_leaf': 21}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:50,858] Trial 139 finished with value: -1.4549218542078615 and parameters: {'n_estimators': 68, 'max_depth': 3, 'min_samples_split': 39, 'min_samples_leaf': 32}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:51,717] Trial 140 finished with value: -0.5118952242936498 and parameters: {'n_estimators': 353, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:52,055] Trial 141 finished with value: -1.5112321587568514 and parameters: {'n_estimators': 176, 'max_depth': 30, 'min_samples_split': 21, 'min_samples_leaf': 22}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:52,895] Trial 142 finished with value: -1.5085027405839866 and parameters: {'n_estimators': 453, 'max_depth': 19, 'min_samples_split': 27, 'min_samples_leaf': 40}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:53,277] Trial 143 finished with value: -1.5124489735985263 and parameters: {'n_estimators': 199, 'max_depth': 32, 'min_samples_split': 44, 'min_samples_leaf': 48}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:53,435] Trial 144 finished with value: -1.2725380906622434 and parameters: {'n_estimators': 75, 'max_depth': 47, 'min_samples_split': 26, 'min_samples_leaf': 13}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:53,875] Trial 145 finished with value: -1.5124351226777852 and parameters: {'n_estimators': 231, 'max_depth': 50, 'min_samples_split': 26, 'min_samples_leaf': 17}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:54,493] Trial 146 finished with value: -0.7577033004857402 and parameters: {'n_estimators': 318, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:54,631] Trial 147 finished with value: -1.490828239605555 and parameters: {'n_estimators': 65, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 33}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:54,815] Trial 148 finished with value: -1.499988501606199 and parameters: {'n_estimators': 92, 'max_depth': 18, 'min_samples_split': 45, 'min_samples_leaf': 24}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:55,466] Trial 149 finished with value: -0.6387054889271979 and parameters: {'n_estimators': 335, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:55,650] Trial 150 finished with value: -0.7116203955225513 and parameters: {'n_estimators': 86, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:55,783] Trial 151 finished with value: -1.4821607698077288 and parameters: {'n_estimators': 62, 'max_depth': 24, 'min_samples_split': 12, 'min_samples_leaf': 19}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:56,258] Trial 152 finished with value: -1.5108166817186524 and parameters: {'n_estimators': 253, 'max_depth': 35, 'min_samples_split': 3, 'min_samples_leaf': 40}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:56,844] Trial 153 finished with value: -1.501949214357872 and parameters: {'n_estimators': 315, 'max_depth': 6, 'min_samples_split': 44, 'min_samples_leaf': 47}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:56,926] Trial 154 finished with value: -1.5030637584005098 and parameters: {'n_estimators': 32, 'max_depth': 15, 'min_samples_split': 41, 'min_samples_leaf': 38}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:57,114] Trial 155 finished with value: -1.5122159549697811 and parameters: {'n_estimators': 94, 'max_depth': 12, 'min_samples_split': 20, 'min_samples_leaf': 25}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:57,682] Trial 156 finished with value: -1.4941872664372424 and parameters: {'n_estimators': 310, 'max_depth': 20, 'min_samples_split': 24, 'min_samples_leaf': 38}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:57,737] Trial 157 finished with value: -1.4979697489031696 and parameters: {'n_estimators': 20, 'max_depth': 14, 'min_samples_split': 36, 'min_samples_leaf': 45}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:58,214] Trial 158 finished with value: -1.5155439606108732 and parameters: {'n_estimators': 257, 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 23}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:58,721] Trial 159 finished with value: -1.5018329013436567 and parameters: {'n_estimators': 267, 'max_depth': 13, 'min_samples_split': 15, 'min_samples_leaf': 19}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:58,764] Trial 160 finished with value: -1.479791114594389 and parameters: {'n_estimators': 12, 'max_depth': 17, 'min_samples_split': 12, 'min_samples_leaf': 17}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:58,889] Trial 161 finished with value: -1.5046277868085642 and parameters: {'n_estimators': 61, 'max_depth': 45, 'min_samples_split': 31, 'min_samples_leaf': 34}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:13:59,651] Trial 162 finished with value: -1.4931164484530697 and parameters: {'n_estimators': 395, 'max_depth': 26, 'min_samples_split': 6, 'min_samples_leaf': 27}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:00,220] Trial 163 finished with value: -0.8074741781913346 and parameters: {'n_estimators': 294, 'max_depth': 38, 'min_samples_split': 23, 'min_samples_leaf': 7}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:00,507] Trial 164 finished with value: -1.4932357910892706 and parameters: {'n_estimators': 143, 'max_depth': 19, 'min_samples_split': 33, 'min_samples_leaf': 29}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:00,853] Trial 165 finished with value: -1.5059310956221303 and parameters: {'n_estimators': 179, 'max_depth': 50, 'min_samples_split': 31, 'min_samples_leaf': 12}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:00,973] Trial 166 finished with value: -0.8597528898638054 and parameters: {'n_estimators': 52, 'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 9}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:01,171] Trial 167 finished with value: -1.5127418150309768 and parameters: {'n_estimators': 95, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 45}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:01,269] Trial 168 finished with value: -1.5298831383600506 and parameters: {'n_estimators': 42, 'max_depth': 27, 'min_samples_split': 22, 'min_samples_leaf': 50}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:01,385] Trial 169 finished with value: -1.4962704969752365 and parameters: {'n_estimators': 57, 'max_depth': 21, 'min_samples_split': 49, 'min_samples_leaf': 44}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:02,131] Trial 170 finished with value: -1.4946782141656452 and parameters: {'n_estimators': 409, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 34}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:02,991] Trial 171 finished with value: -1.494858185172776 and parameters: {'n_estimators': 465, 'max_depth': 29, 'min_samples_split': 30, 'min_samples_leaf': 14}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:03,713] Trial 172 finished with value: -1.5009041990171545 and parameters: {'n_estimators': 385, 'max_depth': 11, 'min_samples_split': 17, 'min_samples_leaf': 22}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:04,195] Trial 173 finished with value: -1.5057887506284258 and parameters: {'n_estimators': 255, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 31}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:04,484] Trial 174 finished with value: -1.5102729349414177 and parameters: {'n_estimators': 146, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 25}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:05,006] Trial 175 finished with value: -0.7699293086362443 and parameters: {'n_estimators': 267, 'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 7}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:05,083] Trial 176 finished with value: -1.531546465015194 and parameters: {'n_estimators': 33, 'max_depth': 50, 'min_samples_split': 17, 'min_samples_leaf': 41}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:05,491] Trial 177 finished with value: -1.5100814264455586 and parameters: {'n_estimators': 129, 'max_depth': 35, 'min_samples_split': 39, 'min_samples_leaf': 30}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:05,940] Trial 178 finished with value: -1.4866420403879579 and parameters: {'n_estimators': 237, 'max_depth': 22, 'min_samples_split': 19, 'min_samples_leaf': 47}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:06,705] Trial 179 finished with value: -1.4961181862546054 and parameters: {'n_estimators': 416, 'max_depth': 49, 'min_samples_split': 8, 'min_samples_leaf': 37}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:07,569] Trial 180 finished with value: -1.4920485795615008 and parameters: {'n_estimators': 470, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 38}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:08,099] Trial 181 finished with value: -1.5022547497519485 and parameters: {'n_estimators': 288, 'max_depth': 43, 'min_samples_split': 8, 'min_samples_leaf': 40}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:08,304] Trial 182 finished with value: -1.4954498852023852 and parameters: {'n_estimators': 102, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 41}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:08,944] Trial 183 finished with value: -1.504520772099467 and parameters: {'n_estimators': 333, 'max_depth': 27, 'min_samples_split': 19, 'min_samples_leaf': 44}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:09,317] Trial 184 finished with value: -1.4986142338884878 and parameters: {'n_estimators': 197, 'max_depth': 42, 'min_samples_split': 23, 'min_samples_leaf': 19}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:09,817] Trial 185 finished with value: -1.488364181510621 and parameters: {'n_estimators': 232, 'max_depth': 16, 'min_samples_split': 38, 'min_samples_leaf': 26}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:10,047] Trial 186 finished with value: -1.5043628238965412 and parameters: {'n_estimators': 117, 'max_depth': 46, 'min_samples_split': 20, 'min_samples_leaf': 28}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:10,878] Trial 187 finished with value: -1.494518607880189 and parameters: {'n_estimators': 454, 'max_depth': 32, 'min_samples_split': 7, 'min_samples_leaf': 47}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:11,472] Trial 188 finished with value: -1.5033182498852449 and parameters: {'n_estimators': 315, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 40}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:12,057] Trial 189 finished with value: -1.4909396597510525 and parameters: {'n_estimators': 311, 'max_depth': 28, 'min_samples_split': 45, 'min_samples_leaf': 40}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:12,220] Trial 190 finished with value: -1.5058314929687646 and parameters: {'n_estimators': 77, 'max_depth': 17, 'min_samples_split': 14, 'min_samples_leaf': 38}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:12,277] Trial 191 finished with value: -1.5182742788556962 and parameters: {'n_estimators': 18, 'max_depth': 29, 'min_samples_split': 39, 'min_samples_leaf': 44}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:12,596] Trial 192 finished with value: -1.494131490983853 and parameters: {'n_estimators': 172, 'max_depth': 42, 'min_samples_split': 7, 'min_samples_leaf': 43}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:12,732] Trial 193 finished with value: -1.4889074999251792 and parameters: {'n_estimators': 65, 'max_depth': 21, 'min_samples_split': 41, 'min_samples_leaf': 8}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:12,960] Trial 194 finished with value: -1.5097113716208084 and parameters: {'n_estimators': 116, 'max_depth': 37, 'min_samples_split': 37, 'min_samples_leaf': 33}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:13,605] Trial 195 finished with value: -1.4793580773638575 and parameters: {'n_estimators': 348, 'max_depth': 28, 'min_samples_split': 14, 'min_samples_leaf': 18}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:13,800] Trial 196 finished with value: -1.4904871024228463 and parameters: {'n_estimators': 92, 'max_depth': 46, 'min_samples_split': 30, 'min_samples_leaf': 21}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:14,246] Trial 197 finished with value: -1.483038328936448 and parameters: {'n_estimators': 232, 'max_depth': 48, 'min_samples_split': 9, 'min_samples_leaf': 30}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:14,720] Trial 198 finished with value: -1.509427276455554 and parameters: {'n_estimators': 254, 'max_depth': 31, 'min_samples_split': 2, 'min_samples_leaf': 44}. Best is trial 92 with value: -0.5092009309640215.\n",
      "[I 2024-07-29 13:14:15,576] Trial 199 finished with value: -1.4932629863222249 and parameters: {'n_estimators': 467, 'max_depth': 29, 'min_samples_split': 36, 'min_samples_leaf': 47}. Best is trial 92 with value: -0.5092009309640215.\n"
     ]
    }
   ],
   "source": [
    "study_noise.optimize(lambda trial: objective(trial, np.array(list((x_train_noise))).astype(float), y_train_noise), n_trials=200, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc37cdf98d374f6baf8babe5b28856e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 13:14:16,351] Trial 0 finished with value: -1.5169363729938703 and parameters: {'n_estimators': 188, 'max_depth': 48, 'min_samples_split': 37, 'min_samples_leaf': 30}. Best is trial 0 with value: -1.5169363729938703.\n",
      "[I 2024-07-29 13:14:16,510] Trial 1 finished with value: -1.501407584090083 and parameters: {'n_estimators': 79, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 44}. Best is trial 1 with value: -1.501407584090083.\n",
      "[I 2024-07-29 13:14:17,082] Trial 2 finished with value: -1.4968018732497892 and parameters: {'n_estimators': 301, 'max_depth': 36, 'min_samples_split': 3, 'min_samples_leaf': 49}. Best is trial 2 with value: -1.4968018732497892.\n",
      "[I 2024-07-29 13:14:17,926] Trial 3 finished with value: -1.2643938586039054 and parameters: {'n_estimators': 417, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:18,238] Trial 4 finished with value: -1.4584903448030198 and parameters: {'n_estimators': 153, 'max_depth': 27, 'min_samples_split': 23, 'min_samples_leaf': 15}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:18,836] Trial 5 finished with value: -1.4698739790605688 and parameters: {'n_estimators': 307, 'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 19}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:19,267] Trial 6 finished with value: -1.4900021549050995 and parameters: {'n_estimators': 229, 'max_depth': 40, 'min_samples_split': 11, 'min_samples_leaf': 26}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:19,874] Trial 7 finished with value: -1.3241079192437157 and parameters: {'n_estimators': 297, 'max_depth': 4, 'min_samples_split': 31, 'min_samples_leaf': 9}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:19,960] Trial 8 finished with value: -1.4780494941388735 and parameters: {'n_estimators': 34, 'max_depth': 48, 'min_samples_split': 49, 'min_samples_leaf': 41}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:20,257] Trial 9 finished with value: -1.5036206748481764 and parameters: {'n_estimators': 154, 'max_depth': 6, 'min_samples_split': 35, 'min_samples_leaf': 23}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:20,388] Trial 10 finished with value: -1.497204508750865 and parameters: {'n_estimators': 62, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 46}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:20,641] Trial 11 finished with value: -1.5039077811136803 and parameters: {'n_estimators': 131, 'max_depth': 34, 'min_samples_split': 17, 'min_samples_leaf': 27}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:21,162] Trial 12 finished with value: -1.491141054641057 and parameters: {'n_estimators': 274, 'max_depth': 11, 'min_samples_split': 49, 'min_samples_leaf': 39}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:22,042] Trial 13 finished with value: -1.5104346887925388 and parameters: {'n_estimators': 470, 'max_depth': 45, 'min_samples_split': 31, 'min_samples_leaf': 47}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:22,148] Trial 14 finished with value: -1.4817343623669874 and parameters: {'n_estimators': 46, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 17}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:22,523] Trial 15 finished with value: -1.483211413477989 and parameters: {'n_estimators': 195, 'max_depth': 15, 'min_samples_split': 42, 'min_samples_leaf': 18}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:22,801] Trial 16 finished with value: -1.4962259389255852 and parameters: {'n_estimators': 142, 'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 41}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:22,895] Trial 17 finished with value: -1.4153103300672765 and parameters: {'n_estimators': 39, 'max_depth': 50, 'min_samples_split': 39, 'min_samples_leaf': 10}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:22,920] Trial 18 finished with value: -1.5147523967553012 and parameters: {'n_estimators': 4, 'max_depth': 41, 'min_samples_split': 36, 'min_samples_leaf': 37}. Best is trial 3 with value: -1.2643938586039054.\n",
      "[I 2024-07-29 13:14:23,761] Trial 19 finished with value: -1.1171036669291283 and parameters: {'n_estimators': 386, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 6}. Best is trial 19 with value: -1.1171036669291283.\n",
      "[I 2024-07-29 13:14:24,674] Trial 20 finished with value: -1.0486742054266807 and parameters: {'n_estimators': 432, 'max_depth': 32, 'min_samples_split': 18, 'min_samples_leaf': 4}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:24,983] Trial 21 finished with value: -1.495384748506194 and parameters: {'n_estimators': 157, 'max_depth': 17, 'min_samples_split': 37, 'min_samples_leaf': 32}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:25,801] Trial 22 finished with value: -1.5033835696374758 and parameters: {'n_estimators': 444, 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 36}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:26,501] Trial 23 finished with value: -1.5006799821085557 and parameters: {'n_estimators': 381, 'max_depth': 29, 'min_samples_split': 39, 'min_samples_leaf': 25}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:27,017] Trial 24 finished with value: -1.0852219202263038 and parameters: {'n_estimators': 262, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:27,069] Trial 25 finished with value: -1.4922555234866377 and parameters: {'n_estimators': 17, 'max_depth': 33, 'min_samples_split': 17, 'min_samples_leaf': 26}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:27,903] Trial 26 finished with value: -1.4968284353981285 and parameters: {'n_estimators': 454, 'max_depth': 14, 'min_samples_split': 22, 'min_samples_leaf': 38}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:28,149] Trial 27 finished with value: -1.2275298211470471 and parameters: {'n_estimators': 116, 'max_depth': 5, 'min_samples_split': 16, 'min_samples_leaf': 9}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:29,014] Trial 28 finished with value: -1.5016446161555443 and parameters: {'n_estimators': 465, 'max_depth': 41, 'min_samples_split': 33, 'min_samples_leaf': 44}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:29,753] Trial 29 finished with value: -1.5045042116260194 and parameters: {'n_estimators': 403, 'max_depth': 11, 'min_samples_split': 45, 'min_samples_leaf': 27}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:30,575] Trial 30 finished with value: -1.1109421901441807 and parameters: {'n_estimators': 404, 'max_depth': 45, 'min_samples_split': 17, 'min_samples_leaf': 6}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:30,817] Trial 31 finished with value: -1.4993824480990683 and parameters: {'n_estimators': 115, 'max_depth': 22, 'min_samples_split': 42, 'min_samples_leaf': 44}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:30,846] Trial 32 finished with value: -1.219773480480954 and parameters: {'n_estimators': 5, 'max_depth': 27, 'min_samples_split': 22, 'min_samples_leaf': 12}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:30,973] Trial 33 finished with value: -1.5046964582750202 and parameters: {'n_estimators': 61, 'max_depth': 18, 'min_samples_split': 48, 'min_samples_leaf': 17}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:31,615] Trial 34 finished with value: -1.4982878898739276 and parameters: {'n_estimators': 260, 'max_depth': 36, 'min_samples_split': 19, 'min_samples_leaf': 49}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:32,525] Trial 35 finished with value: -1.4559559378564106 and parameters: {'n_estimators': 482, 'max_depth': 14, 'min_samples_split': 26, 'min_samples_leaf': 16}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:32,811] Trial 36 finished with value: -1.4997617436828623 and parameters: {'n_estimators': 144, 'max_depth': 3, 'min_samples_split': 31, 'min_samples_leaf': 26}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:32,883] Trial 37 finished with value: -1.4845147625194413 and parameters: {'n_estimators': 27, 'max_depth': 15, 'min_samples_split': 46, 'min_samples_leaf': 12}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:33,033] Trial 38 finished with value: -1.5004468004251699 and parameters: {'n_estimators': 74, 'max_depth': 25, 'min_samples_split': 50, 'min_samples_leaf': 13}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:33,677] Trial 39 finished with value: -1.5079178872499885 and parameters: {'n_estimators': 337, 'max_depth': 39, 'min_samples_split': 13, 'min_samples_leaf': 37}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:34,036] Trial 40 finished with value: -1.4900827575549038 and parameters: {'n_estimators': 185, 'max_depth': 32, 'min_samples_split': 33, 'min_samples_leaf': 27}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:34,141] Trial 41 finished with value: -1.2821204654076241 and parameters: {'n_estimators': 47, 'max_depth': 42, 'min_samples_split': 17, 'min_samples_leaf': 10}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:34,203] Trial 42 finished with value: -1.2239311427741915 and parameters: {'n_estimators': 22, 'max_depth': 30, 'min_samples_split': 35, 'min_samples_leaf': 1}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:34,699] Trial 43 finished with value: -1.342547081203847 and parameters: {'n_estimators': 257, 'max_depth': 13, 'min_samples_split': 33, 'min_samples_leaf': 9}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:35,356] Trial 44 finished with value: -1.4866482454362218 and parameters: {'n_estimators': 346, 'max_depth': 20, 'min_samples_split': 47, 'min_samples_leaf': 7}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:35,691] Trial 45 finished with value: -1.4874857974683686 and parameters: {'n_estimators': 172, 'max_depth': 7, 'min_samples_split': 47, 'min_samples_leaf': 44}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:35,943] Trial 46 finished with value: -1.4889720012934025 and parameters: {'n_estimators': 130, 'max_depth': 34, 'min_samples_split': 42, 'min_samples_leaf': 28}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:36,445] Trial 47 finished with value: -1.50086044649924 and parameters: {'n_estimators': 266, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 45}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:37,300] Trial 48 finished with value: -1.4757436064216554 and parameters: {'n_estimators': 451, 'max_depth': 33, 'min_samples_split': 18, 'min_samples_leaf': 18}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:37,966] Trial 49 finished with value: -1.5054588600396137 and parameters: {'n_estimators': 364, 'max_depth': 45, 'min_samples_split': 45, 'min_samples_leaf': 39}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:38,567] Trial 50 finished with value: -1.4974421074049356 and parameters: {'n_estimators': 322, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 45}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:39,141] Trial 51 finished with value: -1.4972122932072227 and parameters: {'n_estimators': 304, 'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 34}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:39,169] Trial 52 finished with value: -1.451565962789965 and parameters: {'n_estimators': 4, 'max_depth': 9, 'min_samples_split': 28, 'min_samples_leaf': 35}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:39,792] Trial 53 finished with value: -1.3945777519757359 and parameters: {'n_estimators': 327, 'max_depth': 12, 'min_samples_split': 36, 'min_samples_leaf': 12}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:40,126] Trial 54 finished with value: -1.5128877582149491 and parameters: {'n_estimators': 164, 'max_depth': 38, 'min_samples_split': 33, 'min_samples_leaf': 43}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:40,776] Trial 55 finished with value: -1.4873387626402015 and parameters: {'n_estimators': 330, 'max_depth': 29, 'min_samples_split': 6, 'min_samples_leaf': 19}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:41,050] Trial 56 finished with value: -1.4967435025048623 and parameters: {'n_estimators': 134, 'max_depth': 13, 'min_samples_split': 49, 'min_samples_leaf': 20}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:41,882] Trial 57 finished with value: -1.5000342005488796 and parameters: {'n_estimators': 447, 'max_depth': 32, 'min_samples_split': 40, 'min_samples_leaf': 26}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:42,426] Trial 58 finished with value: -1.4897228954532347 and parameters: {'n_estimators': 289, 'max_depth': 26, 'min_samples_split': 11, 'min_samples_leaf': 37}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:42,708] Trial 59 finished with value: -1.324486171818789 and parameters: {'n_estimators': 142, 'max_depth': 3, 'min_samples_split': 33, 'min_samples_leaf': 9}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:43,567] Trial 60 finished with value: -1.4948907918884948 and parameters: {'n_estimators': 471, 'max_depth': 48, 'min_samples_split': 46, 'min_samples_leaf': 19}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:43,602] Trial 61 finished with value: -1.4850824706227095 and parameters: {'n_estimators': 9, 'max_depth': 47, 'min_samples_split': 22, 'min_samples_leaf': 49}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:44,584] Trial 62 finished with value: -1.5006518565301898 and parameters: {'n_estimators': 482, 'max_depth': 43, 'min_samples_split': 16, 'min_samples_leaf': 20}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:45,621] Trial 63 finished with value: -1.5004957947114372 and parameters: {'n_estimators': 426, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 28}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:46,910] Trial 64 finished with value: -1.1886509167378994 and parameters: {'n_estimators': 469, 'max_depth': 36, 'min_samples_split': 29, 'min_samples_leaf': 5}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:47,940] Trial 65 finished with value: -1.4932278560646757 and parameters: {'n_estimators': 308, 'max_depth': 50, 'min_samples_split': 8, 'min_samples_leaf': 26}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:48,970] Trial 66 finished with value: -1.5002988842297615 and parameters: {'n_estimators': 439, 'max_depth': 38, 'min_samples_split': 36, 'min_samples_leaf': 36}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:49,430] Trial 67 finished with value: -1.5154490244680079 and parameters: {'n_estimators': 181, 'max_depth': 16, 'min_samples_split': 41, 'min_samples_leaf': 41}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:50,606] Trial 68 finished with value: -1.5060536327295893 and parameters: {'n_estimators': 434, 'max_depth': 46, 'min_samples_split': 27, 'min_samples_leaf': 26}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:51,727] Trial 69 finished with value: -1.5027831340075566 and parameters: {'n_estimators': 400, 'max_depth': 33, 'min_samples_split': 36, 'min_samples_leaf': 40}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:52,824] Trial 70 finished with value: -1.081739514308524 and parameters: {'n_estimators': 446, 'max_depth': 18, 'min_samples_split': 20, 'min_samples_leaf': 5}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:53,461] Trial 71 finished with value: -1.48993947035488 and parameters: {'n_estimators': 290, 'max_depth': 3, 'min_samples_split': 24, 'min_samples_leaf': 28}. Best is trial 20 with value: -1.0486742054266807.\n",
      "[I 2024-07-29 13:14:53,833] Trial 72 finished with value: -0.9653110018202415 and parameters: {'n_estimators': 144, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 72 with value: -0.9653110018202415.\n",
      "[I 2024-07-29 13:14:54,625] Trial 73 finished with value: -1.5044500037266517 and parameters: {'n_estimators': 412, 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 27}. Best is trial 72 with value: -0.9653110018202415.\n",
      "[I 2024-07-29 13:14:55,391] Trial 74 finished with value: -1.254403699256146 and parameters: {'n_estimators': 386, 'max_depth': 12, 'min_samples_split': 32, 'min_samples_leaf': 5}. Best is trial 72 with value: -0.9653110018202415.\n",
      "[I 2024-07-29 13:14:55,462] Trial 75 finished with value: -1.500966792559193 and parameters: {'n_estimators': 27, 'max_depth': 28, 'min_samples_split': 28, 'min_samples_leaf': 32}. Best is trial 72 with value: -0.9653110018202415.\n",
      "[I 2024-07-29 13:14:56,175] Trial 76 finished with value: -1.4769343716411918 and parameters: {'n_estimators': 364, 'max_depth': 49, 'min_samples_split': 27, 'min_samples_leaf': 17}. Best is trial 72 with value: -0.9653110018202415.\n",
      "[I 2024-07-29 13:14:56,996] Trial 77 finished with value: -1.0845805773005792 and parameters: {'n_estimators': 398, 'max_depth': 15, 'min_samples_split': 23, 'min_samples_leaf': 4}. Best is trial 72 with value: -0.9653110018202415.\n",
      "[I 2024-07-29 13:14:57,050] Trial 78 finished with value: -1.5107744962894043 and parameters: {'n_estimators': 14, 'max_depth': 49, 'min_samples_split': 42, 'min_samples_leaf': 35}. Best is trial 72 with value: -0.9653110018202415.\n",
      "[I 2024-07-29 13:14:57,472] Trial 79 finished with value: -1.4017098167147153 and parameters: {'n_estimators': 206, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 13}. Best is trial 72 with value: -0.9653110018202415.\n",
      "[I 2024-07-29 13:14:58,036] Trial 80 finished with value: -1.453208561438407 and parameters: {'n_estimators': 276, 'max_depth': 37, 'min_samples_split': 34, 'min_samples_leaf': 14}. Best is trial 72 with value: -0.9653110018202415.\n",
      "[I 2024-07-29 13:14:58,947] Trial 81 finished with value: -1.4982472310745347 and parameters: {'n_estimators': 478, 'max_depth': 38, 'min_samples_split': 29, 'min_samples_leaf': 31}. Best is trial 72 with value: -0.9653110018202415.\n",
      "[I 2024-07-29 13:14:59,374] Trial 82 finished with value: -1.5111032489158525 and parameters: {'n_estimators': 211, 'max_depth': 14, 'min_samples_split': 19, 'min_samples_leaf': 38}. Best is trial 72 with value: -0.9653110018202415.\n",
      "[I 2024-07-29 13:14:59,417] Trial 83 finished with value: -0.8843748764716926 and parameters: {'n_estimators': 9, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:00,276] Trial 84 finished with value: -1.1218389496008987 and parameters: {'n_estimators': 428, 'max_depth': 36, 'min_samples_split': 25, 'min_samples_leaf': 5}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:00,802] Trial 85 finished with value: -1.5034771061183096 and parameters: {'n_estimators': 247, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 22}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:01,383] Trial 86 finished with value: -1.2362321891941812 and parameters: {'n_estimators': 200, 'max_depth': 32, 'min_samples_split': 33, 'min_samples_leaf': 3}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:01,767] Trial 87 finished with value: -1.4988079694751528 and parameters: {'n_estimators': 188, 'max_depth': 32, 'min_samples_split': 26, 'min_samples_leaf': 43}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:02,408] Trial 88 finished with value: -1.5015510653407038 and parameters: {'n_estimators': 330, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 33}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:02,452] Trial 89 finished with value: -1.4821064394298458 and parameters: {'n_estimators': 15, 'max_depth': 30, 'min_samples_split': 48, 'min_samples_leaf': 29}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:02,824] Trial 90 finished with value: -1.4842998306002646 and parameters: {'n_estimators': 195, 'max_depth': 33, 'min_samples_split': 24, 'min_samples_leaf': 28}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:03,725] Trial 91 finished with value: -1.502432185652763 and parameters: {'n_estimators': 471, 'max_depth': 20, 'min_samples_split': 49, 'min_samples_leaf': 46}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:03,953] Trial 92 finished with value: -0.9836551630954595 and parameters: {'n_estimators': 99, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:04,071] Trial 93 finished with value: -1.455386160085471 and parameters: {'n_estimators': 49, 'max_depth': 35, 'min_samples_split': 5, 'min_samples_leaf': 16}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:04,877] Trial 94 finished with value: -1.4354425012416068 and parameters: {'n_estimators': 423, 'max_depth': 3, 'min_samples_split': 41, 'min_samples_leaf': 15}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:05,017] Trial 95 finished with value: -1.5115512063074656 and parameters: {'n_estimators': 60, 'max_depth': 36, 'min_samples_split': 32, 'min_samples_leaf': 44}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:05,746] Trial 96 finished with value: -1.2226587238734903 and parameters: {'n_estimators': 368, 'max_depth': 41, 'min_samples_split': 15, 'min_samples_leaf': 9}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:06,467] Trial 97 finished with value: -1.4946176248616303 and parameters: {'n_estimators': 376, 'max_depth': 41, 'min_samples_split': 50, 'min_samples_leaf': 21}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:06,832] Trial 98 finished with value: -1.4868614749255298 and parameters: {'n_estimators': 187, 'max_depth': 40, 'min_samples_split': 18, 'min_samples_leaf': 47}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:07,635] Trial 99 finished with value: -1.4981937790163928 and parameters: {'n_estimators': 430, 'max_depth': 23, 'min_samples_split': 38, 'min_samples_leaf': 38}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:07,755] Trial 100 finished with value: -1.4960065204538782 and parameters: {'n_estimators': 53, 'max_depth': 46, 'min_samples_split': 26, 'min_samples_leaf': 42}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:08,118] Trial 101 finished with value: -1.0503174791621344 and parameters: {'n_estimators': 161, 'max_depth': 45, 'min_samples_split': 21, 'min_samples_leaf': 1}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:08,968] Trial 102 finished with value: -1.492665151489433 and parameters: {'n_estimators': 453, 'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 48}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:09,859] Trial 103 finished with value: -1.5051550675359906 and parameters: {'n_estimators': 476, 'max_depth': 30, 'min_samples_split': 32, 'min_samples_leaf': 23}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:10,162] Trial 104 finished with value: -1.498095296137207 and parameters: {'n_estimators': 148, 'max_depth': 18, 'min_samples_split': 34, 'min_samples_leaf': 38}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:10,947] Trial 105 finished with value: -1.5065565680700623 and parameters: {'n_estimators': 396, 'max_depth': 40, 'min_samples_split': 6, 'min_samples_leaf': 25}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:11,027] Trial 106 finished with value: -1.5190582765602183 and parameters: {'n_estimators': 30, 'max_depth': 28, 'min_samples_split': 23, 'min_samples_leaf': 45}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:11,372] Trial 107 finished with value: -1.5116260401256487 and parameters: {'n_estimators': 177, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 39}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:11,965] Trial 108 finished with value: -1.5024399182354196 and parameters: {'n_estimators': 310, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 36}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:12,061] Trial 109 finished with value: -1.271174813638039 and parameters: {'n_estimators': 38, 'max_depth': 42, 'min_samples_split': 36, 'min_samples_leaf': 5}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:12,157] Trial 110 finished with value: -1.4894593062856365 and parameters: {'n_estimators': 44, 'max_depth': 50, 'min_samples_split': 20, 'min_samples_leaf': 19}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:12,922] Trial 111 finished with value: -1.5030811550548537 and parameters: {'n_estimators': 407, 'max_depth': 48, 'min_samples_split': 50, 'min_samples_leaf': 38}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:13,296] Trial 112 finished with value: -1.4943396331151904 and parameters: {'n_estimators': 189, 'max_depth': 6, 'min_samples_split': 40, 'min_samples_leaf': 28}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:13,707] Trial 113 finished with value: -1.5063963261624704 and parameters: {'n_estimators': 213, 'max_depth': 46, 'min_samples_split': 7, 'min_samples_leaf': 25}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:13,745] Trial 114 finished with value: -1.2686093278299593 and parameters: {'n_estimators': 7, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:13,888] Trial 115 finished with value: -1.5161312312479978 and parameters: {'n_estimators': 60, 'max_depth': 33, 'min_samples_split': 38, 'min_samples_leaf': 30}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:14,845] Trial 116 finished with value: -1.4936068977486987 and parameters: {'n_estimators': 482, 'max_depth': 20, 'min_samples_split': 15, 'min_samples_leaf': 44}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:15,214] Trial 117 finished with value: -1.5110051046006414 and parameters: {'n_estimators': 113, 'max_depth': 49, 'min_samples_split': 2, 'min_samples_leaf': 49}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:15,297] Trial 118 finished with value: -1.5060652430956663 and parameters: {'n_estimators': 23, 'max_depth': 45, 'min_samples_split': 27, 'min_samples_leaf': 50}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:15,394] Trial 119 finished with value: -1.4917155790116154 and parameters: {'n_estimators': 38, 'max_depth': 29, 'min_samples_split': 49, 'min_samples_leaf': 27}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:16,064] Trial 120 finished with value: -1.5059626925911285 and parameters: {'n_estimators': 316, 'max_depth': 36, 'min_samples_split': 24, 'min_samples_leaf': 32}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:16,660] Trial 121 finished with value: -1.4402916017592058 and parameters: {'n_estimators': 293, 'max_depth': 46, 'min_samples_split': 4, 'min_samples_leaf': 15}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:17,557] Trial 122 finished with value: -1.4989229711916288 and parameters: {'n_estimators': 476, 'max_depth': 45, 'min_samples_split': 24, 'min_samples_leaf': 32}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:17,848] Trial 123 finished with value: -1.4645531451424516 and parameters: {'n_estimators': 140, 'max_depth': 11, 'min_samples_split': 24, 'min_samples_leaf': 18}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:18,423] Trial 124 finished with value: -1.50703585240251 and parameters: {'n_estimators': 293, 'max_depth': 5, 'min_samples_split': 49, 'min_samples_leaf': 50}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:19,085] Trial 125 finished with value: -1.499327244951676 and parameters: {'n_estimators': 350, 'max_depth': 28, 'min_samples_split': 17, 'min_samples_leaf': 41}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:19,735] Trial 126 finished with value: -1.4938004195228636 and parameters: {'n_estimators': 343, 'max_depth': 9, 'min_samples_split': 46, 'min_samples_leaf': 42}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:20,645] Trial 127 finished with value: -1.4969075051105696 and parameters: {'n_estimators': 475, 'max_depth': 37, 'min_samples_split': 32, 'min_samples_leaf': 21}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:21,685] Trial 128 finished with value: -0.96822183063715 and parameters: {'n_estimators': 467, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:22,069] Trial 129 finished with value: -1.5094745326303738 and parameters: {'n_estimators': 189, 'max_depth': 41, 'min_samples_split': 50, 'min_samples_leaf': 8}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:22,645] Trial 130 finished with value: -1.5066106225630425 and parameters: {'n_estimators': 298, 'max_depth': 20, 'min_samples_split': 49, 'min_samples_leaf': 43}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:23,471] Trial 131 finished with value: -1.4385616094860225 and parameters: {'n_estimators': 420, 'max_depth': 24, 'min_samples_split': 22, 'min_samples_leaf': 14}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:23,549] Trial 132 finished with value: -1.5105486824922447 and parameters: {'n_estimators': 30, 'max_depth': 44, 'min_samples_split': 41, 'min_samples_leaf': 50}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:24,516] Trial 133 finished with value: -1.5028608996129447 and parameters: {'n_estimators': 499, 'max_depth': 29, 'min_samples_split': 39, 'min_samples_leaf': 48}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:25,510] Trial 134 finished with value: -1.159294942102694 and parameters: {'n_estimators': 425, 'max_depth': 14, 'min_samples_split': 24, 'min_samples_leaf': 7}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:26,406] Trial 135 finished with value: -1.49987939011702 and parameters: {'n_estimators': 478, 'max_depth': 31, 'min_samples_split': 13, 'min_samples_leaf': 34}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:27,013] Trial 136 finished with value: -1.5113896342704645 and parameters: {'n_estimators': 310, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 34}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:27,520] Trial 137 finished with value: -1.490343120286953 and parameters: {'n_estimators': 261, 'max_depth': 39, 'min_samples_split': 27, 'min_samples_leaf': 43}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:28,105] Trial 138 finished with value: -1.4940140792961767 and parameters: {'n_estimators': 277, 'max_depth': 29, 'min_samples_split': 44, 'min_samples_leaf': 21}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:28,254] Trial 139 finished with value: -1.5067968219763341 and parameters: {'n_estimators': 68, 'max_depth': 3, 'min_samples_split': 39, 'min_samples_leaf': 32}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:29,005] Trial 140 finished with value: -0.9879651391317383 and parameters: {'n_estimators': 353, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:29,367] Trial 141 finished with value: -1.4924829023333248 and parameters: {'n_estimators': 176, 'max_depth': 30, 'min_samples_split': 21, 'min_samples_leaf': 22}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:30,216] Trial 142 finished with value: -1.495080220537977 and parameters: {'n_estimators': 453, 'max_depth': 19, 'min_samples_split': 27, 'min_samples_leaf': 40}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:30,607] Trial 143 finished with value: -1.5118674613849155 and parameters: {'n_estimators': 199, 'max_depth': 32, 'min_samples_split': 44, 'min_samples_leaf': 48}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:30,769] Trial 144 finished with value: -1.3808503647090355 and parameters: {'n_estimators': 75, 'max_depth': 47, 'min_samples_split': 26, 'min_samples_leaf': 13}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:31,261] Trial 145 finished with value: -1.4748516050912315 and parameters: {'n_estimators': 231, 'max_depth': 50, 'min_samples_split': 26, 'min_samples_leaf': 17}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:31,921] Trial 146 finished with value: -1.137366358669277 and parameters: {'n_estimators': 318, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:32,066] Trial 147 finished with value: -1.509684310795627 and parameters: {'n_estimators': 65, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 33}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:32,260] Trial 148 finished with value: -1.5144216418601482 and parameters: {'n_estimators': 92, 'max_depth': 18, 'min_samples_split': 45, 'min_samples_leaf': 24}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:32,950] Trial 149 finished with value: -1.0163031143531494 and parameters: {'n_estimators': 335, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:33,147] Trial 150 finished with value: -1.0304766405590198 and parameters: {'n_estimators': 86, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:33,298] Trial 151 finished with value: -1.47152980846981 and parameters: {'n_estimators': 62, 'max_depth': 24, 'min_samples_split': 12, 'min_samples_leaf': 19}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:33,804] Trial 152 finished with value: -1.4958574202293484 and parameters: {'n_estimators': 253, 'max_depth': 35, 'min_samples_split': 3, 'min_samples_leaf': 40}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:34,552] Trial 153 finished with value: -1.5030955191659303 and parameters: {'n_estimators': 315, 'max_depth': 6, 'min_samples_split': 44, 'min_samples_leaf': 47}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:34,637] Trial 154 finished with value: -1.525955905288112 and parameters: {'n_estimators': 32, 'max_depth': 15, 'min_samples_split': 41, 'min_samples_leaf': 38}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:34,832] Trial 155 finished with value: -1.5059903293858645 and parameters: {'n_estimators': 94, 'max_depth': 12, 'min_samples_split': 20, 'min_samples_leaf': 25}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:35,445] Trial 156 finished with value: -1.5001171090524972 and parameters: {'n_estimators': 310, 'max_depth': 20, 'min_samples_split': 24, 'min_samples_leaf': 38}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:35,504] Trial 157 finished with value: -1.4920924469729475 and parameters: {'n_estimators': 20, 'max_depth': 14, 'min_samples_split': 36, 'min_samples_leaf': 45}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:35,993] Trial 158 finished with value: -1.494888065600748 and parameters: {'n_estimators': 257, 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 23}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:36,538] Trial 159 finished with value: -1.4754197300818892 and parameters: {'n_estimators': 267, 'max_depth': 13, 'min_samples_split': 15, 'min_samples_leaf': 19}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:36,587] Trial 160 finished with value: -1.4287703747207074 and parameters: {'n_estimators': 12, 'max_depth': 17, 'min_samples_split': 12, 'min_samples_leaf': 17}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:36,715] Trial 161 finished with value: -1.513721556528931 and parameters: {'n_estimators': 61, 'max_depth': 45, 'min_samples_split': 31, 'min_samples_leaf': 34}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:37,457] Trial 162 finished with value: -1.501555670755733 and parameters: {'n_estimators': 395, 'max_depth': 26, 'min_samples_split': 6, 'min_samples_leaf': 27}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:38,050] Trial 163 finished with value: -1.1785784717415542 and parameters: {'n_estimators': 294, 'max_depth': 38, 'min_samples_split': 23, 'min_samples_leaf': 7}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:38,342] Trial 164 finished with value: -1.4932059027343407 and parameters: {'n_estimators': 143, 'max_depth': 19, 'min_samples_split': 33, 'min_samples_leaf': 29}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:38,704] Trial 165 finished with value: -1.4176060834347097 and parameters: {'n_estimators': 179, 'max_depth': 50, 'min_samples_split': 31, 'min_samples_leaf': 12}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:38,988] Trial 166 finished with value: -1.2664344592709125 and parameters: {'n_estimators': 52, 'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 9}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:39,183] Trial 167 finished with value: -1.5012816300021712 and parameters: {'n_estimators': 95, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 45}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:39,285] Trial 168 finished with value: -1.5130901799202496 and parameters: {'n_estimators': 42, 'max_depth': 27, 'min_samples_split': 22, 'min_samples_leaf': 50}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:39,409] Trial 169 finished with value: -1.5125631974943692 and parameters: {'n_estimators': 57, 'max_depth': 21, 'min_samples_split': 49, 'min_samples_leaf': 44}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:40,178] Trial 170 finished with value: -1.499139153361184 and parameters: {'n_estimators': 409, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 34}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:41,189] Trial 171 finished with value: -1.4439915707704494 and parameters: {'n_estimators': 465, 'max_depth': 29, 'min_samples_split': 30, 'min_samples_leaf': 14}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:42,045] Trial 172 finished with value: -1.4958510834838883 and parameters: {'n_estimators': 385, 'max_depth': 11, 'min_samples_split': 17, 'min_samples_leaf': 22}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:42,561] Trial 173 finished with value: -1.5046865907047555 and parameters: {'n_estimators': 255, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 31}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:42,857] Trial 174 finished with value: -1.4937336985400933 and parameters: {'n_estimators': 146, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 25}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:43,516] Trial 175 finished with value: -1.148863258106599 and parameters: {'n_estimators': 267, 'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 7}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:43,655] Trial 176 finished with value: -1.4810841174316052 and parameters: {'n_estimators': 33, 'max_depth': 50, 'min_samples_split': 17, 'min_samples_leaf': 41}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:44,134] Trial 177 finished with value: -1.4895688408283543 and parameters: {'n_estimators': 129, 'max_depth': 35, 'min_samples_split': 39, 'min_samples_leaf': 30}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:44,884] Trial 178 finished with value: -1.5126016564212095 and parameters: {'n_estimators': 237, 'max_depth': 22, 'min_samples_split': 19, 'min_samples_leaf': 47}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:46,038] Trial 179 finished with value: -1.502969833816102 and parameters: {'n_estimators': 416, 'max_depth': 49, 'min_samples_split': 8, 'min_samples_leaf': 37}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:47,454] Trial 180 finished with value: -1.492201825620083 and parameters: {'n_estimators': 470, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 38}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:48,183] Trial 181 finished with value: -1.5072156552953473 and parameters: {'n_estimators': 288, 'max_depth': 43, 'min_samples_split': 8, 'min_samples_leaf': 40}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:48,597] Trial 182 finished with value: -1.4966969649938766 and parameters: {'n_estimators': 102, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 41}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:49,723] Trial 183 finished with value: -1.5001014219546964 and parameters: {'n_estimators': 333, 'max_depth': 27, 'min_samples_split': 19, 'min_samples_leaf': 44}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:50,349] Trial 184 finished with value: -1.4809000214151027 and parameters: {'n_estimators': 197, 'max_depth': 42, 'min_samples_split': 23, 'min_samples_leaf': 19}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:50,939] Trial 185 finished with value: -1.5175577870567207 and parameters: {'n_estimators': 232, 'max_depth': 16, 'min_samples_split': 38, 'min_samples_leaf': 26}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:51,289] Trial 186 finished with value: -1.5075213521540178 and parameters: {'n_estimators': 117, 'max_depth': 46, 'min_samples_split': 20, 'min_samples_leaf': 28}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:52,408] Trial 187 finished with value: -1.4946467667398196 and parameters: {'n_estimators': 454, 'max_depth': 32, 'min_samples_split': 7, 'min_samples_leaf': 47}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:53,377] Trial 188 finished with value: -1.498991448574608 and parameters: {'n_estimators': 315, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 40}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:54,142] Trial 189 finished with value: -1.5064598118809518 and parameters: {'n_estimators': 311, 'max_depth': 28, 'min_samples_split': 45, 'min_samples_leaf': 40}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:54,355] Trial 190 finished with value: -1.492253760820712 and parameters: {'n_estimators': 77, 'max_depth': 17, 'min_samples_split': 14, 'min_samples_leaf': 38}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:54,425] Trial 191 finished with value: -1.5073856453267627 and parameters: {'n_estimators': 18, 'max_depth': 29, 'min_samples_split': 39, 'min_samples_leaf': 44}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:54,851] Trial 192 finished with value: -1.4853489061377705 and parameters: {'n_estimators': 172, 'max_depth': 42, 'min_samples_split': 7, 'min_samples_leaf': 43}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:55,033] Trial 193 finished with value: -1.3994460100327175 and parameters: {'n_estimators': 65, 'max_depth': 21, 'min_samples_split': 41, 'min_samples_leaf': 8}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:55,333] Trial 194 finished with value: -1.494347107784464 and parameters: {'n_estimators': 116, 'max_depth': 37, 'min_samples_split': 37, 'min_samples_leaf': 33}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:56,328] Trial 195 finished with value: -1.468494956623195 and parameters: {'n_estimators': 348, 'max_depth': 28, 'min_samples_split': 14, 'min_samples_leaf': 18}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:56,587] Trial 196 finished with value: -1.5006025012450728 and parameters: {'n_estimators': 92, 'max_depth': 46, 'min_samples_split': 30, 'min_samples_leaf': 21}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:57,152] Trial 197 finished with value: -1.497139849018853 and parameters: {'n_estimators': 232, 'max_depth': 48, 'min_samples_split': 9, 'min_samples_leaf': 30}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:57,793] Trial 198 finished with value: -1.5030302938310256 and parameters: {'n_estimators': 254, 'max_depth': 31, 'min_samples_split': 2, 'min_samples_leaf': 44}. Best is trial 83 with value: -0.8843748764716926.\n",
      "[I 2024-07-29 13:15:58,952] Trial 199 finished with value: -1.509168761199533 and parameters: {'n_estimators': 467, 'max_depth': 29, 'min_samples_split': 36, 'min_samples_leaf': 47}. Best is trial 83 with value: -0.8843748764716926.\n"
     ]
    }
   ],
   "source": [
    "study_fur.optimize(lambda trial: objective(trial, np.array(list((x_train_fur))).astype(float), y_train_fur), n_trials=200, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_rand = study_rand.best_params\n",
    "best_params_strat = study_strat.best_params\n",
    "best_params_hi = study_hi.best_params\n",
    "best_params_noise = study_noise.best_params\n",
    "best_params_fur = study_fur.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n_estimators_rand = best_params_rand[\"n_estimators\"]\n",
    "best_max_depth_rand = best_params_rand[\"max_depth\"]\n",
    "best_min_samples_split_rand = best_params_rand[\"min_samples_split\"]\n",
    "best_min_samples_leaf_rand = best_params_rand[\"min_samples_leaf\"]\n",
    "\n",
    "best_n_estimators_strat = best_params_strat[\"n_estimators\"]\n",
    "best_max_depth_strat = best_params_strat[\"max_depth\"]\n",
    "best_min_samples_split_strat = best_params_strat[\"min_samples_split\"]\n",
    "best_min_samples_leaf_strat = best_params_strat[\"min_samples_leaf\"]\n",
    "\n",
    "best_n_estimators_hi = best_params_hi[\"n_estimators\"]\n",
    "best_max_depth_hi = best_params_hi[\"max_depth\"]\n",
    "best_min_samples_split_hi = best_params_hi[\"min_samples_split\"]\n",
    "best_min_samples_leaf_hi = best_params_hi[\"min_samples_leaf\"]\n",
    "\n",
    "best_n_estimators_noise = best_params_noise[\"n_estimators\"]\n",
    "best_max_depth_noise = best_params_noise[\"max_depth\"]\n",
    "best_min_samples_split_noise = best_params_noise[\"min_samples_split\"]\n",
    "best_min_samples_leaf_noise = best_params_noise[\"min_samples_leaf\"]\n",
    "\n",
    "best_n_estimators_fur = best_params_fur[\"n_estimators\"]\n",
    "best_max_depth_fur = best_params_fur[\"max_depth\"]\n",
    "best_min_samples_split_fur = best_params_fur[\"min_samples_split\"]\n",
    "best_min_samples_leaf_fur = best_params_fur[\"min_samples_leaf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rfr_rand_best = RandomForestRegressor(random_state=SEED, n_estimators=best_n_estimators_rand, max_depth=best_max_depth_rand, min_samples_split=best_min_samples_split_rand, min_samples_leaf=best_min_samples_leaf_rand)\n",
    "rfr_strat_best = RandomForestRegressor(random_state=SEED, n_estimators=best_n_estimators_strat, max_depth=best_max_depth_strat, min_samples_split=best_min_samples_split_strat, min_samples_leaf=best_min_samples_leaf_strat)\n",
    "rfr_hi_best = RandomForestRegressor(random_state=SEED, n_estimators=best_n_estimators_hi, max_depth=best_max_depth_hi, min_samples_split=best_min_samples_split_hi, min_samples_leaf=best_min_samples_leaf_hi)\n",
    "rfr_noise_best = RandomForestRegressor(random_state=SEED, n_estimators=best_n_estimators_noise, max_depth=best_max_depth_noise, min_samples_split=best_min_samples_split_noise, min_samples_leaf=best_min_samples_leaf_noise)\n",
    "rfr_fur_best = RandomForestRegressor(random_state=SEED, n_estimators=best_n_estimators_fur, max_depth=best_max_depth_fur, min_samples_split=best_min_samples_split_fur, min_samples_leaf=best_min_samples_leaf_fur)\n",
    "\n",
    "rfr_rand_best.fit(np.array(list((x_train_rand))).astype(float), y_train_rand)\n",
    "rfr_strat_best.fit(np.array(list((x_train_strat))).astype(float), y_train_strat)\n",
    "rfr_hi_best.fit(np.array(list((x_train_hi))).astype(float), y_train_hi)\n",
    "rfr_noise_best.fit(np.array(list((x_train_noise))).astype(float), y_train_noise)\n",
    "rfr_fur_best.fit(np.array(list((x_train_fur))).astype(float), y_train_fur)\n",
    "\n",
    "y_pred_rfr_rand_best = rfr_rand_best.predict(np.array(list((x_test_rand))).astype(float))\n",
    "y_pred_rfr_strat_best = rfr_strat_best.predict(np.array(list((x_test_strat))).astype(float))\n",
    "y_pred_rfr_hi_best = rfr_hi_best.predict(np.array(list((x_test_hi))).astype(float))\n",
    "y_pred_rfr_noise_best = rfr_noise_best.predict(np.array(list((x_test_noise))).astype(float))\n",
    "y_pred_rfr_fur_best = rfr_fur_best.predict(np.array(list((x_test_fur))).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Split       MAE       MSE        R2\n",
      "0                             Random  0.382970  0.309122  0.579999\n",
      "1                   Random Optimized  0.393117  0.310572  0.578029\n",
      "2                   Stratified pIC50  0.461976  0.423172  0.516725\n",
      "3         Stratified pIC50 Optimized  0.504089  0.459178  0.475605\n",
      "4            Hierarchical Clustering  0.674829  0.705286  0.323519\n",
      "5  Hierarchical Clustering Optimized  0.681877  0.710977  0.318060\n",
      "6                         UMAP Noise  0.787113  0.913533 -0.179115\n",
      "7               UMAP Noise Optimized  0.784079  0.897608 -0.158560\n",
      "8              UMAP Furthest Cluster  0.839491  0.938845 -0.237629\n",
      "9    UMAP Furthest Cluster Optimized  0.876427  1.058782 -0.395735\n"
     ]
    }
   ],
   "source": [
    "                                          \n",
    "mae_rfr_rand_best = mean_absolute_error(y_test_rand, y_pred_rfr_rand_best)\n",
    "mae_rfr_strat_best = mean_absolute_error(y_test_strat, y_pred_rfr_strat_best)\n",
    "mae_rfr_hi_best = mean_absolute_error(y_test_hi, y_pred_rfr_hi_best)\n",
    "mae_rfr_noise_best = mean_absolute_error(y_test_noise, y_pred_rfr_noise_best)\n",
    "mae_rfr_fur_best = mean_absolute_error(y_test_fur, y_pred_rfr_fur_best)\n",
    "\n",
    "mse_rfr_rand_best = mean_squared_error(y_test_rand, y_pred_rfr_rand_best)\n",
    "mse_rfr_strat_best = mean_squared_error(y_test_strat, y_pred_rfr_strat_best)\n",
    "mse_rfr_hi_best = mean_squared_error(y_test_hi, y_pred_rfr_hi_best)\n",
    "mse_rfr_noise_best = mean_squared_error(y_test_noise, y_pred_rfr_noise_best)\n",
    "mse_rfr_fur_best = mean_squared_error(y_test_fur, y_pred_rfr_fur_best)\n",
    "\n",
    "r2_rfr_rand_best = r2_score(y_test_rand, y_pred_rfr_rand_best)\n",
    "r2_rfr_strat_best = r2_score(y_test_strat, y_pred_rfr_strat_best)\n",
    "r2_rfr_hi_best = r2_score(y_test_hi, y_pred_rfr_hi_best)\n",
    "r2_rfr_noise_best = r2_score(y_test_noise, y_pred_rfr_noise_best)\n",
    "r2_rfr_fur_best = r2_score(y_test_fur, y_pred_rfr_fur_best)\n",
    "\n",
    "split_scores_rfr_best = {'Split': ['Random', 'Random Optimized', 'Stratified pIC50', 'Stratified pIC50 Optimized', 'Hierarchical Clustering', 'Hierarchical Clustering Optimized', 'UMAP Noise', 'UMAP Noise Optimized', 'UMAP Furthest Cluster', 'UMAP Furthest Cluster Optimized'],\n",
    "        'MAE': [mae_rfr_rand, mae_rfr_rand_best, mae_rfr_strat, mae_rfr_strat_best, mae_rfr_hi, mae_rfr_hi_best, mae_rfr_noise, mae_rfr_noise_best, mae_rfr_fur, mae_rfr_fur_best],\n",
    "        'MSE': [mse_rfr_rand, mse_rfr_rand_best, mse_rfr_strat, mse_rfr_strat_best, mse_rfr_hi, mse_rfr_hi_best, mse_rfr_noise, mse_rfr_noise_best, mse_rfr_fur, mse_rfr_fur_best],\n",
    "        'R2': [r2_rfr_rand, r2_rfr_rand_best, r2_rfr_strat, r2_rfr_strat_best, r2_rfr_hi, r2_rfr_hi_best, r2_rfr_noise, r2_rfr_noise_best, r2_rfr_fur, r2_rfr_fur_best]}\n",
    "split_scores_rfr_best_df = pd.DataFrame(split_scores_rfr_best)\n",
    "print(split_scores_rfr_best_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299
         ],
         "y": [
          -0.6656641089023417,
          -0.7199505312988174,
          -0.7367121976165063,
          -0.5292824062760534,
          -0.5830638868068412,
          -0.6064985347750641,
          -0.6491396998330222,
          -0.5826558004544863,
          -0.7198382886238155,
          -0.6365594301626742,
          -0.7281212908735382,
          -0.6567363850441149,
          -0.6971412048790289,
          -0.7318348418229933,
          -0.6021902447489296,
          -0.6095886765036791,
          -0.7049809567680899,
          -0.5781707407675112,
          -0.7123111220953364,
          -0.5362297911996794,
          -0.48017143082383884,
          -0.6732099911144622,
          -0.6871998722518835,
          -0.6451410464166459,
          -0.4865594303939796,
          -0.6592189387766794,
          -0.693749189617136,
          -0.5394283111696837,
          -0.7215100690263254,
          -0.6504891641206486,
          -0.4936523772550081,
          -0.7190855088498597,
          -0.599901048813782,
          -0.620023220707351,
          -0.739729699618376,
          -0.5868279331750592,
          -0.6772506231255955,
          -0.5984380868184219,
          -0.6030898048350053,
          -0.6889229626111054,
          -0.6567346634068175,
          -0.5365280459528657,
          -0.5272902657503901,
          -0.55476088410808,
          -0.5774739914576263,
          -0.7206731014378128,
          -0.6649548646105757,
          -0.7282491320559438,
          -0.6023232035720847,
          -0.6979804239242376,
          -0.7253736482763804,
          -0.7364879531961795,
          -0.711902803318176,
          -0.5737354691618617,
          -0.720535430248012,
          -0.6140083975027244,
          -0.6308245622960367,
          -0.6491367580542484,
          -0.6892499103324194,
          -0.6394667580300355,
          -0.6217007472408888,
          -0.7516591987491003,
          -0.6137926197457685,
          -0.6572579621960393,
          -0.5183900208959733,
          -0.6485154077168571,
          -0.6861660653026901,
          -0.7079831661724818,
          -0.6507224003498766,
          -0.7008536636091017,
          -0.4951070763191515,
          -0.6786431670312996,
          -0.41712153744953867,
          -0.6530125755125364,
          -0.526232061303389,
          -0.6742692149713619,
          -0.5960874918976857,
          -0.49784523287761334,
          -0.7003034569002038,
          -0.5575261891851576,
          -0.5810795517404739,
          -0.6726223115203235,
          -0.694091583716562,
          -0.4861664314808126,
          -0.507416950495764,
          -0.6236326493753502,
          -0.5189671029336714,
          -0.7148407544852687,
          -0.6754185858520529,
          -0.7008124318678354,
          -0.6566906022367149,
          -0.7297684135600907,
          -0.4936445929582338,
          -0.5888379459234767,
          -0.6552274852289299,
          -0.7234335841567957,
          -0.5205696945991554,
          -0.633683600587547,
          -0.7322348031482341,
          -0.6937724542282755,
          -0.7103115372826633,
          -0.46884903303831527,
          -0.7350335184364061,
          -0.6357446263478554,
          -0.699773639185317,
          -0.6426578549811641,
          -0.726331002000095,
          -0.7046598199178369,
          -0.6877898034463746,
          -0.5525448469417281,
          -0.6072339340162648,
          -0.6946773147751654,
          -0.6554228057432875,
          -0.645021404016406,
          -0.5355676250624591,
          -0.6673732599985004,
          -0.7207819349945828,
          -0.7367207691047118,
          -0.7420911130977956,
          -0.6623641291825696,
          -0.6733691584391432,
          -0.5784691515708678,
          -0.672501061485665,
          -0.6036173020115925,
          -0.7378608921985318,
          -0.7086040899138626,
          -0.712465567142827,
          -0.6218786407188801,
          -0.4212134071076507,
          -0.5949471355620071,
          -0.7180744675724976,
          -0.5718444534185849,
          -0.7461401220979981,
          -0.7364451171482014,
          -0.5199233971097994,
          -0.6800661540612681,
          -0.684591705417201,
          -0.7185719666659782,
          -0.6216570790776361,
          -0.6884627522610869,
          -0.4309189236051133,
          -0.6340999971005971,
          -0.7049066735302822,
          -0.736095298396033,
          -0.5575661424557397,
          -0.5959313226084771,
          -0.5016420552290282,
          -0.6805391832296139,
          -0.6444461857333621,
          -0.4534311163839527,
          -0.47800147184878217,
          -0.6102641644057103,
          -0.7026023478696585,
          -0.7318410180459475,
          -0.6963147970356646,
          -0.642521595182975,
          -0.694945447973849,
          -0.7236210394028701,
          -0.6371319622457132,
          -0.6115631916304534,
          -0.6197233672065339,
          -0.676852588031575,
          -0.6528228850417255,
          -0.5211290232513768,
          -0.6654746909093561,
          -0.5636770700760805,
          -0.5175294276770354,
          -0.7268309692759534,
          -0.7406732821462988,
          -0.7244714284554623,
          -0.6771246795649218,
          -0.5738367943428421,
          -0.630059648664337,
          -0.6689786995690049,
          -0.6456385184089161,
          -0.5722304897299145,
          -0.7113690927547311,
          -0.6691184189269346,
          -0.7318861081941135,
          -0.6936201319594906,
          -0.6931301582428836,
          -0.7041098042916085,
          -0.7097183812834033,
          -0.7198481850934192,
          -0.6099603367831075,
          -0.6491512326214742,
          -0.6582898973695747,
          -0.7324866917533177,
          -0.6998170595673473,
          -0.7034158277071753,
          -0.6960785719312466,
          -0.7329104413017982,
          -0.7156840344107442,
          -0.5707474312936985,
          -0.6761639437737672,
          -0.6000102899875186,
          -0.6274440192800002,
          -0.6647295143875589,
          -0.7229885297048648,
          -0.7316851825880548,
          -0.6696044965221162,
          -0.7306129079287002,
          -0.7127968428609461,
          -0.6474466610642047,
          -0.5989142140222063,
          -0.7279520642017981,
          -0.6020729755651013,
          -0.6380264676883958,
          -0.6257526641657168,
          -0.6708333375154425,
          -0.7578233877174643,
          -0.7441611774895801,
          -0.6901953291032891,
          -0.5329652656024522,
          -0.5143749599108404,
          -0.6360197751044895,
          -0.531214555818096,
          -0.5688468200400122,
          -0.5078299289366355,
          -0.5509438186349598,
          -0.4864710548841935,
          -0.5653485969688753,
          -0.7221656977912196,
          -0.5646007388336587,
          -0.46611103733010184,
          -0.6805926648942202,
          -0.6125803512915705,
          -0.5740819386506406,
          -0.6247846010472962,
          -0.5667914055211967,
          -0.7026247461990621,
          -0.6767910787381247,
          -0.7118415145174344,
          -0.5680370727366446,
          -0.6619589024880559,
          -0.7113497640589168,
          -0.7486448026882424,
          -0.6788979361480916,
          -0.6154254779287277,
          -0.6889159699262372,
          -0.6180324814496077,
          -0.5838917014456367,
          -0.7356237605361198,
          -0.5682705094225385,
          -0.6663499638514605,
          -0.46176092237448574,
          -0.6284230075335148,
          -0.6801673404468926,
          -0.4936154585972261,
          -0.6373346837646287,
          -0.6965632065195855,
          -0.7214794070692744,
          -0.7412778765745585,
          -0.7303234753161248,
          -0.5611764201724139,
          -0.7363624422846056,
          -0.7180400916979447,
          -0.6681008871286774,
          -0.6812125402915006,
          -0.5884714836752222,
          -0.6755427794821022,
          -0.4497491571032429,
          -0.677293592678948,
          -0.6236895350248963,
          -0.6720504362637552,
          -0.6244630718918318,
          -0.48639822932872046,
          -0.551487612858421,
          -0.7356891659184572,
          -0.7356971786938408,
          -0.7223269473354956,
          -0.5499787650843161,
          -0.6770742267311218,
          -0.5221103797392065,
          -0.6066831694126149,
          -0.7278244879018139,
          -0.6952997155263386,
          -0.584159231412447,
          -0.6685154538991902,
          -0.5048338955860439,
          -0.7070019022696826,
          -0.6250023102477418,
          -0.646680312845219,
          -0.5379270872572142,
          -0.6654700817651202,
          -0.6636247872533302,
          -0.6792009826672004,
          -0.7137492455263932,
          -0.6945490215814906,
          -0.5585793459661609,
          -0.694684268570096,
          -0.6541532216221689,
          -0.7459895737522535,
          -0.6523654444704798,
          -0.6578189153874607,
          -0.7304803138532602,
          -0.5419238152300471,
          -0.6606622731024856,
          -0.7206965991143776,
          -0.5593332812885137
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299
         ],
         "y": [
          -0.6656641089023417,
          -0.6656641089023417,
          -0.6656641089023417,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.5292824062760534,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.48017143082383884,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867,
          -0.41712153744953867
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dark lines are parameters that work better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "Objective Value",
           "range": [
            -0.7578233877174643,
            -0.41712153744953867
           ],
           "values": [
            -0.6656641089023417,
            -0.7199505312988174,
            -0.7367121976165063,
            -0.5292824062760534,
            -0.5830638868068412,
            -0.6064985347750641,
            -0.6491396998330222,
            -0.5826558004544863,
            -0.7198382886238155,
            -0.6365594301626742,
            -0.7281212908735382,
            -0.6567363850441149,
            -0.6971412048790289,
            -0.7318348418229933,
            -0.6021902447489296,
            -0.6095886765036791,
            -0.7049809567680899,
            -0.5781707407675112,
            -0.7123111220953364,
            -0.5362297911996794,
            -0.48017143082383884,
            -0.6732099911144622,
            -0.6871998722518835,
            -0.6451410464166459,
            -0.4865594303939796,
            -0.6592189387766794,
            -0.693749189617136,
            -0.5394283111696837,
            -0.7215100690263254,
            -0.6504891641206486,
            -0.4936523772550081,
            -0.7190855088498597,
            -0.599901048813782,
            -0.620023220707351,
            -0.739729699618376,
            -0.5868279331750592,
            -0.6772506231255955,
            -0.5984380868184219,
            -0.6030898048350053,
            -0.6889229626111054,
            -0.6567346634068175,
            -0.5365280459528657,
            -0.5272902657503901,
            -0.55476088410808,
            -0.5774739914576263,
            -0.7206731014378128,
            -0.6649548646105757,
            -0.7282491320559438,
            -0.6023232035720847,
            -0.6979804239242376,
            -0.7253736482763804,
            -0.7364879531961795,
            -0.711902803318176,
            -0.5737354691618617,
            -0.720535430248012,
            -0.6140083975027244,
            -0.6308245622960367,
            -0.6491367580542484,
            -0.6892499103324194,
            -0.6394667580300355,
            -0.6217007472408888,
            -0.7516591987491003,
            -0.6137926197457685,
            -0.6572579621960393,
            -0.5183900208959733,
            -0.6485154077168571,
            -0.6861660653026901,
            -0.7079831661724818,
            -0.6507224003498766,
            -0.7008536636091017,
            -0.4951070763191515,
            -0.6786431670312996,
            -0.41712153744953867,
            -0.6530125755125364,
            -0.526232061303389,
            -0.6742692149713619,
            -0.5960874918976857,
            -0.49784523287761334,
            -0.7003034569002038,
            -0.5575261891851576,
            -0.5810795517404739,
            -0.6726223115203235,
            -0.694091583716562,
            -0.4861664314808126,
            -0.507416950495764,
            -0.6236326493753502,
            -0.5189671029336714,
            -0.7148407544852687,
            -0.6754185858520529,
            -0.7008124318678354,
            -0.6566906022367149,
            -0.7297684135600907,
            -0.4936445929582338,
            -0.5888379459234767,
            -0.6552274852289299,
            -0.7234335841567957,
            -0.5205696945991554,
            -0.633683600587547,
            -0.7322348031482341,
            -0.6937724542282755,
            -0.7103115372826633,
            -0.46884903303831527,
            -0.7350335184364061,
            -0.6357446263478554,
            -0.699773639185317,
            -0.6426578549811641,
            -0.726331002000095,
            -0.7046598199178369,
            -0.6877898034463746,
            -0.5525448469417281,
            -0.6072339340162648,
            -0.6946773147751654,
            -0.6554228057432875,
            -0.645021404016406,
            -0.5355676250624591,
            -0.6673732599985004,
            -0.7207819349945828,
            -0.7367207691047118,
            -0.7420911130977956,
            -0.6623641291825696,
            -0.6733691584391432,
            -0.5784691515708678,
            -0.672501061485665,
            -0.6036173020115925,
            -0.7378608921985318,
            -0.7086040899138626,
            -0.712465567142827,
            -0.6218786407188801,
            -0.4212134071076507,
            -0.5949471355620071,
            -0.7180744675724976,
            -0.5718444534185849,
            -0.7461401220979981,
            -0.7364451171482014,
            -0.5199233971097994,
            -0.6800661540612681,
            -0.684591705417201,
            -0.7185719666659782,
            -0.6216570790776361,
            -0.6884627522610869,
            -0.4309189236051133,
            -0.6340999971005971,
            -0.7049066735302822,
            -0.736095298396033,
            -0.5575661424557397,
            -0.5959313226084771,
            -0.5016420552290282,
            -0.6805391832296139,
            -0.6444461857333621,
            -0.4534311163839527,
            -0.47800147184878217,
            -0.6102641644057103,
            -0.7026023478696585,
            -0.7318410180459475,
            -0.6963147970356646,
            -0.642521595182975,
            -0.694945447973849,
            -0.7236210394028701,
            -0.6371319622457132,
            -0.6115631916304534,
            -0.6197233672065339,
            -0.676852588031575,
            -0.6528228850417255,
            -0.5211290232513768,
            -0.6654746909093561,
            -0.5636770700760805,
            -0.5175294276770354,
            -0.7268309692759534,
            -0.7406732821462988,
            -0.7244714284554623,
            -0.6771246795649218,
            -0.5738367943428421,
            -0.630059648664337,
            -0.6689786995690049,
            -0.6456385184089161,
            -0.5722304897299145,
            -0.7113690927547311,
            -0.6691184189269346,
            -0.7318861081941135,
            -0.6936201319594906,
            -0.6931301582428836,
            -0.7041098042916085,
            -0.7097183812834033,
            -0.7198481850934192,
            -0.6099603367831075,
            -0.6491512326214742,
            -0.6582898973695747,
            -0.7324866917533177,
            -0.6998170595673473,
            -0.7034158277071753,
            -0.6960785719312466,
            -0.7329104413017982,
            -0.7156840344107442,
            -0.5707474312936985,
            -0.6761639437737672,
            -0.6000102899875186,
            -0.6274440192800002,
            -0.6647295143875589,
            -0.7229885297048648,
            -0.7316851825880548,
            -0.6696044965221162,
            -0.7306129079287002,
            -0.7127968428609461,
            -0.6474466610642047,
            -0.5989142140222063,
            -0.7279520642017981,
            -0.6020729755651013,
            -0.6380264676883958,
            -0.6257526641657168,
            -0.6708333375154425,
            -0.7578233877174643,
            -0.7441611774895801,
            -0.6901953291032891,
            -0.5329652656024522,
            -0.5143749599108404,
            -0.6360197751044895,
            -0.531214555818096,
            -0.5688468200400122,
            -0.5078299289366355,
            -0.5509438186349598,
            -0.4864710548841935,
            -0.5653485969688753,
            -0.7221656977912196,
            -0.5646007388336587,
            -0.46611103733010184,
            -0.6805926648942202,
            -0.6125803512915705,
            -0.5740819386506406,
            -0.6247846010472962,
            -0.5667914055211967,
            -0.7026247461990621,
            -0.6767910787381247,
            -0.7118415145174344,
            -0.5680370727366446,
            -0.6619589024880559,
            -0.7113497640589168,
            -0.7486448026882424,
            -0.6788979361480916,
            -0.6154254779287277,
            -0.6889159699262372,
            -0.6180324814496077,
            -0.5838917014456367,
            -0.7356237605361198,
            -0.5682705094225385,
            -0.6663499638514605,
            -0.46176092237448574,
            -0.6284230075335148,
            -0.6801673404468926,
            -0.4936154585972261,
            -0.6373346837646287,
            -0.6965632065195855,
            -0.7214794070692744,
            -0.7412778765745585,
            -0.7303234753161248,
            -0.5611764201724139,
            -0.7363624422846056,
            -0.7180400916979447,
            -0.6681008871286774,
            -0.6812125402915006,
            -0.5884714836752222,
            -0.6755427794821022,
            -0.4497491571032429,
            -0.677293592678948,
            -0.6236895350248963,
            -0.6720504362637552,
            -0.6244630718918318,
            -0.48639822932872046,
            -0.551487612858421,
            -0.7356891659184572,
            -0.7356971786938408,
            -0.7223269473354956,
            -0.5499787650843161,
            -0.6770742267311218,
            -0.5221103797392065,
            -0.6066831694126149,
            -0.7278244879018139,
            -0.6952997155263386,
            -0.584159231412447,
            -0.6685154538991902,
            -0.5048338955860439,
            -0.7070019022696826,
            -0.6250023102477418,
            -0.646680312845219,
            -0.5379270872572142,
            -0.6654700817651202,
            -0.6636247872533302,
            -0.6792009826672004,
            -0.7137492455263932,
            -0.6945490215814906,
            -0.5585793459661609,
            -0.694684268570096,
            -0.6541532216221689,
            -0.7459895737522535,
            -0.6523654444704798,
            -0.6578189153874607,
            -0.7304803138532602,
            -0.5419238152300471,
            -0.6606622731024856,
            -0.7206965991143776,
            -0.5593332812885137
           ]
          },
          {
           "label": "max_depth",
           "range": [
            2,
            50
           ],
           "values": [
            48,
            9,
            36,
            12,
            27,
            8,
            40,
            4,
            48,
            6,
            26,
            34,
            11,
            45,
            11,
            15,
            28,
            50,
            41,
            5,
            32,
            17,
            25,
            29,
            22,
            33,
            14,
            5,
            41,
            11,
            45,
            22,
            27,
            18,
            36,
            14,
            3,
            15,
            25,
            39,
            32,
            42,
            30,
            13,
            20,
            7,
            34,
            13,
            33,
            45,
            6,
            2,
            9,
            12,
            38,
            29,
            13,
            32,
            26,
            3,
            48,
            47,
            43,
            17,
            36,
            50,
            38,
            16,
            46,
            33,
            18,
            3,
            30,
            19,
            12,
            28,
            49,
            15,
            49,
            10,
            37,
            38,
            14,
            7,
            36,
            25,
            32,
            32,
            9,
            30,
            33,
            20,
            5,
            35,
            3,
            36,
            41,
            41,
            40,
            23,
            46,
            45,
            6,
            30,
            18,
            40,
            28,
            7,
            6,
            42,
            50,
            48,
            6,
            46,
            24,
            33,
            20,
            49,
            45,
            29,
            36,
            46,
            45,
            11,
            5,
            28,
            9,
            37,
            44,
            41,
            20,
            24,
            44,
            29,
            14,
            31,
            19,
            39,
            29,
            3,
            12,
            30,
            19,
            32,
            47,
            50,
            13,
            9,
            18,
            10,
            15,
            24,
            35,
            6,
            15,
            12,
            20,
            14,
            28,
            13,
            17,
            45,
            26,
            38,
            19,
            50,
            9,
            15,
            27,
            21,
            14,
            29,
            11,
            13,
            30,
            4,
            50,
            35,
            22,
            49,
            10,
            43,
            10,
            27,
            42,
            16,
            46,
            32,
            18,
            28,
            17,
            29,
            42,
            21,
            37,
            28,
            46,
            48,
            31,
            29,
            9,
            38,
            7,
            47,
            21,
            2,
            47,
            24,
            10,
            19,
            34,
            22,
            31,
            46,
            25,
            24,
            29,
            48,
            22,
            34,
            34,
            10,
            13,
            21,
            45,
            3,
            45,
            20,
            22,
            48,
            25,
            3,
            14,
            27,
            46,
            29,
            2,
            31,
            46,
            4,
            31,
            19,
            25,
            12,
            4,
            39,
            26,
            42,
            30,
            8,
            28,
            34,
            25,
            3,
            29,
            16,
            25,
            42,
            7,
            37,
            40,
            32,
            3,
            41,
            21,
            50,
            38,
            16,
            2,
            35,
            6,
            24,
            13,
            27,
            11,
            49,
            10,
            9,
            28,
            44,
            48,
            28,
            14,
            12,
            26,
            19,
            45,
            44,
            35,
            45,
            8,
            42,
            16,
            14,
            7,
            18,
            47,
            36,
            32,
            49
           ]
          },
          {
           "label": "min_samples_leaf",
           "range": [
            1,
            50
           ],
           "values": [
            30,
            44,
            49,
            10,
            15,
            19,
            26,
            9,
            41,
            23,
            46,
            27,
            39,
            47,
            17,
            18,
            41,
            10,
            37,
            6,
            4,
            32,
            36,
            25,
            6,
            26,
            38,
            9,
            44,
            27,
            6,
            44,
            12,
            17,
            49,
            16,
            26,
            12,
            13,
            37,
            27,
            10,
            1,
            9,
            7,
            44,
            28,
            45,
            18,
            39,
            45,
            34,
            35,
            12,
            43,
            19,
            20,
            26,
            37,
            9,
            19,
            49,
            20,
            28,
            5,
            26,
            36,
            41,
            26,
            40,
            5,
            28,
            2,
            27,
            5,
            32,
            17,
            4,
            35,
            13,
            14,
            31,
            38,
            3,
            5,
            22,
            3,
            43,
            33,
            29,
            28,
            46,
            1,
            16,
            15,
            44,
            9,
            21,
            47,
            38,
            42,
            1,
            48,
            23,
            38,
            25,
            45,
            39,
            36,
            5,
            19,
            38,
            28,
            25,
            6,
            30,
            44,
            49,
            50,
            27,
            32,
            15,
            32,
            18,
            50,
            41,
            42,
            21,
            2,
            8,
            43,
            14,
            50,
            48,
            7,
            34,
            34,
            43,
            21,
            32,
            1,
            22,
            40,
            48,
            13,
            17,
            7,
            33,
            24,
            3,
            5,
            19,
            40,
            47,
            38,
            25,
            38,
            45,
            23,
            19,
            17,
            34,
            27,
            7,
            29,
            12,
            9,
            45,
            50,
            44,
            34,
            14,
            22,
            31,
            25,
            7,
            41,
            30,
            47,
            37,
            38,
            40,
            41,
            44,
            19,
            26,
            28,
            47,
            40,
            40,
            38,
            44,
            43,
            8,
            33,
            18,
            21,
            30,
            44,
            47,
            31,
            47,
            42,
            26,
            17,
            20,
            18,
            23,
            21,
            32,
            49,
            50,
            38,
            10,
            4,
            23,
            10,
            14,
            8,
            12,
            6,
            12,
            43,
            11,
            5,
            30,
            18,
            14,
            22,
            8,
            40,
            28,
            42,
            14,
            29,
            42,
            46,
            34,
            20,
            37,
            20,
            15,
            47,
            14,
            30,
            4,
            22,
            35,
            5,
            23,
            37,
            43,
            50,
            47,
            2,
            49,
            43,
            30,
            35,
            16,
            32,
            2,
            27,
            18,
            32,
            21,
            6,
            12,
            22,
            48,
            44,
            9,
            33,
            9,
            18,
            47,
            38,
            12,
            30,
            7,
            41,
            21,
            25,
            4,
            30,
            29,
            33,
            42,
            38,
            2,
            38,
            26,
            50,
            27,
            28,
            47,
            4,
            30,
            44,
            7
           ]
          },
          {
           "label": "min_samples_split",
           "range": [
            2,
            50
           ],
           "values": [
            37,
            4,
            3,
            10,
            23,
            16,
            11,
            31,
            49,
            35,
            3,
            17,
            49,
            31,
            4,
            42,
            8,
            39,
            36,
            19,
            18,
            37,
            7,
            39,
            3,
            17,
            22,
            16,
            33,
            45,
            17,
            42,
            22,
            48,
            19,
            26,
            31,
            46,
            50,
            13,
            33,
            17,
            35,
            33,
            47,
            47,
            42,
            6,
            18,
            45,
            9,
            6,
            28,
            36,
            33,
            6,
            49,
            40,
            11,
            33,
            46,
            22,
            16,
            10,
            29,
            8,
            36,
            41,
            27,
            36,
            20,
            24,
            3,
            8,
            32,
            28,
            27,
            23,
            42,
            9,
            34,
            29,
            19,
            4,
            25,
            10,
            33,
            26,
            5,
            48,
            24,
            49,
            6,
            5,
            41,
            32,
            15,
            50,
            18,
            38,
            26,
            21,
            17,
            32,
            34,
            6,
            23,
            9,
            6,
            36,
            20,
            50,
            40,
            7,
            4,
            38,
            15,
            2,
            27,
            49,
            24,
            4,
            24,
            24,
            49,
            17,
            46,
            32,
            4,
            50,
            49,
            22,
            41,
            39,
            24,
            13,
            7,
            27,
            44,
            39,
            8,
            21,
            27,
            44,
            26,
            26,
            5,
            8,
            45,
            11,
            10,
            12,
            3,
            44,
            41,
            20,
            24,
            36,
            7,
            15,
            12,
            31,
            6,
            23,
            33,
            31,
            14,
            10,
            22,
            49,
            10,
            30,
            17,
            7,
            9,
            18,
            17,
            39,
            19,
            8,
            5,
            8,
            10,
            19,
            23,
            38,
            20,
            7,
            8,
            45,
            14,
            39,
            7,
            41,
            37,
            14,
            30,
            9,
            2,
            36,
            30,
            47,
            50,
            44,
            4,
            18,
            18,
            13,
            26,
            30,
            10,
            6,
            5,
            12,
            29,
            27,
            9,
            20,
            3,
            3,
            2,
            33,
            37,
            34,
            2,
            10,
            42,
            30,
            29,
            39,
            45,
            15,
            8,
            10,
            7,
            33,
            8,
            31,
            22,
            10,
            14,
            37,
            34,
            3,
            26,
            7,
            35,
            41,
            19,
            48,
            44,
            35,
            12,
            36,
            46,
            47,
            44,
            3,
            5,
            5,
            17,
            13,
            44,
            50,
            25,
            39,
            13,
            16,
            50,
            12,
            22,
            32,
            48,
            13,
            40,
            45,
            21,
            41,
            31,
            15,
            44,
            6,
            37,
            35,
            25,
            35,
            41,
            36,
            32,
            44,
            18,
            42,
            32,
            33,
            39,
            32,
            35,
            5,
            4,
            38
           ]
          },
          {
           "label": "n_estimators",
           "range": [
            4,
            499
           ],
           "values": [
            188,
            79,
            301,
            417,
            153,
            307,
            229,
            297,
            34,
            154,
            62,
            131,
            274,
            470,
            46,
            195,
            142,
            39,
            4,
            386,
            432,
            157,
            444,
            381,
            262,
            17,
            454,
            116,
            465,
            403,
            404,
            115,
            5,
            61,
            260,
            482,
            144,
            27,
            74,
            337,
            185,
            47,
            22,
            257,
            346,
            172,
            130,
            266,
            451,
            364,
            322,
            304,
            4,
            327,
            164,
            330,
            134,
            447,
            289,
            142,
            471,
            9,
            482,
            426,
            469,
            308,
            439,
            181,
            434,
            400,
            446,
            290,
            144,
            412,
            386,
            27,
            364,
            398,
            14,
            206,
            276,
            478,
            211,
            9,
            428,
            247,
            200,
            188,
            330,
            15,
            195,
            471,
            99,
            49,
            423,
            60,
            368,
            376,
            187,
            430,
            53,
            161,
            453,
            476,
            148,
            396,
            30,
            177,
            310,
            38,
            44,
            407,
            189,
            213,
            7,
            60,
            482,
            113,
            23,
            38,
            316,
            293,
            476,
            140,
            293,
            350,
            343,
            475,
            467,
            189,
            298,
            420,
            30,
            499,
            425,
            478,
            310,
            261,
            277,
            68,
            353,
            176,
            453,
            199,
            75,
            231,
            318,
            65,
            92,
            335,
            86,
            62,
            253,
            315,
            32,
            94,
            310,
            20,
            257,
            267,
            12,
            61,
            395,
            294,
            143,
            179,
            52,
            95,
            42,
            57,
            409,
            465,
            385,
            255,
            146,
            267,
            33,
            129,
            237,
            416,
            470,
            288,
            102,
            333,
            197,
            232,
            117,
            454,
            315,
            311,
            77,
            18,
            172,
            65,
            116,
            348,
            92,
            232,
            254,
            467,
            354,
            213,
            226,
            64,
            297,
            402,
            270,
            370,
            72,
            458,
            8,
            76,
            252,
            106,
            20,
            388,
            201,
            432,
            323,
            359,
            117,
            401,
            51,
            416,
            148,
            105,
            212,
            131,
            313,
            148,
            435,
            214,
            318,
            493,
            11,
            138,
            105,
            438,
            89,
            260,
            43,
            146,
            284,
            367,
            298,
            168,
            365,
            124,
            137,
            459,
            94,
            404,
            126,
            473,
            92,
            350,
            473,
            161,
            116,
            171,
            271,
            444,
            436,
            470,
            384,
            437,
            212,
            178,
            23,
            193,
            394,
            473,
            496,
            305,
            112,
            30,
            498,
            349,
            113,
            47,
            445,
            328,
            187,
            42,
            426,
            413,
            135,
            426,
            350,
            81,
            414,
            82,
            5,
            317,
            391,
            482,
            53,
            152,
            174,
            487
           ]
          }
         ],
         "labelangle": 30,
         "labelside": "bottom",
         "line": {
          "color": [
           -0.6656641089023417,
           -0.7199505312988174,
           -0.7367121976165063,
           -0.5292824062760534,
           -0.5830638868068412,
           -0.6064985347750641,
           -0.6491396998330222,
           -0.5826558004544863,
           -0.7198382886238155,
           -0.6365594301626742,
           -0.7281212908735382,
           -0.6567363850441149,
           -0.6971412048790289,
           -0.7318348418229933,
           -0.6021902447489296,
           -0.6095886765036791,
           -0.7049809567680899,
           -0.5781707407675112,
           -0.7123111220953364,
           -0.5362297911996794,
           -0.48017143082383884,
           -0.6732099911144622,
           -0.6871998722518835,
           -0.6451410464166459,
           -0.4865594303939796,
           -0.6592189387766794,
           -0.693749189617136,
           -0.5394283111696837,
           -0.7215100690263254,
           -0.6504891641206486,
           -0.4936523772550081,
           -0.7190855088498597,
           -0.599901048813782,
           -0.620023220707351,
           -0.739729699618376,
           -0.5868279331750592,
           -0.6772506231255955,
           -0.5984380868184219,
           -0.6030898048350053,
           -0.6889229626111054,
           -0.6567346634068175,
           -0.5365280459528657,
           -0.5272902657503901,
           -0.55476088410808,
           -0.5774739914576263,
           -0.7206731014378128,
           -0.6649548646105757,
           -0.7282491320559438,
           -0.6023232035720847,
           -0.6979804239242376,
           -0.7253736482763804,
           -0.7364879531961795,
           -0.711902803318176,
           -0.5737354691618617,
           -0.720535430248012,
           -0.6140083975027244,
           -0.6308245622960367,
           -0.6491367580542484,
           -0.6892499103324194,
           -0.6394667580300355,
           -0.6217007472408888,
           -0.7516591987491003,
           -0.6137926197457685,
           -0.6572579621960393,
           -0.5183900208959733,
           -0.6485154077168571,
           -0.6861660653026901,
           -0.7079831661724818,
           -0.6507224003498766,
           -0.7008536636091017,
           -0.4951070763191515,
           -0.6786431670312996,
           -0.41712153744953867,
           -0.6530125755125364,
           -0.526232061303389,
           -0.6742692149713619,
           -0.5960874918976857,
           -0.49784523287761334,
           -0.7003034569002038,
           -0.5575261891851576,
           -0.5810795517404739,
           -0.6726223115203235,
           -0.694091583716562,
           -0.4861664314808126,
           -0.507416950495764,
           -0.6236326493753502,
           -0.5189671029336714,
           -0.7148407544852687,
           -0.6754185858520529,
           -0.7008124318678354,
           -0.6566906022367149,
           -0.7297684135600907,
           -0.4936445929582338,
           -0.5888379459234767,
           -0.6552274852289299,
           -0.7234335841567957,
           -0.5205696945991554,
           -0.633683600587547,
           -0.7322348031482341,
           -0.6937724542282755,
           -0.7103115372826633,
           -0.46884903303831527,
           -0.7350335184364061,
           -0.6357446263478554,
           -0.699773639185317,
           -0.6426578549811641,
           -0.726331002000095,
           -0.7046598199178369,
           -0.6877898034463746,
           -0.5525448469417281,
           -0.6072339340162648,
           -0.6946773147751654,
           -0.6554228057432875,
           -0.645021404016406,
           -0.5355676250624591,
           -0.6673732599985004,
           -0.7207819349945828,
           -0.7367207691047118,
           -0.7420911130977956,
           -0.6623641291825696,
           -0.6733691584391432,
           -0.5784691515708678,
           -0.672501061485665,
           -0.6036173020115925,
           -0.7378608921985318,
           -0.7086040899138626,
           -0.712465567142827,
           -0.6218786407188801,
           -0.4212134071076507,
           -0.5949471355620071,
           -0.7180744675724976,
           -0.5718444534185849,
           -0.7461401220979981,
           -0.7364451171482014,
           -0.5199233971097994,
           -0.6800661540612681,
           -0.684591705417201,
           -0.7185719666659782,
           -0.6216570790776361,
           -0.6884627522610869,
           -0.4309189236051133,
           -0.6340999971005971,
           -0.7049066735302822,
           -0.736095298396033,
           -0.5575661424557397,
           -0.5959313226084771,
           -0.5016420552290282,
           -0.6805391832296139,
           -0.6444461857333621,
           -0.4534311163839527,
           -0.47800147184878217,
           -0.6102641644057103,
           -0.7026023478696585,
           -0.7318410180459475,
           -0.6963147970356646,
           -0.642521595182975,
           -0.694945447973849,
           -0.7236210394028701,
           -0.6371319622457132,
           -0.6115631916304534,
           -0.6197233672065339,
           -0.676852588031575,
           -0.6528228850417255,
           -0.5211290232513768,
           -0.6654746909093561,
           -0.5636770700760805,
           -0.5175294276770354,
           -0.7268309692759534,
           -0.7406732821462988,
           -0.7244714284554623,
           -0.6771246795649218,
           -0.5738367943428421,
           -0.630059648664337,
           -0.6689786995690049,
           -0.6456385184089161,
           -0.5722304897299145,
           -0.7113690927547311,
           -0.6691184189269346,
           -0.7318861081941135,
           -0.6936201319594906,
           -0.6931301582428836,
           -0.7041098042916085,
           -0.7097183812834033,
           -0.7198481850934192,
           -0.6099603367831075,
           -0.6491512326214742,
           -0.6582898973695747,
           -0.7324866917533177,
           -0.6998170595673473,
           -0.7034158277071753,
           -0.6960785719312466,
           -0.7329104413017982,
           -0.7156840344107442,
           -0.5707474312936985,
           -0.6761639437737672,
           -0.6000102899875186,
           -0.6274440192800002,
           -0.6647295143875589,
           -0.7229885297048648,
           -0.7316851825880548,
           -0.6696044965221162,
           -0.7306129079287002,
           -0.7127968428609461,
           -0.6474466610642047,
           -0.5989142140222063,
           -0.7279520642017981,
           -0.6020729755651013,
           -0.6380264676883958,
           -0.6257526641657168,
           -0.6708333375154425,
           -0.7578233877174643,
           -0.7441611774895801,
           -0.6901953291032891,
           -0.5329652656024522,
           -0.5143749599108404,
           -0.6360197751044895,
           -0.531214555818096,
           -0.5688468200400122,
           -0.5078299289366355,
           -0.5509438186349598,
           -0.4864710548841935,
           -0.5653485969688753,
           -0.7221656977912196,
           -0.5646007388336587,
           -0.46611103733010184,
           -0.6805926648942202,
           -0.6125803512915705,
           -0.5740819386506406,
           -0.6247846010472962,
           -0.5667914055211967,
           -0.7026247461990621,
           -0.6767910787381247,
           -0.7118415145174344,
           -0.5680370727366446,
           -0.6619589024880559,
           -0.7113497640589168,
           -0.7486448026882424,
           -0.6788979361480916,
           -0.6154254779287277,
           -0.6889159699262372,
           -0.6180324814496077,
           -0.5838917014456367,
           -0.7356237605361198,
           -0.5682705094225385,
           -0.6663499638514605,
           -0.46176092237448574,
           -0.6284230075335148,
           -0.6801673404468926,
           -0.4936154585972261,
           -0.6373346837646287,
           -0.6965632065195855,
           -0.7214794070692744,
           -0.7412778765745585,
           -0.7303234753161248,
           -0.5611764201724139,
           -0.7363624422846056,
           -0.7180400916979447,
           -0.6681008871286774,
           -0.6812125402915006,
           -0.5884714836752222,
           -0.6755427794821022,
           -0.4497491571032429,
           -0.677293592678948,
           -0.6236895350248963,
           -0.6720504362637552,
           -0.6244630718918318,
           -0.48639822932872046,
           -0.551487612858421,
           -0.7356891659184572,
           -0.7356971786938408,
           -0.7223269473354956,
           -0.5499787650843161,
           -0.6770742267311218,
           -0.5221103797392065,
           -0.6066831694126149,
           -0.7278244879018139,
           -0.6952997155263386,
           -0.584159231412447,
           -0.6685154538991902,
           -0.5048338955860439,
           -0.7070019022696826,
           -0.6250023102477418,
           -0.646680312845219,
           -0.5379270872572142,
           -0.6654700817651202,
           -0.6636247872533302,
           -0.6792009826672004,
           -0.7137492455263932,
           -0.6945490215814906,
           -0.5585793459661609,
           -0.694684268570096,
           -0.6541532216221689,
           -0.7459895737522535,
           -0.6523654444704798,
           -0.6578189153874607,
           -0.7304803138532602,
           -0.5419238152300471,
           -0.6606622731024856,
           -0.7206965991143776,
           -0.5593332812885137
          ],
          "colorbar": {
           "title": {
            "text": "Objective Value"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "reversescale": false,
          "showscale": true
         },
         "type": "parcoords"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Parallel Coordinate Plot"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": true
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          48,
          9,
          36,
          12,
          27,
          8,
          40,
          4,
          48,
          6,
          26,
          34,
          11,
          45,
          11,
          15,
          28,
          50,
          41,
          5,
          32,
          17,
          25,
          29,
          22,
          33,
          14,
          5,
          41,
          11,
          45,
          22,
          27,
          18,
          36,
          14,
          3,
          15,
          25,
          39,
          32,
          42,
          30,
          13,
          20,
          7,
          34,
          13,
          33,
          45,
          6,
          2,
          9,
          12,
          38,
          29,
          13,
          32,
          26,
          3,
          48,
          47,
          43,
          17,
          36,
          50,
          38,
          16,
          46,
          33,
          18,
          3,
          30,
          19,
          12,
          28,
          49,
          15,
          49,
          10,
          37,
          38,
          14,
          7,
          36,
          25,
          32,
          32,
          9,
          30,
          33,
          20,
          5,
          35,
          3,
          36,
          41,
          41,
          40,
          23,
          46,
          45,
          6,
          30,
          18,
          40,
          28,
          7,
          6,
          42,
          50,
          48,
          6,
          46,
          24,
          33,
          20,
          49,
          45,
          29,
          36,
          46,
          45,
          11,
          5,
          28,
          9,
          37,
          44,
          41,
          20,
          24,
          44,
          29,
          14,
          31,
          19,
          39,
          29,
          3,
          12,
          30,
          19,
          32,
          47,
          50,
          13,
          9,
          18,
          10,
          15,
          24,
          35,
          6,
          15,
          12,
          20,
          14,
          28,
          13,
          17,
          45,
          26,
          38,
          19,
          50,
          9,
          15,
          27,
          21,
          14,
          29,
          11,
          13,
          30,
          4,
          50,
          35,
          22,
          49,
          10,
          43,
          10,
          27,
          42,
          16,
          46,
          32,
          18,
          28,
          17,
          29,
          42,
          21,
          37,
          28,
          46,
          48,
          31,
          29,
          9,
          38,
          7,
          47,
          21,
          2,
          47,
          24,
          10,
          19,
          34,
          22,
          31,
          46,
          25,
          24,
          29,
          48,
          22,
          34,
          34,
          10,
          13,
          21,
          45,
          3,
          45,
          20,
          22,
          48,
          25,
          3,
          14,
          27,
          46,
          29,
          2,
          31,
          46,
          4,
          31,
          19,
          25,
          12,
          4,
          39,
          26,
          42,
          30,
          8,
          28,
          34,
          25,
          3,
          29,
          16,
          25,
          42,
          7,
          37,
          40,
          32,
          3,
          41,
          21,
          50,
          38,
          16,
          2,
          35,
          6,
          24,
          13,
          27,
          11,
          49,
          10,
          9,
          28,
          44,
          48,
          28,
          14,
          12,
          26,
          19,
          45,
          44,
          35,
          45,
          8,
          42,
          16,
          14,
          7,
          18,
          47,
          36,
          32,
          49
         ],
         "xaxis": "x",
         "y": [
          -0.6656641089023417,
          -0.7199505312988174,
          -0.7367121976165063,
          -0.5292824062760534,
          -0.5830638868068412,
          -0.6064985347750641,
          -0.6491396998330222,
          -0.5826558004544863,
          -0.7198382886238155,
          -0.6365594301626742,
          -0.7281212908735382,
          -0.6567363850441149,
          -0.6971412048790289,
          -0.7318348418229933,
          -0.6021902447489296,
          -0.6095886765036791,
          -0.7049809567680899,
          -0.5781707407675112,
          -0.7123111220953364,
          -0.5362297911996794,
          -0.48017143082383884,
          -0.6732099911144622,
          -0.6871998722518835,
          -0.6451410464166459,
          -0.4865594303939796,
          -0.6592189387766794,
          -0.693749189617136,
          -0.5394283111696837,
          -0.7215100690263254,
          -0.6504891641206486,
          -0.4936523772550081,
          -0.7190855088498597,
          -0.599901048813782,
          -0.620023220707351,
          -0.739729699618376,
          -0.5868279331750592,
          -0.6772506231255955,
          -0.5984380868184219,
          -0.6030898048350053,
          -0.6889229626111054,
          -0.6567346634068175,
          -0.5365280459528657,
          -0.5272902657503901,
          -0.55476088410808,
          -0.5774739914576263,
          -0.7206731014378128,
          -0.6649548646105757,
          -0.7282491320559438,
          -0.6023232035720847,
          -0.6979804239242376,
          -0.7253736482763804,
          -0.7364879531961795,
          -0.711902803318176,
          -0.5737354691618617,
          -0.720535430248012,
          -0.6140083975027244,
          -0.6308245622960367,
          -0.6491367580542484,
          -0.6892499103324194,
          -0.6394667580300355,
          -0.6217007472408888,
          -0.7516591987491003,
          -0.6137926197457685,
          -0.6572579621960393,
          -0.5183900208959733,
          -0.6485154077168571,
          -0.6861660653026901,
          -0.7079831661724818,
          -0.6507224003498766,
          -0.7008536636091017,
          -0.4951070763191515,
          -0.6786431670312996,
          -0.41712153744953867,
          -0.6530125755125364,
          -0.526232061303389,
          -0.6742692149713619,
          -0.5960874918976857,
          -0.49784523287761334,
          -0.7003034569002038,
          -0.5575261891851576,
          -0.5810795517404739,
          -0.6726223115203235,
          -0.694091583716562,
          -0.4861664314808126,
          -0.507416950495764,
          -0.6236326493753502,
          -0.5189671029336714,
          -0.7148407544852687,
          -0.6754185858520529,
          -0.7008124318678354,
          -0.6566906022367149,
          -0.7297684135600907,
          -0.4936445929582338,
          -0.5888379459234767,
          -0.6552274852289299,
          -0.7234335841567957,
          -0.5205696945991554,
          -0.633683600587547,
          -0.7322348031482341,
          -0.6937724542282755,
          -0.7103115372826633,
          -0.46884903303831527,
          -0.7350335184364061,
          -0.6357446263478554,
          -0.699773639185317,
          -0.6426578549811641,
          -0.726331002000095,
          -0.7046598199178369,
          -0.6877898034463746,
          -0.5525448469417281,
          -0.6072339340162648,
          -0.6946773147751654,
          -0.6554228057432875,
          -0.645021404016406,
          -0.5355676250624591,
          -0.6673732599985004,
          -0.7207819349945828,
          -0.7367207691047118,
          -0.7420911130977956,
          -0.6623641291825696,
          -0.6733691584391432,
          -0.5784691515708678,
          -0.672501061485665,
          -0.6036173020115925,
          -0.7378608921985318,
          -0.7086040899138626,
          -0.712465567142827,
          -0.6218786407188801,
          -0.4212134071076507,
          -0.5949471355620071,
          -0.7180744675724976,
          -0.5718444534185849,
          -0.7461401220979981,
          -0.7364451171482014,
          -0.5199233971097994,
          -0.6800661540612681,
          -0.684591705417201,
          -0.7185719666659782,
          -0.6216570790776361,
          -0.6884627522610869,
          -0.4309189236051133,
          -0.6340999971005971,
          -0.7049066735302822,
          -0.736095298396033,
          -0.5575661424557397,
          -0.5959313226084771,
          -0.5016420552290282,
          -0.6805391832296139,
          -0.6444461857333621,
          -0.4534311163839527,
          -0.47800147184878217,
          -0.6102641644057103,
          -0.7026023478696585,
          -0.7318410180459475,
          -0.6963147970356646,
          -0.642521595182975,
          -0.694945447973849,
          -0.7236210394028701,
          -0.6371319622457132,
          -0.6115631916304534,
          -0.6197233672065339,
          -0.676852588031575,
          -0.6528228850417255,
          -0.5211290232513768,
          -0.6654746909093561,
          -0.5636770700760805,
          -0.5175294276770354,
          -0.7268309692759534,
          -0.7406732821462988,
          -0.7244714284554623,
          -0.6771246795649218,
          -0.5738367943428421,
          -0.630059648664337,
          -0.6689786995690049,
          -0.6456385184089161,
          -0.5722304897299145,
          -0.7113690927547311,
          -0.6691184189269346,
          -0.7318861081941135,
          -0.6936201319594906,
          -0.6931301582428836,
          -0.7041098042916085,
          -0.7097183812834033,
          -0.7198481850934192,
          -0.6099603367831075,
          -0.6491512326214742,
          -0.6582898973695747,
          -0.7324866917533177,
          -0.6998170595673473,
          -0.7034158277071753,
          -0.6960785719312466,
          -0.7329104413017982,
          -0.7156840344107442,
          -0.5707474312936985,
          -0.6761639437737672,
          -0.6000102899875186,
          -0.6274440192800002,
          -0.6647295143875589,
          -0.7229885297048648,
          -0.7316851825880548,
          -0.6696044965221162,
          -0.7306129079287002,
          -0.7127968428609461,
          -0.6474466610642047,
          -0.5989142140222063,
          -0.7279520642017981,
          -0.6020729755651013,
          -0.6380264676883958,
          -0.6257526641657168,
          -0.6708333375154425,
          -0.7578233877174643,
          -0.7441611774895801,
          -0.6901953291032891,
          -0.5329652656024522,
          -0.5143749599108404,
          -0.6360197751044895,
          -0.531214555818096,
          -0.5688468200400122,
          -0.5078299289366355,
          -0.5509438186349598,
          -0.4864710548841935,
          -0.5653485969688753,
          -0.7221656977912196,
          -0.5646007388336587,
          -0.46611103733010184,
          -0.6805926648942202,
          -0.6125803512915705,
          -0.5740819386506406,
          -0.6247846010472962,
          -0.5667914055211967,
          -0.7026247461990621,
          -0.6767910787381247,
          -0.7118415145174344,
          -0.5680370727366446,
          -0.6619589024880559,
          -0.7113497640589168,
          -0.7486448026882424,
          -0.6788979361480916,
          -0.6154254779287277,
          -0.6889159699262372,
          -0.6180324814496077,
          -0.5838917014456367,
          -0.7356237605361198,
          -0.5682705094225385,
          -0.6663499638514605,
          -0.46176092237448574,
          -0.6284230075335148,
          -0.6801673404468926,
          -0.4936154585972261,
          -0.6373346837646287,
          -0.6965632065195855,
          -0.7214794070692744,
          -0.7412778765745585,
          -0.7303234753161248,
          -0.5611764201724139,
          -0.7363624422846056,
          -0.7180400916979447,
          -0.6681008871286774,
          -0.6812125402915006,
          -0.5884714836752222,
          -0.6755427794821022,
          -0.4497491571032429,
          -0.677293592678948,
          -0.6236895350248963,
          -0.6720504362637552,
          -0.6244630718918318,
          -0.48639822932872046,
          -0.551487612858421,
          -0.7356891659184572,
          -0.7356971786938408,
          -0.7223269473354956,
          -0.5499787650843161,
          -0.6770742267311218,
          -0.5221103797392065,
          -0.6066831694126149,
          -0.7278244879018139,
          -0.6952997155263386,
          -0.584159231412447,
          -0.6685154538991902,
          -0.5048338955860439,
          -0.7070019022696826,
          -0.6250023102477418,
          -0.646680312845219,
          -0.5379270872572142,
          -0.6654700817651202,
          -0.6636247872533302,
          -0.6792009826672004,
          -0.7137492455263932,
          -0.6945490215814906,
          -0.5585793459661609,
          -0.694684268570096,
          -0.6541532216221689,
          -0.7459895737522535,
          -0.6523654444704798,
          -0.6578189153874607,
          -0.7304803138532602,
          -0.5419238152300471,
          -0.6606622731024856,
          -0.7206965991143776,
          -0.5593332812885137
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          30,
          44,
          49,
          10,
          15,
          19,
          26,
          9,
          41,
          23,
          46,
          27,
          39,
          47,
          17,
          18,
          41,
          10,
          37,
          6,
          4,
          32,
          36,
          25,
          6,
          26,
          38,
          9,
          44,
          27,
          6,
          44,
          12,
          17,
          49,
          16,
          26,
          12,
          13,
          37,
          27,
          10,
          1,
          9,
          7,
          44,
          28,
          45,
          18,
          39,
          45,
          34,
          35,
          12,
          43,
          19,
          20,
          26,
          37,
          9,
          19,
          49,
          20,
          28,
          5,
          26,
          36,
          41,
          26,
          40,
          5,
          28,
          2,
          27,
          5,
          32,
          17,
          4,
          35,
          13,
          14,
          31,
          38,
          3,
          5,
          22,
          3,
          43,
          33,
          29,
          28,
          46,
          1,
          16,
          15,
          44,
          9,
          21,
          47,
          38,
          42,
          1,
          48,
          23,
          38,
          25,
          45,
          39,
          36,
          5,
          19,
          38,
          28,
          25,
          6,
          30,
          44,
          49,
          50,
          27,
          32,
          15,
          32,
          18,
          50,
          41,
          42,
          21,
          2,
          8,
          43,
          14,
          50,
          48,
          7,
          34,
          34,
          43,
          21,
          32,
          1,
          22,
          40,
          48,
          13,
          17,
          7,
          33,
          24,
          3,
          5,
          19,
          40,
          47,
          38,
          25,
          38,
          45,
          23,
          19,
          17,
          34,
          27,
          7,
          29,
          12,
          9,
          45,
          50,
          44,
          34,
          14,
          22,
          31,
          25,
          7,
          41,
          30,
          47,
          37,
          38,
          40,
          41,
          44,
          19,
          26,
          28,
          47,
          40,
          40,
          38,
          44,
          43,
          8,
          33,
          18,
          21,
          30,
          44,
          47,
          31,
          47,
          42,
          26,
          17,
          20,
          18,
          23,
          21,
          32,
          49,
          50,
          38,
          10,
          4,
          23,
          10,
          14,
          8,
          12,
          6,
          12,
          43,
          11,
          5,
          30,
          18,
          14,
          22,
          8,
          40,
          28,
          42,
          14,
          29,
          42,
          46,
          34,
          20,
          37,
          20,
          15,
          47,
          14,
          30,
          4,
          22,
          35,
          5,
          23,
          37,
          43,
          50,
          47,
          2,
          49,
          43,
          30,
          35,
          16,
          32,
          2,
          27,
          18,
          32,
          21,
          6,
          12,
          22,
          48,
          44,
          9,
          33,
          9,
          18,
          47,
          38,
          12,
          30,
          7,
          41,
          21,
          25,
          4,
          30,
          29,
          33,
          42,
          38,
          2,
          38,
          26,
          50,
          27,
          28,
          47,
          4,
          30,
          44,
          7
         ],
         "xaxis": "x2",
         "y": [
          -0.6656641089023417,
          -0.7199505312988174,
          -0.7367121976165063,
          -0.5292824062760534,
          -0.5830638868068412,
          -0.6064985347750641,
          -0.6491396998330222,
          -0.5826558004544863,
          -0.7198382886238155,
          -0.6365594301626742,
          -0.7281212908735382,
          -0.6567363850441149,
          -0.6971412048790289,
          -0.7318348418229933,
          -0.6021902447489296,
          -0.6095886765036791,
          -0.7049809567680899,
          -0.5781707407675112,
          -0.7123111220953364,
          -0.5362297911996794,
          -0.48017143082383884,
          -0.6732099911144622,
          -0.6871998722518835,
          -0.6451410464166459,
          -0.4865594303939796,
          -0.6592189387766794,
          -0.693749189617136,
          -0.5394283111696837,
          -0.7215100690263254,
          -0.6504891641206486,
          -0.4936523772550081,
          -0.7190855088498597,
          -0.599901048813782,
          -0.620023220707351,
          -0.739729699618376,
          -0.5868279331750592,
          -0.6772506231255955,
          -0.5984380868184219,
          -0.6030898048350053,
          -0.6889229626111054,
          -0.6567346634068175,
          -0.5365280459528657,
          -0.5272902657503901,
          -0.55476088410808,
          -0.5774739914576263,
          -0.7206731014378128,
          -0.6649548646105757,
          -0.7282491320559438,
          -0.6023232035720847,
          -0.6979804239242376,
          -0.7253736482763804,
          -0.7364879531961795,
          -0.711902803318176,
          -0.5737354691618617,
          -0.720535430248012,
          -0.6140083975027244,
          -0.6308245622960367,
          -0.6491367580542484,
          -0.6892499103324194,
          -0.6394667580300355,
          -0.6217007472408888,
          -0.7516591987491003,
          -0.6137926197457685,
          -0.6572579621960393,
          -0.5183900208959733,
          -0.6485154077168571,
          -0.6861660653026901,
          -0.7079831661724818,
          -0.6507224003498766,
          -0.7008536636091017,
          -0.4951070763191515,
          -0.6786431670312996,
          -0.41712153744953867,
          -0.6530125755125364,
          -0.526232061303389,
          -0.6742692149713619,
          -0.5960874918976857,
          -0.49784523287761334,
          -0.7003034569002038,
          -0.5575261891851576,
          -0.5810795517404739,
          -0.6726223115203235,
          -0.694091583716562,
          -0.4861664314808126,
          -0.507416950495764,
          -0.6236326493753502,
          -0.5189671029336714,
          -0.7148407544852687,
          -0.6754185858520529,
          -0.7008124318678354,
          -0.6566906022367149,
          -0.7297684135600907,
          -0.4936445929582338,
          -0.5888379459234767,
          -0.6552274852289299,
          -0.7234335841567957,
          -0.5205696945991554,
          -0.633683600587547,
          -0.7322348031482341,
          -0.6937724542282755,
          -0.7103115372826633,
          -0.46884903303831527,
          -0.7350335184364061,
          -0.6357446263478554,
          -0.699773639185317,
          -0.6426578549811641,
          -0.726331002000095,
          -0.7046598199178369,
          -0.6877898034463746,
          -0.5525448469417281,
          -0.6072339340162648,
          -0.6946773147751654,
          -0.6554228057432875,
          -0.645021404016406,
          -0.5355676250624591,
          -0.6673732599985004,
          -0.7207819349945828,
          -0.7367207691047118,
          -0.7420911130977956,
          -0.6623641291825696,
          -0.6733691584391432,
          -0.5784691515708678,
          -0.672501061485665,
          -0.6036173020115925,
          -0.7378608921985318,
          -0.7086040899138626,
          -0.712465567142827,
          -0.6218786407188801,
          -0.4212134071076507,
          -0.5949471355620071,
          -0.7180744675724976,
          -0.5718444534185849,
          -0.7461401220979981,
          -0.7364451171482014,
          -0.5199233971097994,
          -0.6800661540612681,
          -0.684591705417201,
          -0.7185719666659782,
          -0.6216570790776361,
          -0.6884627522610869,
          -0.4309189236051133,
          -0.6340999971005971,
          -0.7049066735302822,
          -0.736095298396033,
          -0.5575661424557397,
          -0.5959313226084771,
          -0.5016420552290282,
          -0.6805391832296139,
          -0.6444461857333621,
          -0.4534311163839527,
          -0.47800147184878217,
          -0.6102641644057103,
          -0.7026023478696585,
          -0.7318410180459475,
          -0.6963147970356646,
          -0.642521595182975,
          -0.694945447973849,
          -0.7236210394028701,
          -0.6371319622457132,
          -0.6115631916304534,
          -0.6197233672065339,
          -0.676852588031575,
          -0.6528228850417255,
          -0.5211290232513768,
          -0.6654746909093561,
          -0.5636770700760805,
          -0.5175294276770354,
          -0.7268309692759534,
          -0.7406732821462988,
          -0.7244714284554623,
          -0.6771246795649218,
          -0.5738367943428421,
          -0.630059648664337,
          -0.6689786995690049,
          -0.6456385184089161,
          -0.5722304897299145,
          -0.7113690927547311,
          -0.6691184189269346,
          -0.7318861081941135,
          -0.6936201319594906,
          -0.6931301582428836,
          -0.7041098042916085,
          -0.7097183812834033,
          -0.7198481850934192,
          -0.6099603367831075,
          -0.6491512326214742,
          -0.6582898973695747,
          -0.7324866917533177,
          -0.6998170595673473,
          -0.7034158277071753,
          -0.6960785719312466,
          -0.7329104413017982,
          -0.7156840344107442,
          -0.5707474312936985,
          -0.6761639437737672,
          -0.6000102899875186,
          -0.6274440192800002,
          -0.6647295143875589,
          -0.7229885297048648,
          -0.7316851825880548,
          -0.6696044965221162,
          -0.7306129079287002,
          -0.7127968428609461,
          -0.6474466610642047,
          -0.5989142140222063,
          -0.7279520642017981,
          -0.6020729755651013,
          -0.6380264676883958,
          -0.6257526641657168,
          -0.6708333375154425,
          -0.7578233877174643,
          -0.7441611774895801,
          -0.6901953291032891,
          -0.5329652656024522,
          -0.5143749599108404,
          -0.6360197751044895,
          -0.531214555818096,
          -0.5688468200400122,
          -0.5078299289366355,
          -0.5509438186349598,
          -0.4864710548841935,
          -0.5653485969688753,
          -0.7221656977912196,
          -0.5646007388336587,
          -0.46611103733010184,
          -0.6805926648942202,
          -0.6125803512915705,
          -0.5740819386506406,
          -0.6247846010472962,
          -0.5667914055211967,
          -0.7026247461990621,
          -0.6767910787381247,
          -0.7118415145174344,
          -0.5680370727366446,
          -0.6619589024880559,
          -0.7113497640589168,
          -0.7486448026882424,
          -0.6788979361480916,
          -0.6154254779287277,
          -0.6889159699262372,
          -0.6180324814496077,
          -0.5838917014456367,
          -0.7356237605361198,
          -0.5682705094225385,
          -0.6663499638514605,
          -0.46176092237448574,
          -0.6284230075335148,
          -0.6801673404468926,
          -0.4936154585972261,
          -0.6373346837646287,
          -0.6965632065195855,
          -0.7214794070692744,
          -0.7412778765745585,
          -0.7303234753161248,
          -0.5611764201724139,
          -0.7363624422846056,
          -0.7180400916979447,
          -0.6681008871286774,
          -0.6812125402915006,
          -0.5884714836752222,
          -0.6755427794821022,
          -0.4497491571032429,
          -0.677293592678948,
          -0.6236895350248963,
          -0.6720504362637552,
          -0.6244630718918318,
          -0.48639822932872046,
          -0.551487612858421,
          -0.7356891659184572,
          -0.7356971786938408,
          -0.7223269473354956,
          -0.5499787650843161,
          -0.6770742267311218,
          -0.5221103797392065,
          -0.6066831694126149,
          -0.7278244879018139,
          -0.6952997155263386,
          -0.584159231412447,
          -0.6685154538991902,
          -0.5048338955860439,
          -0.7070019022696826,
          -0.6250023102477418,
          -0.646680312845219,
          -0.5379270872572142,
          -0.6654700817651202,
          -0.6636247872533302,
          -0.6792009826672004,
          -0.7137492455263932,
          -0.6945490215814906,
          -0.5585793459661609,
          -0.694684268570096,
          -0.6541532216221689,
          -0.7459895737522535,
          -0.6523654444704798,
          -0.6578189153874607,
          -0.7304803138532602,
          -0.5419238152300471,
          -0.6606622731024856,
          -0.7206965991143776,
          -0.5593332812885137
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          37,
          4,
          3,
          10,
          23,
          16,
          11,
          31,
          49,
          35,
          3,
          17,
          49,
          31,
          4,
          42,
          8,
          39,
          36,
          19,
          18,
          37,
          7,
          39,
          3,
          17,
          22,
          16,
          33,
          45,
          17,
          42,
          22,
          48,
          19,
          26,
          31,
          46,
          50,
          13,
          33,
          17,
          35,
          33,
          47,
          47,
          42,
          6,
          18,
          45,
          9,
          6,
          28,
          36,
          33,
          6,
          49,
          40,
          11,
          33,
          46,
          22,
          16,
          10,
          29,
          8,
          36,
          41,
          27,
          36,
          20,
          24,
          3,
          8,
          32,
          28,
          27,
          23,
          42,
          9,
          34,
          29,
          19,
          4,
          25,
          10,
          33,
          26,
          5,
          48,
          24,
          49,
          6,
          5,
          41,
          32,
          15,
          50,
          18,
          38,
          26,
          21,
          17,
          32,
          34,
          6,
          23,
          9,
          6,
          36,
          20,
          50,
          40,
          7,
          4,
          38,
          15,
          2,
          27,
          49,
          24,
          4,
          24,
          24,
          49,
          17,
          46,
          32,
          4,
          50,
          49,
          22,
          41,
          39,
          24,
          13,
          7,
          27,
          44,
          39,
          8,
          21,
          27,
          44,
          26,
          26,
          5,
          8,
          45,
          11,
          10,
          12,
          3,
          44,
          41,
          20,
          24,
          36,
          7,
          15,
          12,
          31,
          6,
          23,
          33,
          31,
          14,
          10,
          22,
          49,
          10,
          30,
          17,
          7,
          9,
          18,
          17,
          39,
          19,
          8,
          5,
          8,
          10,
          19,
          23,
          38,
          20,
          7,
          8,
          45,
          14,
          39,
          7,
          41,
          37,
          14,
          30,
          9,
          2,
          36,
          30,
          47,
          50,
          44,
          4,
          18,
          18,
          13,
          26,
          30,
          10,
          6,
          5,
          12,
          29,
          27,
          9,
          20,
          3,
          3,
          2,
          33,
          37,
          34,
          2,
          10,
          42,
          30,
          29,
          39,
          45,
          15,
          8,
          10,
          7,
          33,
          8,
          31,
          22,
          10,
          14,
          37,
          34,
          3,
          26,
          7,
          35,
          41,
          19,
          48,
          44,
          35,
          12,
          36,
          46,
          47,
          44,
          3,
          5,
          5,
          17,
          13,
          44,
          50,
          25,
          39,
          13,
          16,
          50,
          12,
          22,
          32,
          48,
          13,
          40,
          45,
          21,
          41,
          31,
          15,
          44,
          6,
          37,
          35,
          25,
          35,
          41,
          36,
          32,
          44,
          18,
          42,
          32,
          33,
          39,
          32,
          35,
          5,
          4,
          38
         ],
         "xaxis": "x3",
         "y": [
          -0.6656641089023417,
          -0.7199505312988174,
          -0.7367121976165063,
          -0.5292824062760534,
          -0.5830638868068412,
          -0.6064985347750641,
          -0.6491396998330222,
          -0.5826558004544863,
          -0.7198382886238155,
          -0.6365594301626742,
          -0.7281212908735382,
          -0.6567363850441149,
          -0.6971412048790289,
          -0.7318348418229933,
          -0.6021902447489296,
          -0.6095886765036791,
          -0.7049809567680899,
          -0.5781707407675112,
          -0.7123111220953364,
          -0.5362297911996794,
          -0.48017143082383884,
          -0.6732099911144622,
          -0.6871998722518835,
          -0.6451410464166459,
          -0.4865594303939796,
          -0.6592189387766794,
          -0.693749189617136,
          -0.5394283111696837,
          -0.7215100690263254,
          -0.6504891641206486,
          -0.4936523772550081,
          -0.7190855088498597,
          -0.599901048813782,
          -0.620023220707351,
          -0.739729699618376,
          -0.5868279331750592,
          -0.6772506231255955,
          -0.5984380868184219,
          -0.6030898048350053,
          -0.6889229626111054,
          -0.6567346634068175,
          -0.5365280459528657,
          -0.5272902657503901,
          -0.55476088410808,
          -0.5774739914576263,
          -0.7206731014378128,
          -0.6649548646105757,
          -0.7282491320559438,
          -0.6023232035720847,
          -0.6979804239242376,
          -0.7253736482763804,
          -0.7364879531961795,
          -0.711902803318176,
          -0.5737354691618617,
          -0.720535430248012,
          -0.6140083975027244,
          -0.6308245622960367,
          -0.6491367580542484,
          -0.6892499103324194,
          -0.6394667580300355,
          -0.6217007472408888,
          -0.7516591987491003,
          -0.6137926197457685,
          -0.6572579621960393,
          -0.5183900208959733,
          -0.6485154077168571,
          -0.6861660653026901,
          -0.7079831661724818,
          -0.6507224003498766,
          -0.7008536636091017,
          -0.4951070763191515,
          -0.6786431670312996,
          -0.41712153744953867,
          -0.6530125755125364,
          -0.526232061303389,
          -0.6742692149713619,
          -0.5960874918976857,
          -0.49784523287761334,
          -0.7003034569002038,
          -0.5575261891851576,
          -0.5810795517404739,
          -0.6726223115203235,
          -0.694091583716562,
          -0.4861664314808126,
          -0.507416950495764,
          -0.6236326493753502,
          -0.5189671029336714,
          -0.7148407544852687,
          -0.6754185858520529,
          -0.7008124318678354,
          -0.6566906022367149,
          -0.7297684135600907,
          -0.4936445929582338,
          -0.5888379459234767,
          -0.6552274852289299,
          -0.7234335841567957,
          -0.5205696945991554,
          -0.633683600587547,
          -0.7322348031482341,
          -0.6937724542282755,
          -0.7103115372826633,
          -0.46884903303831527,
          -0.7350335184364061,
          -0.6357446263478554,
          -0.699773639185317,
          -0.6426578549811641,
          -0.726331002000095,
          -0.7046598199178369,
          -0.6877898034463746,
          -0.5525448469417281,
          -0.6072339340162648,
          -0.6946773147751654,
          -0.6554228057432875,
          -0.645021404016406,
          -0.5355676250624591,
          -0.6673732599985004,
          -0.7207819349945828,
          -0.7367207691047118,
          -0.7420911130977956,
          -0.6623641291825696,
          -0.6733691584391432,
          -0.5784691515708678,
          -0.672501061485665,
          -0.6036173020115925,
          -0.7378608921985318,
          -0.7086040899138626,
          -0.712465567142827,
          -0.6218786407188801,
          -0.4212134071076507,
          -0.5949471355620071,
          -0.7180744675724976,
          -0.5718444534185849,
          -0.7461401220979981,
          -0.7364451171482014,
          -0.5199233971097994,
          -0.6800661540612681,
          -0.684591705417201,
          -0.7185719666659782,
          -0.6216570790776361,
          -0.6884627522610869,
          -0.4309189236051133,
          -0.6340999971005971,
          -0.7049066735302822,
          -0.736095298396033,
          -0.5575661424557397,
          -0.5959313226084771,
          -0.5016420552290282,
          -0.6805391832296139,
          -0.6444461857333621,
          -0.4534311163839527,
          -0.47800147184878217,
          -0.6102641644057103,
          -0.7026023478696585,
          -0.7318410180459475,
          -0.6963147970356646,
          -0.642521595182975,
          -0.694945447973849,
          -0.7236210394028701,
          -0.6371319622457132,
          -0.6115631916304534,
          -0.6197233672065339,
          -0.676852588031575,
          -0.6528228850417255,
          -0.5211290232513768,
          -0.6654746909093561,
          -0.5636770700760805,
          -0.5175294276770354,
          -0.7268309692759534,
          -0.7406732821462988,
          -0.7244714284554623,
          -0.6771246795649218,
          -0.5738367943428421,
          -0.630059648664337,
          -0.6689786995690049,
          -0.6456385184089161,
          -0.5722304897299145,
          -0.7113690927547311,
          -0.6691184189269346,
          -0.7318861081941135,
          -0.6936201319594906,
          -0.6931301582428836,
          -0.7041098042916085,
          -0.7097183812834033,
          -0.7198481850934192,
          -0.6099603367831075,
          -0.6491512326214742,
          -0.6582898973695747,
          -0.7324866917533177,
          -0.6998170595673473,
          -0.7034158277071753,
          -0.6960785719312466,
          -0.7329104413017982,
          -0.7156840344107442,
          -0.5707474312936985,
          -0.6761639437737672,
          -0.6000102899875186,
          -0.6274440192800002,
          -0.6647295143875589,
          -0.7229885297048648,
          -0.7316851825880548,
          -0.6696044965221162,
          -0.7306129079287002,
          -0.7127968428609461,
          -0.6474466610642047,
          -0.5989142140222063,
          -0.7279520642017981,
          -0.6020729755651013,
          -0.6380264676883958,
          -0.6257526641657168,
          -0.6708333375154425,
          -0.7578233877174643,
          -0.7441611774895801,
          -0.6901953291032891,
          -0.5329652656024522,
          -0.5143749599108404,
          -0.6360197751044895,
          -0.531214555818096,
          -0.5688468200400122,
          -0.5078299289366355,
          -0.5509438186349598,
          -0.4864710548841935,
          -0.5653485969688753,
          -0.7221656977912196,
          -0.5646007388336587,
          -0.46611103733010184,
          -0.6805926648942202,
          -0.6125803512915705,
          -0.5740819386506406,
          -0.6247846010472962,
          -0.5667914055211967,
          -0.7026247461990621,
          -0.6767910787381247,
          -0.7118415145174344,
          -0.5680370727366446,
          -0.6619589024880559,
          -0.7113497640589168,
          -0.7486448026882424,
          -0.6788979361480916,
          -0.6154254779287277,
          -0.6889159699262372,
          -0.6180324814496077,
          -0.5838917014456367,
          -0.7356237605361198,
          -0.5682705094225385,
          -0.6663499638514605,
          -0.46176092237448574,
          -0.6284230075335148,
          -0.6801673404468926,
          -0.4936154585972261,
          -0.6373346837646287,
          -0.6965632065195855,
          -0.7214794070692744,
          -0.7412778765745585,
          -0.7303234753161248,
          -0.5611764201724139,
          -0.7363624422846056,
          -0.7180400916979447,
          -0.6681008871286774,
          -0.6812125402915006,
          -0.5884714836752222,
          -0.6755427794821022,
          -0.4497491571032429,
          -0.677293592678948,
          -0.6236895350248963,
          -0.6720504362637552,
          -0.6244630718918318,
          -0.48639822932872046,
          -0.551487612858421,
          -0.7356891659184572,
          -0.7356971786938408,
          -0.7223269473354956,
          -0.5499787650843161,
          -0.6770742267311218,
          -0.5221103797392065,
          -0.6066831694126149,
          -0.7278244879018139,
          -0.6952997155263386,
          -0.584159231412447,
          -0.6685154538991902,
          -0.5048338955860439,
          -0.7070019022696826,
          -0.6250023102477418,
          -0.646680312845219,
          -0.5379270872572142,
          -0.6654700817651202,
          -0.6636247872533302,
          -0.6792009826672004,
          -0.7137492455263932,
          -0.6945490215814906,
          -0.5585793459661609,
          -0.694684268570096,
          -0.6541532216221689,
          -0.7459895737522535,
          -0.6523654444704798,
          -0.6578189153874607,
          -0.7304803138532602,
          -0.5419238152300471,
          -0.6606622731024856,
          -0.7206965991143776,
          -0.5593332812885137
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          188,
          79,
          301,
          417,
          153,
          307,
          229,
          297,
          34,
          154,
          62,
          131,
          274,
          470,
          46,
          195,
          142,
          39,
          4,
          386,
          432,
          157,
          444,
          381,
          262,
          17,
          454,
          116,
          465,
          403,
          404,
          115,
          5,
          61,
          260,
          482,
          144,
          27,
          74,
          337,
          185,
          47,
          22,
          257,
          346,
          172,
          130,
          266,
          451,
          364,
          322,
          304,
          4,
          327,
          164,
          330,
          134,
          447,
          289,
          142,
          471,
          9,
          482,
          426,
          469,
          308,
          439,
          181,
          434,
          400,
          446,
          290,
          144,
          412,
          386,
          27,
          364,
          398,
          14,
          206,
          276,
          478,
          211,
          9,
          428,
          247,
          200,
          188,
          330,
          15,
          195,
          471,
          99,
          49,
          423,
          60,
          368,
          376,
          187,
          430,
          53,
          161,
          453,
          476,
          148,
          396,
          30,
          177,
          310,
          38,
          44,
          407,
          189,
          213,
          7,
          60,
          482,
          113,
          23,
          38,
          316,
          293,
          476,
          140,
          293,
          350,
          343,
          475,
          467,
          189,
          298,
          420,
          30,
          499,
          425,
          478,
          310,
          261,
          277,
          68,
          353,
          176,
          453,
          199,
          75,
          231,
          318,
          65,
          92,
          335,
          86,
          62,
          253,
          315,
          32,
          94,
          310,
          20,
          257,
          267,
          12,
          61,
          395,
          294,
          143,
          179,
          52,
          95,
          42,
          57,
          409,
          465,
          385,
          255,
          146,
          267,
          33,
          129,
          237,
          416,
          470,
          288,
          102,
          333,
          197,
          232,
          117,
          454,
          315,
          311,
          77,
          18,
          172,
          65,
          116,
          348,
          92,
          232,
          254,
          467,
          354,
          213,
          226,
          64,
          297,
          402,
          270,
          370,
          72,
          458,
          8,
          76,
          252,
          106,
          20,
          388,
          201,
          432,
          323,
          359,
          117,
          401,
          51,
          416,
          148,
          105,
          212,
          131,
          313,
          148,
          435,
          214,
          318,
          493,
          11,
          138,
          105,
          438,
          89,
          260,
          43,
          146,
          284,
          367,
          298,
          168,
          365,
          124,
          137,
          459,
          94,
          404,
          126,
          473,
          92,
          350,
          473,
          161,
          116,
          171,
          271,
          444,
          436,
          470,
          384,
          437,
          212,
          178,
          23,
          193,
          394,
          473,
          496,
          305,
          112,
          30,
          498,
          349,
          113,
          47,
          445,
          328,
          187,
          42,
          426,
          413,
          135,
          426,
          350,
          81,
          414,
          82,
          5,
          317,
          391,
          482,
          53,
          152,
          174,
          487
         ],
         "xaxis": "x4",
         "y": [
          -0.6656641089023417,
          -0.7199505312988174,
          -0.7367121976165063,
          -0.5292824062760534,
          -0.5830638868068412,
          -0.6064985347750641,
          -0.6491396998330222,
          -0.5826558004544863,
          -0.7198382886238155,
          -0.6365594301626742,
          -0.7281212908735382,
          -0.6567363850441149,
          -0.6971412048790289,
          -0.7318348418229933,
          -0.6021902447489296,
          -0.6095886765036791,
          -0.7049809567680899,
          -0.5781707407675112,
          -0.7123111220953364,
          -0.5362297911996794,
          -0.48017143082383884,
          -0.6732099911144622,
          -0.6871998722518835,
          -0.6451410464166459,
          -0.4865594303939796,
          -0.6592189387766794,
          -0.693749189617136,
          -0.5394283111696837,
          -0.7215100690263254,
          -0.6504891641206486,
          -0.4936523772550081,
          -0.7190855088498597,
          -0.599901048813782,
          -0.620023220707351,
          -0.739729699618376,
          -0.5868279331750592,
          -0.6772506231255955,
          -0.5984380868184219,
          -0.6030898048350053,
          -0.6889229626111054,
          -0.6567346634068175,
          -0.5365280459528657,
          -0.5272902657503901,
          -0.55476088410808,
          -0.5774739914576263,
          -0.7206731014378128,
          -0.6649548646105757,
          -0.7282491320559438,
          -0.6023232035720847,
          -0.6979804239242376,
          -0.7253736482763804,
          -0.7364879531961795,
          -0.711902803318176,
          -0.5737354691618617,
          -0.720535430248012,
          -0.6140083975027244,
          -0.6308245622960367,
          -0.6491367580542484,
          -0.6892499103324194,
          -0.6394667580300355,
          -0.6217007472408888,
          -0.7516591987491003,
          -0.6137926197457685,
          -0.6572579621960393,
          -0.5183900208959733,
          -0.6485154077168571,
          -0.6861660653026901,
          -0.7079831661724818,
          -0.6507224003498766,
          -0.7008536636091017,
          -0.4951070763191515,
          -0.6786431670312996,
          -0.41712153744953867,
          -0.6530125755125364,
          -0.526232061303389,
          -0.6742692149713619,
          -0.5960874918976857,
          -0.49784523287761334,
          -0.7003034569002038,
          -0.5575261891851576,
          -0.5810795517404739,
          -0.6726223115203235,
          -0.694091583716562,
          -0.4861664314808126,
          -0.507416950495764,
          -0.6236326493753502,
          -0.5189671029336714,
          -0.7148407544852687,
          -0.6754185858520529,
          -0.7008124318678354,
          -0.6566906022367149,
          -0.7297684135600907,
          -0.4936445929582338,
          -0.5888379459234767,
          -0.6552274852289299,
          -0.7234335841567957,
          -0.5205696945991554,
          -0.633683600587547,
          -0.7322348031482341,
          -0.6937724542282755,
          -0.7103115372826633,
          -0.46884903303831527,
          -0.7350335184364061,
          -0.6357446263478554,
          -0.699773639185317,
          -0.6426578549811641,
          -0.726331002000095,
          -0.7046598199178369,
          -0.6877898034463746,
          -0.5525448469417281,
          -0.6072339340162648,
          -0.6946773147751654,
          -0.6554228057432875,
          -0.645021404016406,
          -0.5355676250624591,
          -0.6673732599985004,
          -0.7207819349945828,
          -0.7367207691047118,
          -0.7420911130977956,
          -0.6623641291825696,
          -0.6733691584391432,
          -0.5784691515708678,
          -0.672501061485665,
          -0.6036173020115925,
          -0.7378608921985318,
          -0.7086040899138626,
          -0.712465567142827,
          -0.6218786407188801,
          -0.4212134071076507,
          -0.5949471355620071,
          -0.7180744675724976,
          -0.5718444534185849,
          -0.7461401220979981,
          -0.7364451171482014,
          -0.5199233971097994,
          -0.6800661540612681,
          -0.684591705417201,
          -0.7185719666659782,
          -0.6216570790776361,
          -0.6884627522610869,
          -0.4309189236051133,
          -0.6340999971005971,
          -0.7049066735302822,
          -0.736095298396033,
          -0.5575661424557397,
          -0.5959313226084771,
          -0.5016420552290282,
          -0.6805391832296139,
          -0.6444461857333621,
          -0.4534311163839527,
          -0.47800147184878217,
          -0.6102641644057103,
          -0.7026023478696585,
          -0.7318410180459475,
          -0.6963147970356646,
          -0.642521595182975,
          -0.694945447973849,
          -0.7236210394028701,
          -0.6371319622457132,
          -0.6115631916304534,
          -0.6197233672065339,
          -0.676852588031575,
          -0.6528228850417255,
          -0.5211290232513768,
          -0.6654746909093561,
          -0.5636770700760805,
          -0.5175294276770354,
          -0.7268309692759534,
          -0.7406732821462988,
          -0.7244714284554623,
          -0.6771246795649218,
          -0.5738367943428421,
          -0.630059648664337,
          -0.6689786995690049,
          -0.6456385184089161,
          -0.5722304897299145,
          -0.7113690927547311,
          -0.6691184189269346,
          -0.7318861081941135,
          -0.6936201319594906,
          -0.6931301582428836,
          -0.7041098042916085,
          -0.7097183812834033,
          -0.7198481850934192,
          -0.6099603367831075,
          -0.6491512326214742,
          -0.6582898973695747,
          -0.7324866917533177,
          -0.6998170595673473,
          -0.7034158277071753,
          -0.6960785719312466,
          -0.7329104413017982,
          -0.7156840344107442,
          -0.5707474312936985,
          -0.6761639437737672,
          -0.6000102899875186,
          -0.6274440192800002,
          -0.6647295143875589,
          -0.7229885297048648,
          -0.7316851825880548,
          -0.6696044965221162,
          -0.7306129079287002,
          -0.7127968428609461,
          -0.6474466610642047,
          -0.5989142140222063,
          -0.7279520642017981,
          -0.6020729755651013,
          -0.6380264676883958,
          -0.6257526641657168,
          -0.6708333375154425,
          -0.7578233877174643,
          -0.7441611774895801,
          -0.6901953291032891,
          -0.5329652656024522,
          -0.5143749599108404,
          -0.6360197751044895,
          -0.531214555818096,
          -0.5688468200400122,
          -0.5078299289366355,
          -0.5509438186349598,
          -0.4864710548841935,
          -0.5653485969688753,
          -0.7221656977912196,
          -0.5646007388336587,
          -0.46611103733010184,
          -0.6805926648942202,
          -0.6125803512915705,
          -0.5740819386506406,
          -0.6247846010472962,
          -0.5667914055211967,
          -0.7026247461990621,
          -0.6767910787381247,
          -0.7118415145174344,
          -0.5680370727366446,
          -0.6619589024880559,
          -0.7113497640589168,
          -0.7486448026882424,
          -0.6788979361480916,
          -0.6154254779287277,
          -0.6889159699262372,
          -0.6180324814496077,
          -0.5838917014456367,
          -0.7356237605361198,
          -0.5682705094225385,
          -0.6663499638514605,
          -0.46176092237448574,
          -0.6284230075335148,
          -0.6801673404468926,
          -0.4936154585972261,
          -0.6373346837646287,
          -0.6965632065195855,
          -0.7214794070692744,
          -0.7412778765745585,
          -0.7303234753161248,
          -0.5611764201724139,
          -0.7363624422846056,
          -0.7180400916979447,
          -0.6681008871286774,
          -0.6812125402915006,
          -0.5884714836752222,
          -0.6755427794821022,
          -0.4497491571032429,
          -0.677293592678948,
          -0.6236895350248963,
          -0.6720504362637552,
          -0.6244630718918318,
          -0.48639822932872046,
          -0.551487612858421,
          -0.7356891659184572,
          -0.7356971786938408,
          -0.7223269473354956,
          -0.5499787650843161,
          -0.6770742267311218,
          -0.5221103797392065,
          -0.6066831694126149,
          -0.7278244879018139,
          -0.6952997155263386,
          -0.584159231412447,
          -0.6685154538991902,
          -0.5048338955860439,
          -0.7070019022696826,
          -0.6250023102477418,
          -0.646680312845219,
          -0.5379270872572142,
          -0.6654700817651202,
          -0.6636247872533302,
          -0.6792009826672004,
          -0.7137492455263932,
          -0.6945490215814906,
          -0.5585793459661609,
          -0.694684268570096,
          -0.6541532216221689,
          -0.7459895737522535,
          -0.6523654444704798,
          -0.6578189153874607,
          -0.7304803138532602,
          -0.5419238152300471,
          -0.6606622731024856,
          -0.7206965991143776,
          -0.5593332812885137
         ],
         "yaxis": "y4"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Slice Plot"
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.2125
         ],
         "title": {
          "text": "max_depth"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.2625,
          0.475
         ],
         "title": {
          "text": "min_samples_leaf"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.525,
          0.7375
         ],
         "title": {
          "text": "min_samples_split"
         }
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.7875,
          1
         ],
         "title": {
          "text": "n_estimators"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Objective Value"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_slice(study, params=[\"n_estimators\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "n_estimators (IntDistribution): 0.0011226895563001325<extra></extra>",
          "max_depth (IntDistribution): 0.00446067248720753<extra></extra>",
          "min_samples_split (IntDistribution): 0.010581712134362152<extra></extra>",
          "min_samples_leaf (IntDistribution): 0.9838349258221303<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "<0.01",
          "<0.01",
          "0.01",
          "0.98"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.0011226895563001325,
          0.00446067248720753,
          0.010581712134362152,
          0.9838349258221303
         ],
         "y": [
          "n_estimators",
          "max_depth",
          "min_samples_split",
          "min_samples_leaf"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
